//go:build go1.18
// +build go1.18

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License. See License.txt in the project root for license information.
// Code generated by Microsoft (R) AutoRest Code Generator. DO NOT EDIT.
// Changes may cause incorrect behavior and will be lost if the code is regenerated.

package azopenai

// AudioTaskLabel - Defines the possible descriptors for available audio operation responses.
type AudioTaskLabel string

const (
	// AudioTaskLabelTranscribe - Accompanying response data resulted from an audio transcription task.
	AudioTaskLabelTranscribe AudioTaskLabel = "transcribe"
	// AudioTaskLabelTranslate - Accompanying response data resulted from an audio translation task.
	AudioTaskLabelTranslate AudioTaskLabel = "translate"
)

// PossibleAudioTaskLabelValues returns the possible values for the AudioTaskLabel const type.
func PossibleAudioTaskLabelValues() []AudioTaskLabel {
	return []AudioTaskLabel{
		AudioTaskLabelTranscribe,
		AudioTaskLabelTranslate,
	}
}

// AudioTranscriptionFormat - Defines available options for the underlying response format of output transcription information.
type AudioTranscriptionFormat string

const (
	// AudioTranscriptionFormatJSON - Use a response body that is a JSON object containing a single 'text' field for the transcription.
	AudioTranscriptionFormatJSON AudioTranscriptionFormat = "json"
	// AudioTranscriptionFormatSrt - Use a response body that is plain text in SubRip (SRT) format that also includes timing information.
	AudioTranscriptionFormatSrt AudioTranscriptionFormat = "srt"
	// AudioTranscriptionFormatText - Use a response body that is plain text containing the raw, unannotated transcription.
	AudioTranscriptionFormatText AudioTranscriptionFormat = "text"
	// AudioTranscriptionFormatVerboseJSON - Use a response body that is a JSON object containing transcription text along with
	// timing, segments, and other
	// metadata.
	AudioTranscriptionFormatVerboseJSON AudioTranscriptionFormat = "verbose_json"
	// AudioTranscriptionFormatVtt - Use a response body that is plain text in Web Video Text Tracks (VTT) format that also includes
	// timing information.
	AudioTranscriptionFormatVtt AudioTranscriptionFormat = "vtt"
)

// PossibleAudioTranscriptionFormatValues returns the possible values for the AudioTranscriptionFormat const type.
func PossibleAudioTranscriptionFormatValues() []AudioTranscriptionFormat {
	return []AudioTranscriptionFormat{
		AudioTranscriptionFormatJSON,
		AudioTranscriptionFormatSrt,
		AudioTranscriptionFormatText,
		AudioTranscriptionFormatVerboseJSON,
		AudioTranscriptionFormatVtt,
	}
}

// AudioTranscriptionTimestampGranularity - Defines the timestamp granularities that can be requested on a verbose transcription
// response.
type AudioTranscriptionTimestampGranularity string

const (
	// AudioTranscriptionTimestampGranularitySegment - Indicates that responses should include timing and other information about
	// each transcribed audio segment. Audio
	// segment timestamp information does not incur any additional latency.
	AudioTranscriptionTimestampGranularitySegment AudioTranscriptionTimestampGranularity = "segment"
	// AudioTranscriptionTimestampGranularityWord - Indicates that responses should include timing information about each transcribed
	// word. Note that generating word
	// timestamp information will incur additional response latency.
	AudioTranscriptionTimestampGranularityWord AudioTranscriptionTimestampGranularity = "word"
)

// PossibleAudioTranscriptionTimestampGranularityValues returns the possible values for the AudioTranscriptionTimestampGranularity const type.
func PossibleAudioTranscriptionTimestampGranularityValues() []AudioTranscriptionTimestampGranularity {
	return []AudioTranscriptionTimestampGranularity{
		AudioTranscriptionTimestampGranularitySegment,
		AudioTranscriptionTimestampGranularityWord,
	}
}

// AudioTranslationFormat - Defines available options for the underlying response format of output translation information.
type AudioTranslationFormat string

const (
	// AudioTranslationFormatJSON - Use a response body that is a JSON object containing a single 'text' field for the translation.
	AudioTranslationFormatJSON AudioTranslationFormat = "json"
	// AudioTranslationFormatSrt - Use a response body that is plain text in SubRip (SRT) format that also includes timing information.
	AudioTranslationFormatSrt AudioTranslationFormat = "srt"
	// AudioTranslationFormatText - Use a response body that is plain text containing the raw, unannotated translation.
	AudioTranslationFormatText AudioTranslationFormat = "text"
	// AudioTranslationFormatVerboseJSON - Use a response body that is a JSON object containing translation text along with timing,
	// segments, and other
	// metadata.
	AudioTranslationFormatVerboseJSON AudioTranslationFormat = "verbose_json"
	// AudioTranslationFormatVtt - Use a response body that is plain text in Web Video Text Tracks (VTT) format that also includes
	// timing information.
	AudioTranslationFormatVtt AudioTranslationFormat = "vtt"
)

// PossibleAudioTranslationFormatValues returns the possible values for the AudioTranslationFormat const type.
func PossibleAudioTranslationFormatValues() []AudioTranslationFormat {
	return []AudioTranslationFormat{
		AudioTranslationFormatJSON,
		AudioTranslationFormatSrt,
		AudioTranslationFormatText,
		AudioTranslationFormatVerboseJSON,
		AudioTranslationFormatVtt,
	}
}

// AzureChatExtensionRetrieveDocumentFilterReason - The reason for filtering the retrieved document.
type AzureChatExtensionRetrieveDocumentFilterReason string

const (
	// AzureChatExtensionRetrieveDocumentFilterReasonRerank - The document is not filtered by original search score threshold,
	// but is filtered by rerank score and `top_n_documents` configure.
	AzureChatExtensionRetrieveDocumentFilterReasonRerank AzureChatExtensionRetrieveDocumentFilterReason = "rerank"
	// AzureChatExtensionRetrieveDocumentFilterReasonScore - The document is filtered by original search score threshold defined
	// by `strictness` configure.
	AzureChatExtensionRetrieveDocumentFilterReasonScore AzureChatExtensionRetrieveDocumentFilterReason = "score"
)

// PossibleAzureChatExtensionRetrieveDocumentFilterReasonValues returns the possible values for the AzureChatExtensionRetrieveDocumentFilterReason const type.
func PossibleAzureChatExtensionRetrieveDocumentFilterReasonValues() []AzureChatExtensionRetrieveDocumentFilterReason {
	return []AzureChatExtensionRetrieveDocumentFilterReason{
		AzureChatExtensionRetrieveDocumentFilterReasonRerank,
		AzureChatExtensionRetrieveDocumentFilterReasonScore,
	}
}

// AzureChatExtensionType - A representation of configuration data for a single Azure OpenAI chat extension. This will be
// used by a chat completions request that should use Azure OpenAI chat extensions to augment the response
// behavior. The use of this configuration is compatible only with Azure OpenAI.
type AzureChatExtensionType string

const (
	// AzureChatExtensionTypeAzureCosmosDB - Represents the use of Azure Cosmos DB as an Azure OpenAI chat extension.
	AzureChatExtensionTypeAzureCosmosDB AzureChatExtensionType = "azure_cosmos_db"
	// AzureChatExtensionTypeAzureSearch - Represents the use of Azure AI Search as an Azure OpenAI chat extension.
	AzureChatExtensionTypeAzureSearch AzureChatExtensionType = "azure_search"
	// AzureChatExtensionTypeElasticsearch - Represents the use of Elasticsearch® index as an Azure OpenAI chat extension.
	AzureChatExtensionTypeElasticsearch AzureChatExtensionType = "elasticsearch"
	// AzureChatExtensionTypeMongoDB - Represents the use of a MongoDB chat extension.
	AzureChatExtensionTypeMongoDB AzureChatExtensionType = "mongo_db"
	// AzureChatExtensionTypePinecone - Represents the use of Pinecone index as an Azure OpenAI chat extension.
	AzureChatExtensionTypePinecone AzureChatExtensionType = "pinecone"
)

// PossibleAzureChatExtensionTypeValues returns the possible values for the AzureChatExtensionType const type.
func PossibleAzureChatExtensionTypeValues() []AzureChatExtensionType {
	return []AzureChatExtensionType{
		AzureChatExtensionTypeAzureCosmosDB,
		AzureChatExtensionTypeAzureSearch,
		AzureChatExtensionTypeElasticsearch,
		AzureChatExtensionTypeMongoDB,
		AzureChatExtensionTypePinecone,
	}
}

// AzureSearchQueryType - The type of Azure Search retrieval query that should be executed when using it as an Azure OpenAI
// chat extension.
type AzureSearchQueryType string

const (
	// AzureSearchQueryTypeSemantic - Represents the semantic query parser for advanced semantic modeling.
	AzureSearchQueryTypeSemantic AzureSearchQueryType = "semantic"
	// AzureSearchQueryTypeSimple - Represents the default, simple query parser.
	AzureSearchQueryTypeSimple AzureSearchQueryType = "simple"
	// AzureSearchQueryTypeVector - Represents vector search over computed data.
	AzureSearchQueryTypeVector AzureSearchQueryType = "vector"
	// AzureSearchQueryTypeVectorSemanticHybrid - Represents a combination of semantic search and vector data querying.
	AzureSearchQueryTypeVectorSemanticHybrid AzureSearchQueryType = "vector_semantic_hybrid"
	// AzureSearchQueryTypeVectorSimpleHybrid - Represents a combination of the simple query strategy with vector data.
	AzureSearchQueryTypeVectorSimpleHybrid AzureSearchQueryType = "vector_simple_hybrid"
)

// PossibleAzureSearchQueryTypeValues returns the possible values for the AzureSearchQueryType const type.
func PossibleAzureSearchQueryTypeValues() []AzureSearchQueryType {
	return []AzureSearchQueryType{
		AzureSearchQueryTypeSemantic,
		AzureSearchQueryTypeSimple,
		AzureSearchQueryTypeVector,
		AzureSearchQueryTypeVectorSemanticHybrid,
		AzureSearchQueryTypeVectorSimpleHybrid,
	}
}

// BatchStatus - The status of a batch.
type BatchStatus string

const (
	// BatchStatusCancelled - The batch was cancelled.
	BatchStatusCancelled BatchStatus = "cancelled"
	// BatchStatusCancelling - Cancellation of the batch has been initiated.
	BatchStatusCancelling BatchStatus = "cancelling"
	// BatchStatusCompleted - The batch has been completed and the results are ready.
	BatchStatusCompleted BatchStatus = "completed"
	// BatchStatusExpired - The batch was not able to complete within the 24-hour time window.
	BatchStatusExpired BatchStatus = "expired"
	// BatchStatusFailed - The input file has failed the validation process.
	BatchStatusFailed BatchStatus = "failed"
	// BatchStatusFinalizing - The batch has completed and the results are being prepared.
	BatchStatusFinalizing BatchStatus = "finalizing"
	// BatchStatusInProgress - The input file was successfully validated and the batch is currently being executed.
	BatchStatusInProgress BatchStatus = "in_progress"
	// BatchStatusValidating - The input file is being validated before the batch can begin.
	BatchStatusValidating BatchStatus = "validating"
)

// PossibleBatchStatusValues returns the possible values for the BatchStatus const type.
func PossibleBatchStatusValues() []BatchStatus {
	return []BatchStatus{
		BatchStatusCancelled,
		BatchStatusCancelling,
		BatchStatusCompleted,
		BatchStatusExpired,
		BatchStatusFailed,
		BatchStatusFinalizing,
		BatchStatusInProgress,
		BatchStatusValidating,
	}
}

// ChatCompletionModality - Values to specified the required modality for the model to use.
type ChatCompletionModality string

const (
	// ChatCompletionModalityAudio - The model is to generate audio output.
	ChatCompletionModalityAudio ChatCompletionModality = "audio"
	// ChatCompletionModalityText - The model is to generate text output.
	ChatCompletionModalityText ChatCompletionModality = "text"
)

// PossibleChatCompletionModalityValues returns the possible values for the ChatCompletionModality const type.
func PossibleChatCompletionModalityValues() []ChatCompletionModality {
	return []ChatCompletionModality{
		ChatCompletionModalityAudio,
		ChatCompletionModalityText,
	}
}

// ChatCompletionRequestMessageContentPartImageURLDetail - Specifies the detail level of the image. Learn more in the Vision
// guide [/docs/guides/vision/low-or-high-fidelity-image-understanding].
type ChatCompletionRequestMessageContentPartImageURLDetail string

const (
	ChatCompletionRequestMessageContentPartImageURLDetailAuto ChatCompletionRequestMessageContentPartImageURLDetail = "auto"
	ChatCompletionRequestMessageContentPartImageURLDetailHigh ChatCompletionRequestMessageContentPartImageURLDetail = "high"
	ChatCompletionRequestMessageContentPartImageURLDetailLow  ChatCompletionRequestMessageContentPartImageURLDetail = "low"
)

// PossibleChatCompletionRequestMessageContentPartImageURLDetailValues returns the possible values for the ChatCompletionRequestMessageContentPartImageURLDetail const type.
func PossibleChatCompletionRequestMessageContentPartImageURLDetailValues() []ChatCompletionRequestMessageContentPartImageURLDetail {
	return []ChatCompletionRequestMessageContentPartImageURLDetail{
		ChatCompletionRequestMessageContentPartImageURLDetailAuto,
		ChatCompletionRequestMessageContentPartImageURLDetailHigh,
		ChatCompletionRequestMessageContentPartImageURLDetailLow,
	}
}

// ChatCompletionRequestMessageContentPartType - The type of the content part.
type ChatCompletionRequestMessageContentPartType string

const (
	// ChatCompletionRequestMessageContentPartTypeImageURL - Chat content contains an image URL
	ChatCompletionRequestMessageContentPartTypeImageURL ChatCompletionRequestMessageContentPartType = "image_url"
	// ChatCompletionRequestMessageContentPartTypeText - Chat content contains text
	ChatCompletionRequestMessageContentPartTypeText ChatCompletionRequestMessageContentPartType = "text"
)

// PossibleChatCompletionRequestMessageContentPartTypeValues returns the possible values for the ChatCompletionRequestMessageContentPartType const type.
func PossibleChatCompletionRequestMessageContentPartTypeValues() []ChatCompletionRequestMessageContentPartType {
	return []ChatCompletionRequestMessageContentPartType{
		ChatCompletionRequestMessageContentPartTypeImageURL,
		ChatCompletionRequestMessageContentPartTypeText,
	}
}

// ChatCompletionsToolSelectionPreset - Represents a generic policy for how a chat completions tool may be selected.
type ChatCompletionsToolSelectionPreset string

const (
	// ChatCompletionsToolSelectionPresetAuto - Specifies that the model may either use any of the tools provided in this chat
	// completions request or
	// instead return a standard chat completions response as if no tools were provided.
	ChatCompletionsToolSelectionPresetAuto ChatCompletionsToolSelectionPreset = "auto"
	// ChatCompletionsToolSelectionPresetNone - Specifies that the model should not respond with a tool call and should instead
	// provide a standard chat
	// completions response. Response content may still be influenced by the provided tool definitions.
	ChatCompletionsToolSelectionPresetNone ChatCompletionsToolSelectionPreset = "none"
	// ChatCompletionsToolSelectionPresetRequired - Specifies that the model must call one or more tools.
	ChatCompletionsToolSelectionPresetRequired ChatCompletionsToolSelectionPreset = "required"
)

// PossibleChatCompletionsToolSelectionPresetValues returns the possible values for the ChatCompletionsToolSelectionPreset const type.
func PossibleChatCompletionsToolSelectionPresetValues() []ChatCompletionsToolSelectionPreset {
	return []ChatCompletionsToolSelectionPreset{
		ChatCompletionsToolSelectionPresetAuto,
		ChatCompletionsToolSelectionPresetNone,
		ChatCompletionsToolSelectionPresetRequired,
	}
}

// ChatMessageImageDetailLevel - A representation of the possible image detail levels for image-based chat completions message
// content.
type ChatMessageImageDetailLevel string

const (
	// ChatMessageImageDetailLevelAuto - Specifies that the model should determine which detail level to apply using heuristics
	// like image size.
	ChatMessageImageDetailLevelAuto ChatMessageImageDetailLevel = "auto"
	// ChatMessageImageDetailLevelHigh - Specifies that image evaluation should enable the 'high-res' model that may be more accurate
	// for highly detailed
	// images but may also be slower and consume more tokens.
	ChatMessageImageDetailLevelHigh ChatMessageImageDetailLevel = "high"
	// ChatMessageImageDetailLevelLow - Specifies that image evaluation should be constrained to the 'low-res' model that may
	// be faster and consume fewer
	// tokens but may also be less accurate for highly detailed images.
	ChatMessageImageDetailLevelLow ChatMessageImageDetailLevel = "low"
)

// PossibleChatMessageImageDetailLevelValues returns the possible values for the ChatMessageImageDetailLevel const type.
func PossibleChatMessageImageDetailLevelValues() []ChatMessageImageDetailLevel {
	return []ChatMessageImageDetailLevel{
		ChatMessageImageDetailLevelAuto,
		ChatMessageImageDetailLevelHigh,
		ChatMessageImageDetailLevelLow,
	}
}

// ChatRole - A description of the intended purpose of a message within a chat completions interaction.
type ChatRole string

const (
	// ChatRoleAssistant - The role that provides responses to system-instructed, user-prompted input.
	ChatRoleAssistant ChatRole = "assistant"
	// ChatRoleDeveloper - The role that provides instructions that the model should follow
	ChatRoleDeveloper ChatRole = "developer"
	// ChatRoleFunction - The role that provides function results for chat completions.
	ChatRoleFunction ChatRole = "function"
	// ChatRoleSystem - The role that instructs or sets the behavior of the assistant.
	ChatRoleSystem ChatRole = "system"
	// ChatRoleTool - The role that represents extension tool activity within a chat completions operation.
	ChatRoleTool ChatRole = "tool"
	// ChatRoleUser - The role that provides input for chat completions.
	ChatRoleUser ChatRole = "user"
)

// PossibleChatRoleValues returns the possible values for the ChatRole const type.
func PossibleChatRoleValues() []ChatRole {
	return []ChatRole{
		ChatRoleAssistant,
		ChatRoleDeveloper,
		ChatRoleFunction,
		ChatRoleSystem,
		ChatRoleTool,
		ChatRoleUser,
	}
}

// CompletionsFinishReason - Representation of the manner in which a completions response concluded.
type CompletionsFinishReason string

const (
	// CompletionsFinishReasonContentFiltered - Completions generated a response that was identified as potentially sensitive
	// per content
	// moderation policies.
	CompletionsFinishReasonContentFiltered CompletionsFinishReason = "content_filter"
	// CompletionsFinishReasonFunctionCall - Completion ended normally, with the model requesting a function to be called.
	CompletionsFinishReasonFunctionCall CompletionsFinishReason = "function_call"
	// CompletionsFinishReasonStopped - Completions ended normally and reached its end of token generation.
	CompletionsFinishReasonStopped CompletionsFinishReason = "stop"
	// CompletionsFinishReasonTokenLimitReached - Completions exhausted available token limits before generation could complete.
	CompletionsFinishReasonTokenLimitReached CompletionsFinishReason = "length"
	// CompletionsFinishReasonToolCalls - Completion ended with the model calling a provided tool for output.
	CompletionsFinishReasonToolCalls CompletionsFinishReason = "tool_calls"
)

// PossibleCompletionsFinishReasonValues returns the possible values for the CompletionsFinishReason const type.
func PossibleCompletionsFinishReasonValues() []CompletionsFinishReason {
	return []CompletionsFinishReason{
		CompletionsFinishReasonContentFiltered,
		CompletionsFinishReasonFunctionCall,
		CompletionsFinishReasonStopped,
		CompletionsFinishReasonTokenLimitReached,
		CompletionsFinishReasonToolCalls,
	}
}

// ContentFilterSeverity - Ratings for the intensity and risk level of harmful content.
type ContentFilterSeverity string

const (
	// ContentFilterSeverityHigh - Content that displays explicit and severe harmful instructions, actions,
	// damage, or abuse; includes endorsement, glorification, or promotion of severe
	// harmful acts, extreme or illegal forms of harm, radicalization, or non-consensual
	// power exchange or abuse.
	ContentFilterSeverityHigh ContentFilterSeverity = "high"
	// ContentFilterSeverityLow - Content that expresses prejudiced, judgmental, or opinionated views, includes offensive
	// use of language, stereotyping, use cases exploring a fictional world (for example, gaming,
	// literature) and depictions at low intensity.
	ContentFilterSeverityLow ContentFilterSeverity = "low"
	// ContentFilterSeverityMedium - Content that uses offensive, insulting, mocking, intimidating, or demeaning language
	// towards specific identity groups, includes depictions of seeking and executing harmful
	// instructions, fantasies, glorification, promotion of harm at medium intensity.
	ContentFilterSeverityMedium ContentFilterSeverity = "medium"
	// ContentFilterSeveritySafe - Content may be related to violence, self-harm, sexual, or hate categories but the terms
	// are used in general, journalistic, scientific, medical, and similar professional contexts,
	// which are appropriate for most audiences.
	ContentFilterSeveritySafe ContentFilterSeverity = "safe"
)

// PossibleContentFilterSeverityValues returns the possible values for the ContentFilterSeverity const type.
func PossibleContentFilterSeverityValues() []ContentFilterSeverity {
	return []ContentFilterSeverity{
		ContentFilterSeverityHigh,
		ContentFilterSeverityLow,
		ContentFilterSeverityMedium,
		ContentFilterSeveritySafe,
	}
}

// CreateUploadRequestPurpose - The intended purpose of the uploaded file.
// Use 'assistants' for Assistants and Message files, 'vision' for Assistants image file inputs, 'batch' for Batch API, and
// 'fine-tune' for Fine-tuning.
type CreateUploadRequestPurpose string

const (
	CreateUploadRequestPurposeAssistants CreateUploadRequestPurpose = "assistants"
	CreateUploadRequestPurposeBatch      CreateUploadRequestPurpose = "batch"
	CreateUploadRequestPurposeFineTune   CreateUploadRequestPurpose = "fine-tune"
	CreateUploadRequestPurposeVision     CreateUploadRequestPurpose = "vision"
)

// PossibleCreateUploadRequestPurposeValues returns the possible values for the CreateUploadRequestPurpose const type.
func PossibleCreateUploadRequestPurposeValues() []CreateUploadRequestPurpose {
	return []CreateUploadRequestPurpose{
		CreateUploadRequestPurposeAssistants,
		CreateUploadRequestPurposeBatch,
		CreateUploadRequestPurposeFineTune,
		CreateUploadRequestPurposeVision,
	}
}

// ElasticsearchQueryType - The type of Elasticsearch® retrieval query that should be executed when using it as an Azure OpenAI
// chat extension.
type ElasticsearchQueryType string

const (
	// ElasticsearchQueryTypeSimple - Represents the default, simple query parser.
	ElasticsearchQueryTypeSimple ElasticsearchQueryType = "simple"
	// ElasticsearchQueryTypeVector - Represents vector search over computed data.
	ElasticsearchQueryTypeVector ElasticsearchQueryType = "vector"
)

// PossibleElasticsearchQueryTypeValues returns the possible values for the ElasticsearchQueryType const type.
func PossibleElasticsearchQueryTypeValues() []ElasticsearchQueryType {
	return []ElasticsearchQueryType{
		ElasticsearchQueryTypeSimple,
		ElasticsearchQueryTypeVector,
	}
}

// EmbeddingEncodingFormat - Represents the available formats for embeddings data on responses.
type EmbeddingEncodingFormat string

const (
	// EmbeddingEncodingFormatBase64 - Specifies that responses should provide a base64-encoded string for each embedding.
	EmbeddingEncodingFormatBase64 EmbeddingEncodingFormat = "base64"
	// EmbeddingEncodingFormatFloat - Specifies that responses should provide arrays of floats for each embedding.
	EmbeddingEncodingFormatFloat EmbeddingEncodingFormat = "float"
)

// PossibleEmbeddingEncodingFormatValues returns the possible values for the EmbeddingEncodingFormat const type.
func PossibleEmbeddingEncodingFormatValues() []EmbeddingEncodingFormat {
	return []EmbeddingEncodingFormat{
		EmbeddingEncodingFormatBase64,
		EmbeddingEncodingFormatFloat,
	}
}

// FilePurpose - The possible values denoting the intended usage of a file.
type FilePurpose string

const (
	// FilePurposeAssistants - Indicates a file is used as input to assistants.
	FilePurposeAssistants FilePurpose = "assistants"
	// FilePurposeAssistantsOutput - Indicates a file is used as output by assistants.
	FilePurposeAssistantsOutput FilePurpose = "assistants_output"
	// FilePurposeBatch - Indicates a file is used as input to .
	FilePurposeBatch FilePurpose = "batch"
	// FilePurposeBatchOutput - Indicates a file is used as output by a vector store batch operation.
	FilePurposeBatchOutput FilePurpose = "batch_output"
	// FilePurposeFineTune - Indicates a file is used for fine tuning input.
	FilePurposeFineTune FilePurpose = "fine-tune"
	// FilePurposeFineTuneResults - Indicates a file is used for fine tuning results.
	FilePurposeFineTuneResults FilePurpose = "fine-tune-results"
	// FilePurposeVision - Indicates a file is used as input to a vision operation.
	FilePurposeVision FilePurpose = "vision"
)

// PossibleFilePurposeValues returns the possible values for the FilePurpose const type.
func PossibleFilePurposeValues() []FilePurpose {
	return []FilePurpose{
		FilePurposeAssistants,
		FilePurposeAssistantsOutput,
		FilePurposeBatch,
		FilePurposeBatchOutput,
		FilePurposeFineTune,
		FilePurposeFineTuneResults,
		FilePurposeVision,
	}
}

// FileState - The state of the file.
type FileState string

const (
	// FileStateDeleted - The entity has been deleted but may still be referenced by other entities predating the deletion. It
	// can be categorized as a
	// terminal state.
	FileStateDeleted FileState = "deleted"
	// FileStateDeleting - The entity is in the process to be deleted. This state is not returned by Azure OpenAI and exposed
	// only for compatibility.
	// It can be categorized as an active state.
	FileStateDeleting FileState = "deleting"
	// FileStateError - The operation has completed processing with a failure and cannot be further consumed. It can be categorized
	// as a terminal state.
	FileStateError FileState = "error"
	// FileStatePending - The operation was created and is not queued to be processed in the future. It can be categorized as
	// an inactive state.
	FileStatePending FileState = "pending"
	// FileStateProcessed - The operation has successfully processed and is ready for consumption. It can be categorized as a
	// terminal state.
	FileStateProcessed FileState = "processed"
	// FileStateRunning - The operation has started to be processed. It can be categorized as an active state.
	FileStateRunning FileState = "running"
	// FileStateUploaded - The file has been uploaded but it's not yet processed. This state is not returned by Azure OpenAI and
	// exposed only for
	// compatibility. It can be categorized as an inactive state.
	FileStateUploaded FileState = "uploaded"
)

// PossibleFileStateValues returns the possible values for the FileState const type.
func PossibleFileStateValues() []FileState {
	return []FileState{
		FileStateDeleted,
		FileStateDeleting,
		FileStateError,
		FileStatePending,
		FileStateProcessed,
		FileStateRunning,
		FileStateUploaded,
	}
}

// FunctionCallPreset - The collection of predefined behaviors for handling request-provided function information in a chat
// completions operation.
type FunctionCallPreset string

const (
	// FunctionCallPresetAuto - Specifies that the model may either use any of the functions provided in this chat completions
	// request or
	// instead return a standard chat completions response as if no functions were provided.
	FunctionCallPresetAuto FunctionCallPreset = "auto"
	// FunctionCallPresetNone - Specifies that the model should not respond with a function call and should instead provide a
	// standard chat
	// completions response. Response content may still be influenced by the provided function information.
	FunctionCallPresetNone FunctionCallPreset = "none"
)

// PossibleFunctionCallPresetValues returns the possible values for the FunctionCallPreset const type.
func PossibleFunctionCallPresetValues() []FunctionCallPreset {
	return []FunctionCallPreset{
		FunctionCallPresetAuto,
		FunctionCallPresetNone,
	}
}

// ImageGenerationQuality - The desired image generation quality level to use. Only configurable with dall-e-3 models.
type ImageGenerationQuality string

const (
	// ImageGenerationQualityHd - Requests image generation with higher quality, higher cost and lower speed relative to standard.
	ImageGenerationQualityHd ImageGenerationQuality = "hd"
	// ImageGenerationQualityStandard - Requests image generation with standard, balanced characteristics of quality, cost, and
	// speed.
	ImageGenerationQualityStandard ImageGenerationQuality = "standard"
)

// PossibleImageGenerationQualityValues returns the possible values for the ImageGenerationQuality const type.
func PossibleImageGenerationQualityValues() []ImageGenerationQuality {
	return []ImageGenerationQuality{
		ImageGenerationQualityHd,
		ImageGenerationQualityStandard,
	}
}

// ImageGenerationResponseFormat - The format in which image generation response items should be presented.
type ImageGenerationResponseFormat string

const (
	// ImageGenerationResponseFormatBase64 - Image generation response items should provide image data as a base64-encoded string.
	ImageGenerationResponseFormatBase64 ImageGenerationResponseFormat = "b64_json"
	// ImageGenerationResponseFormatURL - Image generation response items should provide a URL from which the image may be retrieved.
	ImageGenerationResponseFormatURL ImageGenerationResponseFormat = "url"
)

// PossibleImageGenerationResponseFormatValues returns the possible values for the ImageGenerationResponseFormat const type.
func PossibleImageGenerationResponseFormatValues() []ImageGenerationResponseFormat {
	return []ImageGenerationResponseFormat{
		ImageGenerationResponseFormatBase64,
		ImageGenerationResponseFormatURL,
	}
}

// ImageGenerationStyle - The desired image generation style to use. Only configurable with dall-e-3 models.
type ImageGenerationStyle string

const (
	// ImageGenerationStyleNatural - Requests image generation in a natural style with less preference for dramatic and hyper-realistic
	// characteristics.
	ImageGenerationStyleNatural ImageGenerationStyle = "natural"
	// ImageGenerationStyleVivid - Requests image generation in a vivid style with a higher preference for dramatic and hyper-realistic
	// characteristics.
	ImageGenerationStyleVivid ImageGenerationStyle = "vivid"
)

// PossibleImageGenerationStyleValues returns the possible values for the ImageGenerationStyle const type.
func PossibleImageGenerationStyleValues() []ImageGenerationStyle {
	return []ImageGenerationStyle{
		ImageGenerationStyleNatural,
		ImageGenerationStyleVivid,
	}
}

// ImageSize - The desired dimensions for generated images. Dall-e-2 models support 256x256, 512x512, or 1024x1024. Dall-e-3
// models support 1024x1024, 1792x1024, or 1024x1792.
type ImageSize string

const (
	// ImageSizeSize1024X1024 - A standard, square image size of 1024x1024 pixels.
	// Supported by both dall-e-2 and dall-e-3 models.
	ImageSizeSize1024X1024 ImageSize = "1024x1024"
	// ImageSizeSize1024X1792 - A taller image size of 1792x1024 pixels.
	// Only supported with dall-e-3 models.
	ImageSizeSize1024X1792 ImageSize = "1024x1792"
	// ImageSizeSize1792X1024 - A wider image size of 1024x1792 pixels.
	// Only supported with dall-e-3 models.
	ImageSizeSize1792X1024 ImageSize = "1792x1024"
	// ImageSizeSize256X256 - Very small image size of 256x256 pixels.
	// Only supported with dall-e-2 models.
	ImageSizeSize256X256 ImageSize = "256x256"
	// ImageSizeSize512X512 - A smaller image size of 512x512 pixels.
	// Only supported with dall-e-2 models.
	ImageSizeSize512X512 ImageSize = "512x512"
)

// PossibleImageSizeValues returns the possible values for the ImageSize const type.
func PossibleImageSizeValues() []ImageSize {
	return []ImageSize{
		ImageSizeSize1024X1024,
		ImageSizeSize1024X1792,
		ImageSizeSize1792X1024,
		ImageSizeSize256X256,
		ImageSizeSize512X512,
	}
}

// InputAudioFormat - Values to describe the format of the input audio data.
type InputAudioFormat string

const (
	// InputAudioFormatMp3 - Specifies that the audio data is in the MP3 format.
	InputAudioFormatMp3 InputAudioFormat = "mp3"
	// InputAudioFormatWav - Specifies that the audio data is in the WAV format.
	InputAudioFormatWav InputAudioFormat = "wav"
)

// PossibleInputAudioFormatValues returns the possible values for the InputAudioFormat const type.
func PossibleInputAudioFormatValues() []InputAudioFormat {
	return []InputAudioFormat{
		InputAudioFormatMp3,
		InputAudioFormatWav,
	}
}

// OnYourDataAuthenticationType - The authentication types supported with Azure OpenAI On Your Data.
type OnYourDataAuthenticationType string

const (
	// OnYourDataAuthenticationTypeAPIKey - Authentication via API key.
	OnYourDataAuthenticationTypeAPIKey OnYourDataAuthenticationType = "api_key"
	// OnYourDataAuthenticationTypeAccessToken - Authentication via access token.
	OnYourDataAuthenticationTypeAccessToken OnYourDataAuthenticationType = "access_token"
	// OnYourDataAuthenticationTypeConnectionString - Authentication via connection string.
	OnYourDataAuthenticationTypeConnectionString OnYourDataAuthenticationType = "connection_string"
	// OnYourDataAuthenticationTypeEncodedAPIKey - Authentication via encoded API key.
	OnYourDataAuthenticationTypeEncodedAPIKey OnYourDataAuthenticationType = "encoded_api_key"
	// OnYourDataAuthenticationTypeKeyAndKeyID - Authentication via key and key ID pair.
	OnYourDataAuthenticationTypeKeyAndKeyID OnYourDataAuthenticationType = "key_and_key_id"
	// OnYourDataAuthenticationTypeSystemAssignedManagedIdentity - Authentication via system-assigned managed identity.
	OnYourDataAuthenticationTypeSystemAssignedManagedIdentity OnYourDataAuthenticationType = "system_assigned_managed_identity"
	// OnYourDataAuthenticationTypeUserAssignedManagedIdentity - Authentication via user-assigned managed identity.
	OnYourDataAuthenticationTypeUserAssignedManagedIdentity OnYourDataAuthenticationType = "user_assigned_managed_identity"
	// OnYourDataAuthenticationTypeUsernameAndPassword - Authentication via username and password.
	OnYourDataAuthenticationTypeUsernameAndPassword OnYourDataAuthenticationType = "username_and_password"
)

// PossibleOnYourDataAuthenticationTypeValues returns the possible values for the OnYourDataAuthenticationType const type.
func PossibleOnYourDataAuthenticationTypeValues() []OnYourDataAuthenticationType {
	return []OnYourDataAuthenticationType{
		OnYourDataAuthenticationTypeAPIKey,
		OnYourDataAuthenticationTypeAccessToken,
		OnYourDataAuthenticationTypeConnectionString,
		OnYourDataAuthenticationTypeEncodedAPIKey,
		OnYourDataAuthenticationTypeKeyAndKeyID,
		OnYourDataAuthenticationTypeSystemAssignedManagedIdentity,
		OnYourDataAuthenticationTypeUserAssignedManagedIdentity,
		OnYourDataAuthenticationTypeUsernameAndPassword,
	}
}

// OnYourDataContextProperty - The context property.
type OnYourDataContextProperty string

const (
	// OnYourDataContextPropertyAllRetrievedDocuments - The `all_retrieved_documents` property.
	OnYourDataContextPropertyAllRetrievedDocuments OnYourDataContextProperty = "all_retrieved_documents"
	// OnYourDataContextPropertyCitations - The `citations` property.
	OnYourDataContextPropertyCitations OnYourDataContextProperty = "citations"
	// OnYourDataContextPropertyIntent - The `intent` property.
	OnYourDataContextPropertyIntent OnYourDataContextProperty = "intent"
)

// PossibleOnYourDataContextPropertyValues returns the possible values for the OnYourDataContextProperty const type.
func PossibleOnYourDataContextPropertyValues() []OnYourDataContextProperty {
	return []OnYourDataContextProperty{
		OnYourDataContextPropertyAllRetrievedDocuments,
		OnYourDataContextPropertyCitations,
		OnYourDataContextPropertyIntent,
	}
}

// OnYourDataVectorSearchAuthenticationType - The authentication types supported with Azure OpenAI On Your Data vector search.
type OnYourDataVectorSearchAuthenticationType string

const (
	// OnYourDataVectorSearchAuthenticationTypeAPIKey - Authentication via API key.
	OnYourDataVectorSearchAuthenticationTypeAPIKey OnYourDataVectorSearchAuthenticationType = "api_key"
	// OnYourDataVectorSearchAuthenticationTypeAccessToken - Authentication via access token.
	OnYourDataVectorSearchAuthenticationTypeAccessToken OnYourDataVectorSearchAuthenticationType = "access_token"
)

// PossibleOnYourDataVectorSearchAuthenticationTypeValues returns the possible values for the OnYourDataVectorSearchAuthenticationType const type.
func PossibleOnYourDataVectorSearchAuthenticationTypeValues() []OnYourDataVectorSearchAuthenticationType {
	return []OnYourDataVectorSearchAuthenticationType{
		OnYourDataVectorSearchAuthenticationTypeAPIKey,
		OnYourDataVectorSearchAuthenticationTypeAccessToken,
	}
}

// OnYourDataVectorizationSourceType - Represents the available sources Azure OpenAI On Your Data can use to configure vectorization
// of data for use with vector search.
type OnYourDataVectorizationSourceType string

const (
	// OnYourDataVectorizationSourceTypeDeploymentName - Represents an Ada model deployment name to use. This model deployment
	// must be in the same Azure OpenAI resource, but
	// On Your Data will use this model deployment via an internal call rather than a public one, which enables vector
	// search even in private networks.
	OnYourDataVectorizationSourceTypeDeploymentName OnYourDataVectorizationSourceType = "deployment_name"
	// OnYourDataVectorizationSourceTypeEndpoint - Represents vectorization performed by public service calls to an Azure OpenAI
	// embedding model.
	OnYourDataVectorizationSourceTypeEndpoint OnYourDataVectorizationSourceType = "endpoint"
	// OnYourDataVectorizationSourceTypeIntegrated - Represents the integrated vectorizer defined within the search resource.
	OnYourDataVectorizationSourceTypeIntegrated OnYourDataVectorizationSourceType = "integrated"
	// OnYourDataVectorizationSourceTypeModelID - Represents a specific embedding model ID as defined in the search service.
	// Currently only supported by Elasticsearch®.
	OnYourDataVectorizationSourceTypeModelID OnYourDataVectorizationSourceType = "model_id"
)

// PossibleOnYourDataVectorizationSourceTypeValues returns the possible values for the OnYourDataVectorizationSourceType const type.
func PossibleOnYourDataVectorizationSourceTypeValues() []OnYourDataVectorizationSourceType {
	return []OnYourDataVectorizationSourceType{
		OnYourDataVectorizationSourceTypeDeploymentName,
		OnYourDataVectorizationSourceTypeEndpoint,
		OnYourDataVectorizationSourceTypeIntegrated,
		OnYourDataVectorizationSourceTypeModelID,
	}
}

// OutputAudioFormat - The output audio format.
type OutputAudioFormat string

const (
	// OutputAudioFormatFlac - The output audio format is FLAC.
	OutputAudioFormatFlac OutputAudioFormat = "flac"
	// OutputAudioFormatMp3 - The output audio format is MP3.
	OutputAudioFormatMp3 OutputAudioFormat = "mp3"
	// OutputAudioFormatOpus - The output audio format is OPUS.
	OutputAudioFormatOpus OutputAudioFormat = "opus"
	// OutputAudioFormatPcm16 - The output audio format is PCM16.
	OutputAudioFormatPcm16 OutputAudioFormat = "pcm16"
	// OutputAudioFormatWav - The output audio format is WAV.
	OutputAudioFormatWav OutputAudioFormat = "wav"
)

// PossibleOutputAudioFormatValues returns the possible values for the OutputAudioFormat const type.
func PossibleOutputAudioFormatValues() []OutputAudioFormat {
	return []OutputAudioFormat{
		OutputAudioFormatFlac,
		OutputAudioFormatMp3,
		OutputAudioFormatOpus,
		OutputAudioFormatPcm16,
		OutputAudioFormatWav,
	}
}

// ReasoningEffortValue - This option is only valid for o1 models,
// Constrains effort on reasoning for reasoning models (see https://platform.openai.com/docs/guides/reasoning).
// Currently supported values are low, medium, and high. Reducing reasoning effort can result in faster responses and fewer
// tokens used on reasoning in a response.
type ReasoningEffortValue string

const (
	// ReasoningEffortValueHigh - The reasoning effort is high.
	ReasoningEffortValueHigh ReasoningEffortValue = "high"
	// ReasoningEffortValueLow - The reasoning effort is low.
	ReasoningEffortValueLow ReasoningEffortValue = "low"
	// ReasoningEffortValueMedium - The reasoning effort is medium.
	ReasoningEffortValueMedium ReasoningEffortValue = "medium"
)

// PossibleReasoningEffortValueValues returns the possible values for the ReasoningEffortValue const type.
func PossibleReasoningEffortValueValues() []ReasoningEffortValue {
	return []ReasoningEffortValue{
		ReasoningEffortValueHigh,
		ReasoningEffortValueLow,
		ReasoningEffortValueMedium,
	}
}

// SpeechGenerationResponseFormat - The audio output format for the spoken text. By default, the MP3 format will be used.
type SpeechGenerationResponseFormat string

const (
	// SpeechGenerationResponseFormatAac - Use AAC as the audio output format. AAC is optimized for digital audio compression
	// and is preferred by YouTube, Android, and iOS.
	SpeechGenerationResponseFormatAac SpeechGenerationResponseFormat = "aac"
	// SpeechGenerationResponseFormatFlac - Use FLAC as the audio output format. FLAC is a fully lossless format optimized for
	// maximum quality at the expense of size.
	SpeechGenerationResponseFormatFlac SpeechGenerationResponseFormat = "flac"
	// SpeechGenerationResponseFormatMp3 - Use MP3 as the audio output format. MP3 is the default, general-purpose format.
	SpeechGenerationResponseFormatMp3 SpeechGenerationResponseFormat = "mp3"
	// SpeechGenerationResponseFormatOpus - Use Opus as the audio output format. Opus is optimized for internet streaming and
	// low latency.
	SpeechGenerationResponseFormatOpus SpeechGenerationResponseFormat = "opus"
	// SpeechGenerationResponseFormatPcm - Use uncompressed PCM as the audio output format, which is similar to WAV but contains
	// raw samples in 24kHz (16-bit signed, low-endian), without the header.
	SpeechGenerationResponseFormatPcm SpeechGenerationResponseFormat = "pcm"
	// SpeechGenerationResponseFormatWav - Use uncompressed WAV as the audio output format, suitable for low-latency applications
	// to avoid decoding overhead.
	SpeechGenerationResponseFormatWav SpeechGenerationResponseFormat = "wav"
)

// PossibleSpeechGenerationResponseFormatValues returns the possible values for the SpeechGenerationResponseFormat const type.
func PossibleSpeechGenerationResponseFormatValues() []SpeechGenerationResponseFormat {
	return []SpeechGenerationResponseFormat{
		SpeechGenerationResponseFormatAac,
		SpeechGenerationResponseFormatFlac,
		SpeechGenerationResponseFormatMp3,
		SpeechGenerationResponseFormatOpus,
		SpeechGenerationResponseFormatPcm,
		SpeechGenerationResponseFormatWav,
	}
}

// SpeechVoice - The available voices for text-to-speech.
type SpeechVoice string

const (
	// SpeechVoiceAlloy - The Alloy voice.
	SpeechVoiceAlloy SpeechVoice = "alloy"
	// SpeechVoiceEcho - The Echo voice.
	SpeechVoiceEcho SpeechVoice = "echo"
	// SpeechVoiceFable - The Fable voice.
	SpeechVoiceFable SpeechVoice = "fable"
	// SpeechVoiceNova - The Nova voice.
	SpeechVoiceNova SpeechVoice = "nova"
	// SpeechVoiceOnyx - The Onyx voice.
	SpeechVoiceOnyx SpeechVoice = "onyx"
	// SpeechVoiceShimmer - The Shimmer voice.
	SpeechVoiceShimmer SpeechVoice = "shimmer"
)

// PossibleSpeechVoiceValues returns the possible values for the SpeechVoice const type.
func PossibleSpeechVoiceValues() []SpeechVoice {
	return []SpeechVoice{
		SpeechVoiceAlloy,
		SpeechVoiceEcho,
		SpeechVoiceFable,
		SpeechVoiceNova,
		SpeechVoiceOnyx,
		SpeechVoiceShimmer,
	}
}

// UploadPurpose - The intended purpose of the file.
type UploadPurpose string

const (
	UploadPurposeAssistants       UploadPurpose = "assistants"
	UploadPurposeAssistantsOutput UploadPurpose = "assistants_output"
	UploadPurposeBatch            UploadPurpose = "batch"
	UploadPurposeBatchOutput      UploadPurpose = "batch_output"
	UploadPurposeFineTune         UploadPurpose = "fine-tune"
	UploadPurposeFineTuneResults  UploadPurpose = "fine-tune-results"
	UploadPurposeVision           UploadPurpose = "vision"
)

// PossibleUploadPurposeValues returns the possible values for the UploadPurpose const type.
func PossibleUploadPurposeValues() []UploadPurpose {
	return []UploadPurpose{
		UploadPurposeAssistants,
		UploadPurposeAssistantsOutput,
		UploadPurposeBatch,
		UploadPurposeBatchOutput,
		UploadPurposeFineTune,
		UploadPurposeFineTuneResults,
		UploadPurposeVision,
	}
}

// UploadStatus - The status of the Upload.
type UploadStatus string

const (
	UploadStatusCancelled UploadStatus = "cancelled"
	UploadStatusCompleted UploadStatus = "completed"
	UploadStatusExpired   UploadStatus = "expired"
	UploadStatusPending   UploadStatus = "pending"
)

// PossibleUploadStatusValues returns the possible values for the UploadStatus const type.
func PossibleUploadStatusValues() []UploadStatus {
	return []UploadStatus{
		UploadStatusCancelled,
		UploadStatusCompleted,
		UploadStatusExpired,
		UploadStatusPending,
	}
}
