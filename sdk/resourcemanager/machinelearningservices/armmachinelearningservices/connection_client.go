// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License. See License.txt in the project root for license information.
// Code generated by Microsoft (R) AutoRest Code Generator. DO NOT EDIT.
// Changes may cause incorrect behavior and will be lost if the code is regenerated.

package armmachinelearningservices

import (
	"context"
	"errors"
	"github.com/Azure/azure-sdk-for-go/sdk/azcore"
	"github.com/Azure/azure-sdk-for-go/sdk/azcore/arm"
	"github.com/Azure/azure-sdk-for-go/sdk/azcore/policy"
	"github.com/Azure/azure-sdk-for-go/sdk/azcore/runtime"
	"net/http"
	"net/url"
	"strings"
)

// ConnectionClient contains the methods for the Connection group.
// Don't use this type directly, use NewConnectionClient() instead.
type ConnectionClient struct {
	internal       *arm.Client
	subscriptionID string
}

// NewConnectionClient creates a new instance of ConnectionClient with the specified values.
//   - subscriptionID - The ID of the target subscription.
//   - credential - used to authorize requests. Usually a credential from azidentity.
//   - options - Contains optional client configuration. Pass nil to accept the default values.
func NewConnectionClient(subscriptionID string, credential azcore.TokenCredential, options *arm.ClientOptions) (*ConnectionClient, error) {
	cl, err := arm.NewClient(moduleName, moduleVersion, credential, options)
	if err != nil {
		return nil, err
	}
	client := &ConnectionClient{
		subscriptionID: subscriptionID,
		internal:       cl,
	}
	return client, nil
}

// BeginCreateOrUpdateDeployment - Create or update Azure OpenAI connection deployment resource with the specified parameters
// If the operation fails it returns an *azcore.ResponseError type.
//
// Generated from API version 2025-10-01-preview
//   - resourceGroupName - The name of the resource group. The name is case insensitive.
//   - workspaceName - Azure Machine Learning Workspace Name
//   - connectionName - Friendly name of the workspace connection
//   - deploymentName - Name of the deployment resource
//   - body - deployment object
//   - options - ConnectionClientBeginCreateOrUpdateDeploymentOptions contains the optional parameters for the ConnectionClient.BeginCreateOrUpdateDeployment
//     method.
func (client *ConnectionClient) BeginCreateOrUpdateDeployment(ctx context.Context, resourceGroupName string, workspaceName string, connectionName string, deploymentName string, body EndpointDeploymentResourcePropertiesBasicResource, options *ConnectionClientBeginCreateOrUpdateDeploymentOptions) (*runtime.Poller[ConnectionClientCreateOrUpdateDeploymentResponse], error) {
	if options == nil || options.ResumeToken == "" {
		resp, err := client.createOrUpdateDeployment(ctx, resourceGroupName, workspaceName, connectionName, deploymentName, body, options)
		if err != nil {
			return nil, err
		}
		poller, err := runtime.NewPoller(resp, client.internal.Pipeline(), &runtime.NewPollerOptions[ConnectionClientCreateOrUpdateDeploymentResponse]{
			FinalStateVia: runtime.FinalStateViaLocation,
			Tracer:        client.internal.Tracer(),
		})
		return poller, err
	} else {
		return runtime.NewPollerFromResumeToken(options.ResumeToken, client.internal.Pipeline(), &runtime.NewPollerFromResumeTokenOptions[ConnectionClientCreateOrUpdateDeploymentResponse]{
			Tracer: client.internal.Tracer(),
		})
	}
}

// CreateOrUpdateDeployment - Create or update Azure OpenAI connection deployment resource with the specified parameters
// If the operation fails it returns an *azcore.ResponseError type.
//
// Generated from API version 2025-10-01-preview
func (client *ConnectionClient) createOrUpdateDeployment(ctx context.Context, resourceGroupName string, workspaceName string, connectionName string, deploymentName string, body EndpointDeploymentResourcePropertiesBasicResource, options *ConnectionClientBeginCreateOrUpdateDeploymentOptions) (*http.Response, error) {
	var err error
	const operationName = "ConnectionClient.BeginCreateOrUpdateDeployment"
	ctx = context.WithValue(ctx, runtime.CtxAPINameKey{}, operationName)
	ctx, endSpan := runtime.StartSpan(ctx, operationName, client.internal.Tracer(), nil)
	defer func() { endSpan(err) }()
	req, err := client.createOrUpdateDeploymentCreateRequest(ctx, resourceGroupName, workspaceName, connectionName, deploymentName, body, options)
	if err != nil {
		return nil, err
	}
	httpResp, err := client.internal.Pipeline().Do(req)
	if err != nil {
		return nil, err
	}
	if !runtime.HasStatusCode(httpResp, http.StatusOK, http.StatusCreated) {
		err = runtime.NewResponseError(httpResp)
		return nil, err
	}
	return httpResp, nil
}

// createOrUpdateDeploymentCreateRequest creates the CreateOrUpdateDeployment request.
func (client *ConnectionClient) createOrUpdateDeploymentCreateRequest(ctx context.Context, resourceGroupName string, workspaceName string, connectionName string, deploymentName string, body EndpointDeploymentResourcePropertiesBasicResource, options *ConnectionClientBeginCreateOrUpdateDeploymentOptions) (*policy.Request, error) {
	urlPath := "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/connections/{connectionName}/deployments/{deploymentName}"
	if client.subscriptionID == "" {
		return nil, errors.New("parameter client.subscriptionID cannot be empty")
	}
	urlPath = strings.ReplaceAll(urlPath, "{subscriptionId}", url.PathEscape(client.subscriptionID))
	if resourceGroupName == "" {
		return nil, errors.New("parameter resourceGroupName cannot be empty")
	}
	urlPath = strings.ReplaceAll(urlPath, "{resourceGroupName}", url.PathEscape(resourceGroupName))
	if workspaceName == "" {
		return nil, errors.New("parameter workspaceName cannot be empty")
	}
	urlPath = strings.ReplaceAll(urlPath, "{workspaceName}", url.PathEscape(workspaceName))
	if connectionName == "" {
		return nil, errors.New("parameter connectionName cannot be empty")
	}
	urlPath = strings.ReplaceAll(urlPath, "{connectionName}", url.PathEscape(connectionName))
	if deploymentName == "" {
		return nil, errors.New("parameter deploymentName cannot be empty")
	}
	urlPath = strings.ReplaceAll(urlPath, "{deploymentName}", url.PathEscape(deploymentName))
	req, err := runtime.NewRequest(ctx, http.MethodPut, runtime.JoinPaths(client.internal.Endpoint(), urlPath))
	if err != nil {
		return nil, err
	}
	reqQP := req.Raw().URL.Query()
	reqQP.Set("api-version", "2025-10-01-preview")
	if options != nil && options.ProxyAPIVersion != nil {
		reqQP.Set("proxy-api-version", *options.ProxyAPIVersion)
	}
	req.Raw().URL.RawQuery = reqQP.Encode()
	req.Raw().Header["Accept"] = []string{"application/json"}
	if err := runtime.MarshalAsJSON(req, body); err != nil {
		return nil, err
	}
	return req, nil
}

// BeginDeleteDeployment - Delete Azure OpenAI connection deployment resource by name
// If the operation fails it returns an *azcore.ResponseError type.
//
// Generated from API version 2025-10-01-preview
//   - resourceGroupName - The name of the resource group. The name is case insensitive.
//   - workspaceName - Azure Machine Learning Workspace Name
//   - connectionName - Friendly name of the workspace connection
//   - deploymentName - Name of the deployment resource
//   - options - ConnectionClientBeginDeleteDeploymentOptions contains the optional parameters for the ConnectionClient.BeginDeleteDeployment
//     method.
func (client *ConnectionClient) BeginDeleteDeployment(ctx context.Context, resourceGroupName string, workspaceName string, connectionName string, deploymentName string, options *ConnectionClientBeginDeleteDeploymentOptions) (*runtime.Poller[ConnectionClientDeleteDeploymentResponse], error) {
	if options == nil || options.ResumeToken == "" {
		resp, err := client.deleteDeployment(ctx, resourceGroupName, workspaceName, connectionName, deploymentName, options)
		if err != nil {
			return nil, err
		}
		poller, err := runtime.NewPoller(resp, client.internal.Pipeline(), &runtime.NewPollerOptions[ConnectionClientDeleteDeploymentResponse]{
			FinalStateVia: runtime.FinalStateViaLocation,
			Tracer:        client.internal.Tracer(),
		})
		return poller, err
	} else {
		return runtime.NewPollerFromResumeToken(options.ResumeToken, client.internal.Pipeline(), &runtime.NewPollerFromResumeTokenOptions[ConnectionClientDeleteDeploymentResponse]{
			Tracer: client.internal.Tracer(),
		})
	}
}

// DeleteDeployment - Delete Azure OpenAI connection deployment resource by name
// If the operation fails it returns an *azcore.ResponseError type.
//
// Generated from API version 2025-10-01-preview
func (client *ConnectionClient) deleteDeployment(ctx context.Context, resourceGroupName string, workspaceName string, connectionName string, deploymentName string, options *ConnectionClientBeginDeleteDeploymentOptions) (*http.Response, error) {
	var err error
	const operationName = "ConnectionClient.BeginDeleteDeployment"
	ctx = context.WithValue(ctx, runtime.CtxAPINameKey{}, operationName)
	ctx, endSpan := runtime.StartSpan(ctx, operationName, client.internal.Tracer(), nil)
	defer func() { endSpan(err) }()
	req, err := client.deleteDeploymentCreateRequest(ctx, resourceGroupName, workspaceName, connectionName, deploymentName, options)
	if err != nil {
		return nil, err
	}
	httpResp, err := client.internal.Pipeline().Do(req)
	if err != nil {
		return nil, err
	}
	if !runtime.HasStatusCode(httpResp, http.StatusAccepted, http.StatusNoContent) {
		err = runtime.NewResponseError(httpResp)
		return nil, err
	}
	return httpResp, nil
}

// deleteDeploymentCreateRequest creates the DeleteDeployment request.
func (client *ConnectionClient) deleteDeploymentCreateRequest(ctx context.Context, resourceGroupName string, workspaceName string, connectionName string, deploymentName string, options *ConnectionClientBeginDeleteDeploymentOptions) (*policy.Request, error) {
	urlPath := "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/connections/{connectionName}/deployments/{deploymentName}"
	if client.subscriptionID == "" {
		return nil, errors.New("parameter client.subscriptionID cannot be empty")
	}
	urlPath = strings.ReplaceAll(urlPath, "{subscriptionId}", url.PathEscape(client.subscriptionID))
	if resourceGroupName == "" {
		return nil, errors.New("parameter resourceGroupName cannot be empty")
	}
	urlPath = strings.ReplaceAll(urlPath, "{resourceGroupName}", url.PathEscape(resourceGroupName))
	if workspaceName == "" {
		return nil, errors.New("parameter workspaceName cannot be empty")
	}
	urlPath = strings.ReplaceAll(urlPath, "{workspaceName}", url.PathEscape(workspaceName))
	if connectionName == "" {
		return nil, errors.New("parameter connectionName cannot be empty")
	}
	urlPath = strings.ReplaceAll(urlPath, "{connectionName}", url.PathEscape(connectionName))
	if deploymentName == "" {
		return nil, errors.New("parameter deploymentName cannot be empty")
	}
	urlPath = strings.ReplaceAll(urlPath, "{deploymentName}", url.PathEscape(deploymentName))
	req, err := runtime.NewRequest(ctx, http.MethodDelete, runtime.JoinPaths(client.internal.Endpoint(), urlPath))
	if err != nil {
		return nil, err
	}
	reqQP := req.Raw().URL.Query()
	reqQP.Set("api-version", "2025-10-01-preview")
	if options != nil && options.ProxyAPIVersion != nil {
		reqQP.Set("proxy-api-version", *options.ProxyAPIVersion)
	}
	req.Raw().URL.RawQuery = reqQP.Encode()
	req.Raw().Header["Accept"] = []string{"application/json"}
	return req, nil
}

// GetAllModels - Get models under the Azure ML workspace for all Azure OpenAI connections that the user can deploy.
// If the operation fails it returns an *azcore.ResponseError type.
//
// Generated from API version 2025-10-01-preview
//   - resourceGroupName - The name of the resource group. The name is case insensitive.
//   - workspaceName - Azure Machine Learning Workspace Name
//   - options - ConnectionClientGetAllModelsOptions contains the optional parameters for the ConnectionClient.GetAllModels method.
func (client *ConnectionClient) GetAllModels(ctx context.Context, resourceGroupName string, workspaceName string, options *ConnectionClientGetAllModelsOptions) (ConnectionClientGetAllModelsResponse, error) {
	var err error
	const operationName = "ConnectionClient.GetAllModels"
	ctx = context.WithValue(ctx, runtime.CtxAPINameKey{}, operationName)
	ctx, endSpan := runtime.StartSpan(ctx, operationName, client.internal.Tracer(), nil)
	defer func() { endSpan(err) }()
	req, err := client.getAllModelsCreateRequest(ctx, resourceGroupName, workspaceName, options)
	if err != nil {
		return ConnectionClientGetAllModelsResponse{}, err
	}
	httpResp, err := client.internal.Pipeline().Do(req)
	if err != nil {
		return ConnectionClientGetAllModelsResponse{}, err
	}
	if !runtime.HasStatusCode(httpResp, http.StatusOK) {
		err = runtime.NewResponseError(httpResp)
		return ConnectionClientGetAllModelsResponse{}, err
	}
	resp, err := client.getAllModelsHandleResponse(httpResp)
	return resp, err
}

// getAllModelsCreateRequest creates the GetAllModels request.
func (client *ConnectionClient) getAllModelsCreateRequest(ctx context.Context, resourceGroupName string, workspaceName string, _ *ConnectionClientGetAllModelsOptions) (*policy.Request, error) {
	urlPath := "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/listConnectionModels"
	if client.subscriptionID == "" {
		return nil, errors.New("parameter client.subscriptionID cannot be empty")
	}
	urlPath = strings.ReplaceAll(urlPath, "{subscriptionId}", url.PathEscape(client.subscriptionID))
	if resourceGroupName == "" {
		return nil, errors.New("parameter resourceGroupName cannot be empty")
	}
	urlPath = strings.ReplaceAll(urlPath, "{resourceGroupName}", url.PathEscape(resourceGroupName))
	if workspaceName == "" {
		return nil, errors.New("parameter workspaceName cannot be empty")
	}
	urlPath = strings.ReplaceAll(urlPath, "{workspaceName}", url.PathEscape(workspaceName))
	req, err := runtime.NewRequest(ctx, http.MethodPost, runtime.JoinPaths(client.internal.Endpoint(), urlPath))
	if err != nil {
		return nil, err
	}
	reqQP := req.Raw().URL.Query()
	reqQP.Set("api-version", "2025-10-01-preview")
	req.Raw().URL.RawQuery = reqQP.Encode()
	req.Raw().Header["Accept"] = []string{"application/json"}
	return req, nil
}

// getAllModelsHandleResponse handles the GetAllModels response.
func (client *ConnectionClient) getAllModelsHandleResponse(resp *http.Response) (ConnectionClientGetAllModelsResponse, error) {
	result := ConnectionClientGetAllModelsResponse{}
	if err := runtime.UnmarshalAsJSON(resp, &result.EndpointModels); err != nil {
		return ConnectionClientGetAllModelsResponse{}, err
	}
	return result, nil
}

// GetDeployment - Get deployments under the Azure OpenAI connection by name.
// If the operation fails it returns an *azcore.ResponseError type.
//
// Generated from API version 2025-10-01-preview
//   - resourceGroupName - The name of the resource group. The name is case insensitive.
//   - workspaceName - Azure Machine Learning Workspace Name
//   - connectionName - Friendly name of the workspace connection
//   - deploymentName - Name of the deployment resource
//   - options - ConnectionClientGetDeploymentOptions contains the optional parameters for the ConnectionClient.GetDeployment
//     method.
func (client *ConnectionClient) GetDeployment(ctx context.Context, resourceGroupName string, workspaceName string, connectionName string, deploymentName string, options *ConnectionClientGetDeploymentOptions) (ConnectionClientGetDeploymentResponse, error) {
	var err error
	const operationName = "ConnectionClient.GetDeployment"
	ctx = context.WithValue(ctx, runtime.CtxAPINameKey{}, operationName)
	ctx, endSpan := runtime.StartSpan(ctx, operationName, client.internal.Tracer(), nil)
	defer func() { endSpan(err) }()
	req, err := client.getDeploymentCreateRequest(ctx, resourceGroupName, workspaceName, connectionName, deploymentName, options)
	if err != nil {
		return ConnectionClientGetDeploymentResponse{}, err
	}
	httpResp, err := client.internal.Pipeline().Do(req)
	if err != nil {
		return ConnectionClientGetDeploymentResponse{}, err
	}
	if !runtime.HasStatusCode(httpResp, http.StatusOK) {
		err = runtime.NewResponseError(httpResp)
		return ConnectionClientGetDeploymentResponse{}, err
	}
	resp, err := client.getDeploymentHandleResponse(httpResp)
	return resp, err
}

// getDeploymentCreateRequest creates the GetDeployment request.
func (client *ConnectionClient) getDeploymentCreateRequest(ctx context.Context, resourceGroupName string, workspaceName string, connectionName string, deploymentName string, _ *ConnectionClientGetDeploymentOptions) (*policy.Request, error) {
	urlPath := "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/connections/{connectionName}/deployments/{deploymentName}"
	if client.subscriptionID == "" {
		return nil, errors.New("parameter client.subscriptionID cannot be empty")
	}
	urlPath = strings.ReplaceAll(urlPath, "{subscriptionId}", url.PathEscape(client.subscriptionID))
	if resourceGroupName == "" {
		return nil, errors.New("parameter resourceGroupName cannot be empty")
	}
	urlPath = strings.ReplaceAll(urlPath, "{resourceGroupName}", url.PathEscape(resourceGroupName))
	if workspaceName == "" {
		return nil, errors.New("parameter workspaceName cannot be empty")
	}
	urlPath = strings.ReplaceAll(urlPath, "{workspaceName}", url.PathEscape(workspaceName))
	if connectionName == "" {
		return nil, errors.New("parameter connectionName cannot be empty")
	}
	urlPath = strings.ReplaceAll(urlPath, "{connectionName}", url.PathEscape(connectionName))
	if deploymentName == "" {
		return nil, errors.New("parameter deploymentName cannot be empty")
	}
	urlPath = strings.ReplaceAll(urlPath, "{deploymentName}", url.PathEscape(deploymentName))
	req, err := runtime.NewRequest(ctx, http.MethodGet, runtime.JoinPaths(client.internal.Endpoint(), urlPath))
	if err != nil {
		return nil, err
	}
	reqQP := req.Raw().URL.Query()
	reqQP.Set("api-version", "2025-10-01-preview")
	req.Raw().URL.RawQuery = reqQP.Encode()
	req.Raw().Header["Accept"] = []string{"application/json"}
	return req, nil
}

// getDeploymentHandleResponse handles the GetDeployment response.
func (client *ConnectionClient) getDeploymentHandleResponse(resp *http.Response) (ConnectionClientGetDeploymentResponse, error) {
	result := ConnectionClientGetDeploymentResponse{}
	if err := runtime.UnmarshalAsJSON(resp, &result.EndpointDeploymentResourcePropertiesBasicResource); err != nil {
		return ConnectionClientGetDeploymentResponse{}, err
	}
	return result, nil
}

// NewGetModelsPager - Get available models under the Azure OpenAI connection.
//
// Generated from API version 2025-10-01-preview
//   - resourceGroupName - The name of the resource group. The name is case insensitive.
//   - workspaceName - Azure Machine Learning Workspace Name
//   - connectionName - Friendly name of the workspace connection
//   - options - ConnectionClientGetModelsOptions contains the optional parameters for the ConnectionClient.NewGetModelsPager
//     method.
func (client *ConnectionClient) NewGetModelsPager(resourceGroupName string, workspaceName string, connectionName string, options *ConnectionClientGetModelsOptions) *runtime.Pager[ConnectionClientGetModelsResponse] {
	return runtime.NewPager(runtime.PagingHandler[ConnectionClientGetModelsResponse]{
		More: func(page ConnectionClientGetModelsResponse) bool {
			return page.NextLink != nil && len(*page.NextLink) > 0
		},
		Fetcher: func(ctx context.Context, page *ConnectionClientGetModelsResponse) (ConnectionClientGetModelsResponse, error) {
			ctx = context.WithValue(ctx, runtime.CtxAPINameKey{}, "ConnectionClient.NewGetModelsPager")
			nextLink := ""
			if page != nil {
				nextLink = *page.NextLink
			}
			resp, err := runtime.FetcherForNextLink(ctx, client.internal.Pipeline(), nextLink, func(ctx context.Context) (*policy.Request, error) {
				return client.getModelsCreateRequest(ctx, resourceGroupName, workspaceName, connectionName, options)
			}, nil)
			if err != nil {
				return ConnectionClientGetModelsResponse{}, err
			}
			return client.getModelsHandleResponse(resp)
		},
		Tracer: client.internal.Tracer(),
	})
}

// getModelsCreateRequest creates the GetModels request.
func (client *ConnectionClient) getModelsCreateRequest(ctx context.Context, resourceGroupName string, workspaceName string, connectionName string, options *ConnectionClientGetModelsOptions) (*policy.Request, error) {
	urlPath := "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/connections/{connectionName}/models"
	if client.subscriptionID == "" {
		return nil, errors.New("parameter client.subscriptionID cannot be empty")
	}
	urlPath = strings.ReplaceAll(urlPath, "{subscriptionId}", url.PathEscape(client.subscriptionID))
	if resourceGroupName == "" {
		return nil, errors.New("parameter resourceGroupName cannot be empty")
	}
	urlPath = strings.ReplaceAll(urlPath, "{resourceGroupName}", url.PathEscape(resourceGroupName))
	if workspaceName == "" {
		return nil, errors.New("parameter workspaceName cannot be empty")
	}
	urlPath = strings.ReplaceAll(urlPath, "{workspaceName}", url.PathEscape(workspaceName))
	if connectionName == "" {
		return nil, errors.New("parameter connectionName cannot be empty")
	}
	urlPath = strings.ReplaceAll(urlPath, "{connectionName}", url.PathEscape(connectionName))
	req, err := runtime.NewRequest(ctx, http.MethodGet, runtime.JoinPaths(client.internal.Endpoint(), urlPath))
	if err != nil {
		return nil, err
	}
	reqQP := req.Raw().URL.Query()
	reqQP.Set("api-version", "2025-10-01-preview")
	if options != nil && options.ProxyAPIVersion != nil {
		reqQP.Set("proxy-api-version", *options.ProxyAPIVersion)
	}
	req.Raw().URL.RawQuery = reqQP.Encode()
	req.Raw().Header["Accept"] = []string{"application/json"}
	return req, nil
}

// getModelsHandleResponse handles the GetModels response.
func (client *ConnectionClient) getModelsHandleResponse(resp *http.Response) (ConnectionClientGetModelsResponse, error) {
	result := ConnectionClientGetModelsResponse{}
	if err := runtime.UnmarshalAsJSON(resp, &result.EndpointModels); err != nil {
		return ConnectionClientGetModelsResponse{}, err
	}
	return result, nil
}

// NewListDeploymentsPager - Get all the deployments under the Azure OpenAI connection.
//
// Generated from API version 2025-10-01-preview
//   - resourceGroupName - The name of the resource group. The name is case insensitive.
//   - workspaceName - Azure Machine Learning Workspace Name
//   - connectionName - Friendly name of the workspace connection
//   - options - ConnectionClientListDeploymentsOptions contains the optional parameters for the ConnectionClient.NewListDeploymentsPager
//     method.
func (client *ConnectionClient) NewListDeploymentsPager(resourceGroupName string, workspaceName string, connectionName string, options *ConnectionClientListDeploymentsOptions) *runtime.Pager[ConnectionClientListDeploymentsResponse] {
	return runtime.NewPager(runtime.PagingHandler[ConnectionClientListDeploymentsResponse]{
		More: func(page ConnectionClientListDeploymentsResponse) bool {
			return page.NextLink != nil && len(*page.NextLink) > 0
		},
		Fetcher: func(ctx context.Context, page *ConnectionClientListDeploymentsResponse) (ConnectionClientListDeploymentsResponse, error) {
			ctx = context.WithValue(ctx, runtime.CtxAPINameKey{}, "ConnectionClient.NewListDeploymentsPager")
			nextLink := ""
			if page != nil {
				nextLink = *page.NextLink
			}
			resp, err := runtime.FetcherForNextLink(ctx, client.internal.Pipeline(), nextLink, func(ctx context.Context) (*policy.Request, error) {
				return client.listDeploymentsCreateRequest(ctx, resourceGroupName, workspaceName, connectionName, options)
			}, nil)
			if err != nil {
				return ConnectionClientListDeploymentsResponse{}, err
			}
			return client.listDeploymentsHandleResponse(resp)
		},
		Tracer: client.internal.Tracer(),
	})
}

// listDeploymentsCreateRequest creates the ListDeployments request.
func (client *ConnectionClient) listDeploymentsCreateRequest(ctx context.Context, resourceGroupName string, workspaceName string, connectionName string, options *ConnectionClientListDeploymentsOptions) (*policy.Request, error) {
	urlPath := "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/connections/{connectionName}/deployments"
	if client.subscriptionID == "" {
		return nil, errors.New("parameter client.subscriptionID cannot be empty")
	}
	urlPath = strings.ReplaceAll(urlPath, "{subscriptionId}", url.PathEscape(client.subscriptionID))
	if resourceGroupName == "" {
		return nil, errors.New("parameter resourceGroupName cannot be empty")
	}
	urlPath = strings.ReplaceAll(urlPath, "{resourceGroupName}", url.PathEscape(resourceGroupName))
	if workspaceName == "" {
		return nil, errors.New("parameter workspaceName cannot be empty")
	}
	urlPath = strings.ReplaceAll(urlPath, "{workspaceName}", url.PathEscape(workspaceName))
	if connectionName == "" {
		return nil, errors.New("parameter connectionName cannot be empty")
	}
	urlPath = strings.ReplaceAll(urlPath, "{connectionName}", url.PathEscape(connectionName))
	req, err := runtime.NewRequest(ctx, http.MethodGet, runtime.JoinPaths(client.internal.Endpoint(), urlPath))
	if err != nil {
		return nil, err
	}
	reqQP := req.Raw().URL.Query()
	reqQP.Set("api-version", "2025-10-01-preview")
	if options != nil && options.ProxyAPIVersion != nil {
		reqQP.Set("proxy-api-version", *options.ProxyAPIVersion)
	}
	req.Raw().URL.RawQuery = reqQP.Encode()
	req.Raw().Header["Accept"] = []string{"application/json"}
	return req, nil
}

// listDeploymentsHandleResponse handles the ListDeployments response.
func (client *ConnectionClient) listDeploymentsHandleResponse(resp *http.Response) (ConnectionClientListDeploymentsResponse, error) {
	result := ConnectionClientListDeploymentsResponse{}
	if err := runtime.UnmarshalAsJSON(resp, &result.EndpointDeploymentResourcePropertiesBasicResourceArmPaginatedResult); err != nil {
		return ConnectionClientListDeploymentsResponse{}, err
	}
	return result, nil
}
