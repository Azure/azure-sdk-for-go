package search

// Copyright (c) Microsoft and contributors.  All rights reserved.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
//
// See the License for the specific language governing permissions and
// limitations under the License.
//
// Code generated by Microsoft (R) AutoRest Code Generator.
// Changes may cause incorrect behavior and will be lost if the code is regenerated.

import (
	"encoding/json"
	"errors"
	"github.com/Azure/go-autorest/autorest"
	"github.com/Azure/go-autorest/autorest/date"
)

// CjkBigramTokenFilterScripts enumerates the values for cjk bigram token filter scripts.
type CjkBigramTokenFilterScripts string

const (
	// Han specifies the han state for cjk bigram token filter scripts.
	Han CjkBigramTokenFilterScripts = "han"
	// Hangul specifies the hangul state for cjk bigram token filter scripts.
	Hangul CjkBigramTokenFilterScripts = "hangul"
	// Hiragana specifies the hiragana state for cjk bigram token filter scripts.
	Hiragana CjkBigramTokenFilterScripts = "hiragana"
	// Katakana specifies the katakana state for cjk bigram token filter scripts.
	Katakana CjkBigramTokenFilterScripts = "katakana"
)

// EdgeNGramTokenFilterSide enumerates the values for edge n gram token filter side.
type EdgeNGramTokenFilterSide string

const (
	// Back specifies the back state for edge n gram token filter side.
	Back EdgeNGramTokenFilterSide = "back"
	// Front specifies the front state for edge n gram token filter side.
	Front EdgeNGramTokenFilterSide = "front"
)

// IndexActionType enumerates the values for index action type.
type IndexActionType string

const (
	// Delete specifies the delete state for index action type.
	Delete IndexActionType = "delete"
	// Merge specifies the merge state for index action type.
	Merge IndexActionType = "merge"
	// MergeOrUpload specifies the merge or upload state for index action type.
	MergeOrUpload IndexActionType = "mergeOrUpload"
	// Upload specifies the upload state for index action type.
	Upload IndexActionType = "upload"
)

// IndexerExecutionStatus enumerates the values for indexer execution status.
type IndexerExecutionStatus string

const (
	// InProgress specifies the in progress state for indexer execution status.
	InProgress IndexerExecutionStatus = "inProgress"
	// Reset specifies the reset state for indexer execution status.
	Reset IndexerExecutionStatus = "reset"
	// Success specifies the success state for indexer execution status.
	Success IndexerExecutionStatus = "success"
	// TransientFailure specifies the transient failure state for indexer execution status.
	TransientFailure IndexerExecutionStatus = "transientFailure"
)

// IndexerStatus enumerates the values for indexer status.
type IndexerStatus string

const (
	// Error specifies the error state for indexer status.
	Error IndexerStatus = "error"
	// Running specifies the running state for indexer status.
	Running IndexerStatus = "running"
	// Unknown specifies the unknown state for indexer status.
	Unknown IndexerStatus = "unknown"
)

// MicrosoftStemmingTokenizerLanguage enumerates the values for microsoft stemming tokenizer language.
type MicrosoftStemmingTokenizerLanguage string

const (
	// Arabic specifies the arabic state for microsoft stemming tokenizer language.
	Arabic MicrosoftStemmingTokenizerLanguage = "arabic"
	// Bangla specifies the bangla state for microsoft stemming tokenizer language.
	Bangla MicrosoftStemmingTokenizerLanguage = "bangla"
	// Bulgarian specifies the bulgarian state for microsoft stemming tokenizer language.
	Bulgarian MicrosoftStemmingTokenizerLanguage = "bulgarian"
	// Catalan specifies the catalan state for microsoft stemming tokenizer language.
	Catalan MicrosoftStemmingTokenizerLanguage = "catalan"
	// Croatian specifies the croatian state for microsoft stemming tokenizer language.
	Croatian MicrosoftStemmingTokenizerLanguage = "croatian"
	// Czech specifies the czech state for microsoft stemming tokenizer language.
	Czech MicrosoftStemmingTokenizerLanguage = "czech"
	// Danish specifies the danish state for microsoft stemming tokenizer language.
	Danish MicrosoftStemmingTokenizerLanguage = "danish"
	// Dutch specifies the dutch state for microsoft stemming tokenizer language.
	Dutch MicrosoftStemmingTokenizerLanguage = "dutch"
	// English specifies the english state for microsoft stemming tokenizer language.
	English MicrosoftStemmingTokenizerLanguage = "english"
	// Estonian specifies the estonian state for microsoft stemming tokenizer language.
	Estonian MicrosoftStemmingTokenizerLanguage = "estonian"
	// Finnish specifies the finnish state for microsoft stemming tokenizer language.
	Finnish MicrosoftStemmingTokenizerLanguage = "finnish"
	// French specifies the french state for microsoft stemming tokenizer language.
	French MicrosoftStemmingTokenizerLanguage = "french"
	// German specifies the german state for microsoft stemming tokenizer language.
	German MicrosoftStemmingTokenizerLanguage = "german"
	// Greek specifies the greek state for microsoft stemming tokenizer language.
	Greek MicrosoftStemmingTokenizerLanguage = "greek"
	// Gujarati specifies the gujarati state for microsoft stemming tokenizer language.
	Gujarati MicrosoftStemmingTokenizerLanguage = "gujarati"
	// Hebrew specifies the hebrew state for microsoft stemming tokenizer language.
	Hebrew MicrosoftStemmingTokenizerLanguage = "hebrew"
	// Hindi specifies the hindi state for microsoft stemming tokenizer language.
	Hindi MicrosoftStemmingTokenizerLanguage = "hindi"
	// Hungarian specifies the hungarian state for microsoft stemming tokenizer language.
	Hungarian MicrosoftStemmingTokenizerLanguage = "hungarian"
	// Icelandic specifies the icelandic state for microsoft stemming tokenizer language.
	Icelandic MicrosoftStemmingTokenizerLanguage = "icelandic"
	// Indonesian specifies the indonesian state for microsoft stemming tokenizer language.
	Indonesian MicrosoftStemmingTokenizerLanguage = "indonesian"
	// Italian specifies the italian state for microsoft stemming tokenizer language.
	Italian MicrosoftStemmingTokenizerLanguage = "italian"
	// Kannada specifies the kannada state for microsoft stemming tokenizer language.
	Kannada MicrosoftStemmingTokenizerLanguage = "kannada"
	// Latvian specifies the latvian state for microsoft stemming tokenizer language.
	Latvian MicrosoftStemmingTokenizerLanguage = "latvian"
	// Lithuanian specifies the lithuanian state for microsoft stemming tokenizer language.
	Lithuanian MicrosoftStemmingTokenizerLanguage = "lithuanian"
	// Malay specifies the malay state for microsoft stemming tokenizer language.
	Malay MicrosoftStemmingTokenizerLanguage = "malay"
	// Malayalam specifies the malayalam state for microsoft stemming tokenizer language.
	Malayalam MicrosoftStemmingTokenizerLanguage = "malayalam"
	// Marathi specifies the marathi state for microsoft stemming tokenizer language.
	Marathi MicrosoftStemmingTokenizerLanguage = "marathi"
	// NorwegianBokmaal specifies the norwegian bokmaal state for microsoft stemming tokenizer language.
	NorwegianBokmaal MicrosoftStemmingTokenizerLanguage = "norwegianBokmaal"
	// Polish specifies the polish state for microsoft stemming tokenizer language.
	Polish MicrosoftStemmingTokenizerLanguage = "polish"
	// Portuguese specifies the portuguese state for microsoft stemming tokenizer language.
	Portuguese MicrosoftStemmingTokenizerLanguage = "portuguese"
	// PortugueseBrazilian specifies the portuguese brazilian state for microsoft stemming tokenizer language.
	PortugueseBrazilian MicrosoftStemmingTokenizerLanguage = "portugueseBrazilian"
	// Punjabi specifies the punjabi state for microsoft stemming tokenizer language.
	Punjabi MicrosoftStemmingTokenizerLanguage = "punjabi"
	// Romanian specifies the romanian state for microsoft stemming tokenizer language.
	Romanian MicrosoftStemmingTokenizerLanguage = "romanian"
	// Russian specifies the russian state for microsoft stemming tokenizer language.
	Russian MicrosoftStemmingTokenizerLanguage = "russian"
	// SerbianCyrillic specifies the serbian cyrillic state for microsoft stemming tokenizer language.
	SerbianCyrillic MicrosoftStemmingTokenizerLanguage = "serbianCyrillic"
	// SerbianLatin specifies the serbian latin state for microsoft stemming tokenizer language.
	SerbianLatin MicrosoftStemmingTokenizerLanguage = "serbianLatin"
	// Slovak specifies the slovak state for microsoft stemming tokenizer language.
	Slovak MicrosoftStemmingTokenizerLanguage = "slovak"
	// Slovenian specifies the slovenian state for microsoft stemming tokenizer language.
	Slovenian MicrosoftStemmingTokenizerLanguage = "slovenian"
	// Spanish specifies the spanish state for microsoft stemming tokenizer language.
	Spanish MicrosoftStemmingTokenizerLanguage = "spanish"
	// Swedish specifies the swedish state for microsoft stemming tokenizer language.
	Swedish MicrosoftStemmingTokenizerLanguage = "swedish"
	// Tamil specifies the tamil state for microsoft stemming tokenizer language.
	Tamil MicrosoftStemmingTokenizerLanguage = "tamil"
	// Telugu specifies the telugu state for microsoft stemming tokenizer language.
	Telugu MicrosoftStemmingTokenizerLanguage = "telugu"
	// Turkish specifies the turkish state for microsoft stemming tokenizer language.
	Turkish MicrosoftStemmingTokenizerLanguage = "turkish"
	// Ukrainian specifies the ukrainian state for microsoft stemming tokenizer language.
	Ukrainian MicrosoftStemmingTokenizerLanguage = "ukrainian"
	// Urdu specifies the urdu state for microsoft stemming tokenizer language.
	Urdu MicrosoftStemmingTokenizerLanguage = "urdu"
)

// MicrosoftTokenizerLanguage enumerates the values for microsoft tokenizer language.
type MicrosoftTokenizerLanguage string

const (
	// MicrosoftTokenizerLanguageBangla specifies the microsoft tokenizer language bangla state for microsoft tokenizer
	// language.
	MicrosoftTokenizerLanguageBangla MicrosoftTokenizerLanguage = "bangla"
	// MicrosoftTokenizerLanguageBulgarian specifies the microsoft tokenizer language bulgarian state for microsoft
	// tokenizer language.
	MicrosoftTokenizerLanguageBulgarian MicrosoftTokenizerLanguage = "bulgarian"
	// MicrosoftTokenizerLanguageCatalan specifies the microsoft tokenizer language catalan state for microsoft tokenizer
	// language.
	MicrosoftTokenizerLanguageCatalan MicrosoftTokenizerLanguage = "catalan"
	// MicrosoftTokenizerLanguageChineseSimplified specifies the microsoft tokenizer language chinese simplified state for
	// microsoft tokenizer language.
	MicrosoftTokenizerLanguageChineseSimplified MicrosoftTokenizerLanguage = "chineseSimplified"
	// MicrosoftTokenizerLanguageChineseTraditional specifies the microsoft tokenizer language chinese traditional state
	// for microsoft tokenizer language.
	MicrosoftTokenizerLanguageChineseTraditional MicrosoftTokenizerLanguage = "chineseTraditional"
	// MicrosoftTokenizerLanguageCroatian specifies the microsoft tokenizer language croatian state for microsoft tokenizer
	// language.
	MicrosoftTokenizerLanguageCroatian MicrosoftTokenizerLanguage = "croatian"
	// MicrosoftTokenizerLanguageCzech specifies the microsoft tokenizer language czech state for microsoft tokenizer
	// language.
	MicrosoftTokenizerLanguageCzech MicrosoftTokenizerLanguage = "czech"
	// MicrosoftTokenizerLanguageDanish specifies the microsoft tokenizer language danish state for microsoft tokenizer
	// language.
	MicrosoftTokenizerLanguageDanish MicrosoftTokenizerLanguage = "danish"
	// MicrosoftTokenizerLanguageDutch specifies the microsoft tokenizer language dutch state for microsoft tokenizer
	// language.
	MicrosoftTokenizerLanguageDutch MicrosoftTokenizerLanguage = "dutch"
	// MicrosoftTokenizerLanguageEnglish specifies the microsoft tokenizer language english state for microsoft tokenizer
	// language.
	MicrosoftTokenizerLanguageEnglish MicrosoftTokenizerLanguage = "english"
	// MicrosoftTokenizerLanguageFrench specifies the microsoft tokenizer language french state for microsoft tokenizer
	// language.
	MicrosoftTokenizerLanguageFrench MicrosoftTokenizerLanguage = "french"
	// MicrosoftTokenizerLanguageGerman specifies the microsoft tokenizer language german state for microsoft tokenizer
	// language.
	MicrosoftTokenizerLanguageGerman MicrosoftTokenizerLanguage = "german"
	// MicrosoftTokenizerLanguageGreek specifies the microsoft tokenizer language greek state for microsoft tokenizer
	// language.
	MicrosoftTokenizerLanguageGreek MicrosoftTokenizerLanguage = "greek"
	// MicrosoftTokenizerLanguageGujarati specifies the microsoft tokenizer language gujarati state for microsoft tokenizer
	// language.
	MicrosoftTokenizerLanguageGujarati MicrosoftTokenizerLanguage = "gujarati"
	// MicrosoftTokenizerLanguageHindi specifies the microsoft tokenizer language hindi state for microsoft tokenizer
	// language.
	MicrosoftTokenizerLanguageHindi MicrosoftTokenizerLanguage = "hindi"
	// MicrosoftTokenizerLanguageIcelandic specifies the microsoft tokenizer language icelandic state for microsoft
	// tokenizer language.
	MicrosoftTokenizerLanguageIcelandic MicrosoftTokenizerLanguage = "icelandic"
	// MicrosoftTokenizerLanguageIndonesian specifies the microsoft tokenizer language indonesian state for microsoft
	// tokenizer language.
	MicrosoftTokenizerLanguageIndonesian MicrosoftTokenizerLanguage = "indonesian"
	// MicrosoftTokenizerLanguageItalian specifies the microsoft tokenizer language italian state for microsoft tokenizer
	// language.
	MicrosoftTokenizerLanguageItalian MicrosoftTokenizerLanguage = "italian"
	// MicrosoftTokenizerLanguageJapanese specifies the microsoft tokenizer language japanese state for microsoft tokenizer
	// language.
	MicrosoftTokenizerLanguageJapanese MicrosoftTokenizerLanguage = "japanese"
	// MicrosoftTokenizerLanguageKannada specifies the microsoft tokenizer language kannada state for microsoft tokenizer
	// language.
	MicrosoftTokenizerLanguageKannada MicrosoftTokenizerLanguage = "kannada"
	// MicrosoftTokenizerLanguageKorean specifies the microsoft tokenizer language korean state for microsoft tokenizer
	// language.
	MicrosoftTokenizerLanguageKorean MicrosoftTokenizerLanguage = "korean"
	// MicrosoftTokenizerLanguageMalay specifies the microsoft tokenizer language malay state for microsoft tokenizer
	// language.
	MicrosoftTokenizerLanguageMalay MicrosoftTokenizerLanguage = "malay"
	// MicrosoftTokenizerLanguageMalayalam specifies the microsoft tokenizer language malayalam state for microsoft
	// tokenizer language.
	MicrosoftTokenizerLanguageMalayalam MicrosoftTokenizerLanguage = "malayalam"
	// MicrosoftTokenizerLanguageMarathi specifies the microsoft tokenizer language marathi state for microsoft tokenizer
	// language.
	MicrosoftTokenizerLanguageMarathi MicrosoftTokenizerLanguage = "marathi"
	// MicrosoftTokenizerLanguageNorwegianBokmaal specifies the microsoft tokenizer language norwegian bokmaal state for
	// microsoft tokenizer language.
	MicrosoftTokenizerLanguageNorwegianBokmaal MicrosoftTokenizerLanguage = "norwegianBokmaal"
	// MicrosoftTokenizerLanguagePolish specifies the microsoft tokenizer language polish state for microsoft tokenizer
	// language.
	MicrosoftTokenizerLanguagePolish MicrosoftTokenizerLanguage = "polish"
	// MicrosoftTokenizerLanguagePortuguese specifies the microsoft tokenizer language portuguese state for microsoft
	// tokenizer language.
	MicrosoftTokenizerLanguagePortuguese MicrosoftTokenizerLanguage = "portuguese"
	// MicrosoftTokenizerLanguagePortugueseBrazilian specifies the microsoft tokenizer language portuguese brazilian state
	// for microsoft tokenizer language.
	MicrosoftTokenizerLanguagePortugueseBrazilian MicrosoftTokenizerLanguage = "portugueseBrazilian"
	// MicrosoftTokenizerLanguagePunjabi specifies the microsoft tokenizer language punjabi state for microsoft tokenizer
	// language.
	MicrosoftTokenizerLanguagePunjabi MicrosoftTokenizerLanguage = "punjabi"
	// MicrosoftTokenizerLanguageRomanian specifies the microsoft tokenizer language romanian state for microsoft tokenizer
	// language.
	MicrosoftTokenizerLanguageRomanian MicrosoftTokenizerLanguage = "romanian"
	// MicrosoftTokenizerLanguageRussian specifies the microsoft tokenizer language russian state for microsoft tokenizer
	// language.
	MicrosoftTokenizerLanguageRussian MicrosoftTokenizerLanguage = "russian"
	// MicrosoftTokenizerLanguageSerbianCyrillic specifies the microsoft tokenizer language serbian cyrillic state for
	// microsoft tokenizer language.
	MicrosoftTokenizerLanguageSerbianCyrillic MicrosoftTokenizerLanguage = "serbianCyrillic"
	// MicrosoftTokenizerLanguageSerbianLatin specifies the microsoft tokenizer language serbian latin state for microsoft
	// tokenizer language.
	MicrosoftTokenizerLanguageSerbianLatin MicrosoftTokenizerLanguage = "serbianLatin"
	// MicrosoftTokenizerLanguageSlovenian specifies the microsoft tokenizer language slovenian state for microsoft
	// tokenizer language.
	MicrosoftTokenizerLanguageSlovenian MicrosoftTokenizerLanguage = "slovenian"
	// MicrosoftTokenizerLanguageSpanish specifies the microsoft tokenizer language spanish state for microsoft tokenizer
	// language.
	MicrosoftTokenizerLanguageSpanish MicrosoftTokenizerLanguage = "spanish"
	// MicrosoftTokenizerLanguageSwedish specifies the microsoft tokenizer language swedish state for microsoft tokenizer
	// language.
	MicrosoftTokenizerLanguageSwedish MicrosoftTokenizerLanguage = "swedish"
	// MicrosoftTokenizerLanguageTamil specifies the microsoft tokenizer language tamil state for microsoft tokenizer
	// language.
	MicrosoftTokenizerLanguageTamil MicrosoftTokenizerLanguage = "tamil"
	// MicrosoftTokenizerLanguageTelugu specifies the microsoft tokenizer language telugu state for microsoft tokenizer
	// language.
	MicrosoftTokenizerLanguageTelugu MicrosoftTokenizerLanguage = "telugu"
	// MicrosoftTokenizerLanguageThai specifies the microsoft tokenizer language thai state for microsoft tokenizer
	// language.
	MicrosoftTokenizerLanguageThai MicrosoftTokenizerLanguage = "thai"
	// MicrosoftTokenizerLanguageUkrainian specifies the microsoft tokenizer language ukrainian state for microsoft
	// tokenizer language.
	MicrosoftTokenizerLanguageUkrainian MicrosoftTokenizerLanguage = "ukrainian"
	// MicrosoftTokenizerLanguageUrdu specifies the microsoft tokenizer language urdu state for microsoft tokenizer
	// language.
	MicrosoftTokenizerLanguageUrdu MicrosoftTokenizerLanguage = "urdu"
	// MicrosoftTokenizerLanguageVietnamese specifies the microsoft tokenizer language vietnamese state for microsoft
	// tokenizer language.
	MicrosoftTokenizerLanguageVietnamese MicrosoftTokenizerLanguage = "vietnamese"
)

// Mode enumerates the values for mode.
type Mode string

const (
	// All specifies the all state for mode.
	All Mode = "all"
	// Any specifies the any state for mode.
	Any Mode = "any"
)

// OdataType enumerates the values for odata type.
type OdataType string

const (
	// OdataTypeMicrosoftAzureSearchCustomAnalyzer specifies the odata type microsoft azure search custom analyzer state
	// for odata type.
	OdataTypeMicrosoftAzureSearchCustomAnalyzer OdataType = "#Microsoft.Azure.Search.CustomAnalyzer"
	// OdataTypeMicrosoftAzureSearchPatternAnalyzer specifies the odata type microsoft azure search pattern analyzer state
	// for odata type.
	OdataTypeMicrosoftAzureSearchPatternAnalyzer OdataType = "#Microsoft.Azure.Search.PatternAnalyzer"
	// OdataTypeMicrosoftAzureSearchStandardAnalyzer specifies the odata type microsoft azure search standard analyzer
	// state for odata type.
	OdataTypeMicrosoftAzureSearchStandardAnalyzer OdataType = "#Microsoft.Azure.Search.StandardAnalyzer"
	// OdataTypeMicrosoftAzureSearchStopAnalyzer specifies the odata type microsoft azure search stop analyzer state for
	// odata type.
	OdataTypeMicrosoftAzureSearchStopAnalyzer OdataType = "#Microsoft.Azure.Search.StopAnalyzer"
)

// OdataType1 enumerates the values for odata type 1.
type OdataType1 string

const (
	// OdataTypeMicrosoftAzureSearchClassicTokenizer specifies the odata type microsoft azure search classic tokenizer
	// state for odata type 1.
	OdataTypeMicrosoftAzureSearchClassicTokenizer OdataType1 = "#Microsoft.Azure.Search.ClassicTokenizer"
	// OdataTypeMicrosoftAzureSearchEdgeNGramTokenizer specifies the odata type microsoft azure search edge n gram
	// tokenizer state for odata type 1.
	OdataTypeMicrosoftAzureSearchEdgeNGramTokenizer OdataType1 = "#Microsoft.Azure.Search.EdgeNGramTokenizer"
	// OdataTypeMicrosoftAzureSearchKeywordTokenizer specifies the odata type microsoft azure search keyword tokenizer
	// state for odata type 1.
	OdataTypeMicrosoftAzureSearchKeywordTokenizer OdataType1 = "#Microsoft.Azure.Search.KeywordTokenizer"
	// OdataTypeMicrosoftAzureSearchKeywordTokenizerV2 specifies the odata type microsoft azure search keyword tokenizer v2
	// state for odata type 1.
	OdataTypeMicrosoftAzureSearchKeywordTokenizerV2 OdataType1 = "#Microsoft.Azure.Search.KeywordTokenizerV2"
	// OdataTypeMicrosoftAzureSearchMicrosoftLanguageStemmingTokenizer specifies the odata type microsoft azure search
	// microsoft language stemming tokenizer state for odata type 1.
	OdataTypeMicrosoftAzureSearchMicrosoftLanguageStemmingTokenizer OdataType1 = "#Microsoft.Azure.Search.MicrosoftLanguageStemmingTokenizer"
	// OdataTypeMicrosoftAzureSearchMicrosoftLanguageTokenizer specifies the odata type microsoft azure search microsoft
	// language tokenizer state for odata type 1.
	OdataTypeMicrosoftAzureSearchMicrosoftLanguageTokenizer OdataType1 = "#Microsoft.Azure.Search.MicrosoftLanguageTokenizer"
	// OdataTypeMicrosoftAzureSearchNGramTokenizer specifies the odata type microsoft azure search n gram tokenizer state
	// for odata type 1.
	OdataTypeMicrosoftAzureSearchNGramTokenizer OdataType1 = "#Microsoft.Azure.Search.NGramTokenizer"
	// OdataTypeMicrosoftAzureSearchPathHierarchyTokenizer specifies the odata type microsoft azure search path hierarchy
	// tokenizer state for odata type 1.
	OdataTypeMicrosoftAzureSearchPathHierarchyTokenizer OdataType1 = "#Microsoft.Azure.Search.PathHierarchyTokenizer"
	// OdataTypeMicrosoftAzureSearchPathHierarchyTokenizerV2 specifies the odata type microsoft azure search path hierarchy
	// tokenizer v2 state for odata type 1.
	OdataTypeMicrosoftAzureSearchPathHierarchyTokenizerV2 OdataType1 = "#Microsoft.Azure.Search.PathHierarchyTokenizerV2"
	// OdataTypeMicrosoftAzureSearchPatternTokenizer specifies the odata type microsoft azure search pattern tokenizer
	// state for odata type 1.
	OdataTypeMicrosoftAzureSearchPatternTokenizer OdataType1 = "#Microsoft.Azure.Search.PatternTokenizer"
	// OdataTypeMicrosoftAzureSearchStandardTokenizer specifies the odata type microsoft azure search standard tokenizer
	// state for odata type 1.
	OdataTypeMicrosoftAzureSearchStandardTokenizer OdataType1 = "#Microsoft.Azure.Search.StandardTokenizer"
	// OdataTypeMicrosoftAzureSearchStandardTokenizerV2 specifies the odata type microsoft azure search standard tokenizer
	// v2 state for odata type 1.
	OdataTypeMicrosoftAzureSearchStandardTokenizerV2 OdataType1 = "#Microsoft.Azure.Search.StandardTokenizerV2"
	// OdataTypeMicrosoftAzureSearchUaxURLEmailTokenizer specifies the odata type microsoft azure search uax url email
	// tokenizer state for odata type 1.
	OdataTypeMicrosoftAzureSearchUaxURLEmailTokenizer OdataType1 = "#Microsoft.Azure.Search.UaxUrlEmailTokenizer"
)

// OdataType2 enumerates the values for odata type 2.
type OdataType2 string

const (
	// OdataTypeMicrosoftAzureSearchASCIIFoldingTokenFilter specifies the odata type microsoft azure search ascii folding
	// token filter state for odata type 2.
	OdataTypeMicrosoftAzureSearchASCIIFoldingTokenFilter OdataType2 = "#Microsoft.Azure.Search.AsciiFoldingTokenFilter"
	// OdataTypeMicrosoftAzureSearchCjkBigramTokenFilter specifies the odata type microsoft azure search cjk bigram token
	// filter state for odata type 2.
	OdataTypeMicrosoftAzureSearchCjkBigramTokenFilter OdataType2 = "#Microsoft.Azure.Search.CjkBigramTokenFilter"
	// OdataTypeMicrosoftAzureSearchCommonGramTokenFilter specifies the odata type microsoft azure search common gram token
	// filter state for odata type 2.
	OdataTypeMicrosoftAzureSearchCommonGramTokenFilter OdataType2 = "#Microsoft.Azure.Search.CommonGramTokenFilter"
	// OdataTypeMicrosoftAzureSearchDictionaryDecompounderTokenFilter specifies the odata type microsoft azure search
	// dictionary decompounder token filter state for odata type 2.
	OdataTypeMicrosoftAzureSearchDictionaryDecompounderTokenFilter OdataType2 = "#Microsoft.Azure.Search.DictionaryDecompounderTokenFilter"
	// OdataTypeMicrosoftAzureSearchEdgeNGramTokenFilter specifies the odata type microsoft azure search edge n gram token
	// filter state for odata type 2.
	OdataTypeMicrosoftAzureSearchEdgeNGramTokenFilter OdataType2 = "#Microsoft.Azure.Search.EdgeNGramTokenFilter"
	// OdataTypeMicrosoftAzureSearchEdgeNGramTokenFilterV2 specifies the odata type microsoft azure search edge n gram
	// token filter v2 state for odata type 2.
	OdataTypeMicrosoftAzureSearchEdgeNGramTokenFilterV2 OdataType2 = "#Microsoft.Azure.Search.EdgeNGramTokenFilterV2"
	// OdataTypeMicrosoftAzureSearchElisionTokenFilter specifies the odata type microsoft azure search elision token filter
	// state for odata type 2.
	OdataTypeMicrosoftAzureSearchElisionTokenFilter OdataType2 = "#Microsoft.Azure.Search.ElisionTokenFilter"
	// OdataTypeMicrosoftAzureSearchKeepTokenFilter specifies the odata type microsoft azure search keep token filter state
	// for odata type 2.
	OdataTypeMicrosoftAzureSearchKeepTokenFilter OdataType2 = "#Microsoft.Azure.Search.KeepTokenFilter"
	// OdataTypeMicrosoftAzureSearchKeywordMarkerTokenFilter specifies the odata type microsoft azure search keyword marker
	// token filter state for odata type 2.
	OdataTypeMicrosoftAzureSearchKeywordMarkerTokenFilter OdataType2 = "#Microsoft.Azure.Search.KeywordMarkerTokenFilter"
	// OdataTypeMicrosoftAzureSearchLengthTokenFilter specifies the odata type microsoft azure search length token filter
	// state for odata type 2.
	OdataTypeMicrosoftAzureSearchLengthTokenFilter OdataType2 = "#Microsoft.Azure.Search.LengthTokenFilter"
	// OdataTypeMicrosoftAzureSearchLimitTokenFilter specifies the odata type microsoft azure search limit token filter
	// state for odata type 2.
	OdataTypeMicrosoftAzureSearchLimitTokenFilter OdataType2 = "#Microsoft.Azure.Search.LimitTokenFilter"
	// OdataTypeMicrosoftAzureSearchNGramTokenFilter specifies the odata type microsoft azure search n gram token filter
	// state for odata type 2.
	OdataTypeMicrosoftAzureSearchNGramTokenFilter OdataType2 = "#Microsoft.Azure.Search.NGramTokenFilter"
	// OdataTypeMicrosoftAzureSearchNGramTokenFilterV2 specifies the odata type microsoft azure search n gram token filter
	// v2 state for odata type 2.
	OdataTypeMicrosoftAzureSearchNGramTokenFilterV2 OdataType2 = "#Microsoft.Azure.Search.NGramTokenFilterV2"
	// OdataTypeMicrosoftAzureSearchPatternCaptureTokenFilter specifies the odata type microsoft azure search pattern
	// capture token filter state for odata type 2.
	OdataTypeMicrosoftAzureSearchPatternCaptureTokenFilter OdataType2 = "#Microsoft.Azure.Search.PatternCaptureTokenFilter"
	// OdataTypeMicrosoftAzureSearchPatternReplaceTokenFilter specifies the odata type microsoft azure search pattern
	// replace token filter state for odata type 2.
	OdataTypeMicrosoftAzureSearchPatternReplaceTokenFilter OdataType2 = "#Microsoft.Azure.Search.PatternReplaceTokenFilter"
	// OdataTypeMicrosoftAzureSearchPhoneticTokenFilter specifies the odata type microsoft azure search phonetic token
	// filter state for odata type 2.
	OdataTypeMicrosoftAzureSearchPhoneticTokenFilter OdataType2 = "#Microsoft.Azure.Search.PhoneticTokenFilter"
	// OdataTypeMicrosoftAzureSearchShingleTokenFilter specifies the odata type microsoft azure search shingle token filter
	// state for odata type 2.
	OdataTypeMicrosoftAzureSearchShingleTokenFilter OdataType2 = "#Microsoft.Azure.Search.ShingleTokenFilter"
	// OdataTypeMicrosoftAzureSearchSnowballTokenFilter specifies the odata type microsoft azure search snowball token
	// filter state for odata type 2.
	OdataTypeMicrosoftAzureSearchSnowballTokenFilter OdataType2 = "#Microsoft.Azure.Search.SnowballTokenFilter"
	// OdataTypeMicrosoftAzureSearchStemmerOverrideTokenFilter specifies the odata type microsoft azure search stemmer
	// override token filter state for odata type 2.
	OdataTypeMicrosoftAzureSearchStemmerOverrideTokenFilter OdataType2 = "#Microsoft.Azure.Search.StemmerOverrideTokenFilter"
	// OdataTypeMicrosoftAzureSearchStemmerTokenFilter specifies the odata type microsoft azure search stemmer token filter
	// state for odata type 2.
	OdataTypeMicrosoftAzureSearchStemmerTokenFilter OdataType2 = "#Microsoft.Azure.Search.StemmerTokenFilter"
	// OdataTypeMicrosoftAzureSearchStopwordsTokenFilter specifies the odata type microsoft azure search stopwords token
	// filter state for odata type 2.
	OdataTypeMicrosoftAzureSearchStopwordsTokenFilter OdataType2 = "#Microsoft.Azure.Search.StopwordsTokenFilter"
	// OdataTypeMicrosoftAzureSearchSynonymTokenFilter specifies the odata type microsoft azure search synonym token filter
	// state for odata type 2.
	OdataTypeMicrosoftAzureSearchSynonymTokenFilter OdataType2 = "#Microsoft.Azure.Search.SynonymTokenFilter"
	// OdataTypeMicrosoftAzureSearchTruncateTokenFilter specifies the odata type microsoft azure search truncate token
	// filter state for odata type 2.
	OdataTypeMicrosoftAzureSearchTruncateTokenFilter OdataType2 = "#Microsoft.Azure.Search.TruncateTokenFilter"
	// OdataTypeMicrosoftAzureSearchUniqueTokenFilter specifies the odata type microsoft azure search unique token filter
	// state for odata type 2.
	OdataTypeMicrosoftAzureSearchUniqueTokenFilter OdataType2 = "#Microsoft.Azure.Search.UniqueTokenFilter"
	// OdataTypeMicrosoftAzureSearchWordDelimiterTokenFilter specifies the odata type microsoft azure search word delimiter
	// token filter state for odata type 2.
	OdataTypeMicrosoftAzureSearchWordDelimiterTokenFilter OdataType2 = "#Microsoft.Azure.Search.WordDelimiterTokenFilter"
)

// OdataType3 enumerates the values for odata type 3.
type OdataType3 string

const (
	// OdataTypeMicrosoftAzureSearchMappingCharFilter specifies the odata type microsoft azure search mapping char filter
	// state for odata type 3.
	OdataTypeMicrosoftAzureSearchMappingCharFilter OdataType3 = "#Microsoft.Azure.Search.MappingCharFilter"
	// OdataTypeMicrosoftAzureSearchPatternReplaceCharFilter specifies the odata type microsoft azure search pattern
	// replace char filter state for odata type 3.
	OdataTypeMicrosoftAzureSearchPatternReplaceCharFilter OdataType3 = "#Microsoft.Azure.Search.PatternReplaceCharFilter"
)

// OdataType4 enumerates the values for odata type 4.
type OdataType4 string

const (
	// OdataTypeMicrosoftAzureSearchHighWaterMarkChangeDetectionPolicy specifies the odata type microsoft azure search high
	// water mark change detection policy state for odata type 4.
	OdataTypeMicrosoftAzureSearchHighWaterMarkChangeDetectionPolicy OdataType4 = "#Microsoft.Azure.Search.HighWaterMarkChangeDetectionPolicy"
	// OdataTypeMicrosoftAzureSearchSQLIntegratedChangeTrackingPolicy specifies the odata type microsoft azure search sql
	// integrated change tracking policy state for odata type 4.
	OdataTypeMicrosoftAzureSearchSQLIntegratedChangeTrackingPolicy OdataType4 = "#Microsoft.Azure.Search.SqlIntegratedChangeTrackingPolicy"
)

// OdataType5 enumerates the values for odata type 5.
type OdataType5 string

const (
	// OdataTypeMicrosoftAzureSearchSoftDeleteColumnDeletionDetectionPolicy specifies the odata type microsoft azure search
	// soft delete column deletion detection policy state for odata type 5.
	OdataTypeMicrosoftAzureSearchSoftDeleteColumnDeletionDetectionPolicy OdataType5 = "#Microsoft.Azure.Search.SoftDeleteColumnDeletionDetectionPolicy"
)

// PhoneticEncoder enumerates the values for phonetic encoder.
type PhoneticEncoder string

const (
	// BeiderMorse specifies the beider morse state for phonetic encoder.
	BeiderMorse PhoneticEncoder = "beiderMorse"
	// Caverphone1 specifies the caverphone 1 state for phonetic encoder.
	Caverphone1 PhoneticEncoder = "caverphone1"
	// Caverphone2 specifies the caverphone 2 state for phonetic encoder.
	Caverphone2 PhoneticEncoder = "caverphone2"
	// Cologne specifies the cologne state for phonetic encoder.
	Cologne PhoneticEncoder = "cologne"
	// DoubleMetaphone specifies the double metaphone state for phonetic encoder.
	DoubleMetaphone PhoneticEncoder = "doubleMetaphone"
	// HaasePhonetik specifies the haase phonetik state for phonetic encoder.
	HaasePhonetik PhoneticEncoder = "haasePhonetik"
	// KoelnerPhonetik specifies the koelner phonetik state for phonetic encoder.
	KoelnerPhonetik PhoneticEncoder = "koelnerPhonetik"
	// Metaphone specifies the metaphone state for phonetic encoder.
	Metaphone PhoneticEncoder = "metaphone"
	// Nysiis specifies the nysiis state for phonetic encoder.
	Nysiis PhoneticEncoder = "nysiis"
	// RefinedSoundex specifies the refined soundex state for phonetic encoder.
	RefinedSoundex PhoneticEncoder = "refinedSoundex"
	// Soundex specifies the soundex state for phonetic encoder.
	Soundex PhoneticEncoder = "soundex"
)

// QueryType enumerates the values for query type.
type QueryType string

const (
	// Full specifies the full state for query type.
	Full QueryType = "full"
	// Simple specifies the simple state for query type.
	Simple QueryType = "simple"
)

// ScoringFunctionAggregation enumerates the values for scoring function aggregation.
type ScoringFunctionAggregation string

const (
	// Average specifies the average state for scoring function aggregation.
	Average ScoringFunctionAggregation = "average"
	// FirstMatching specifies the first matching state for scoring function aggregation.
	FirstMatching ScoringFunctionAggregation = "firstMatching"
	// Maximum specifies the maximum state for scoring function aggregation.
	Maximum ScoringFunctionAggregation = "maximum"
	// Minimum specifies the minimum state for scoring function aggregation.
	Minimum ScoringFunctionAggregation = "minimum"
	// Sum specifies the sum state for scoring function aggregation.
	Sum ScoringFunctionAggregation = "sum"
)

// ScoringFunctionInterpolation enumerates the values for scoring function interpolation.
type ScoringFunctionInterpolation string

const (
	// Constant specifies the constant state for scoring function interpolation.
	Constant ScoringFunctionInterpolation = "constant"
	// Linear specifies the linear state for scoring function interpolation.
	Linear ScoringFunctionInterpolation = "linear"
	// Logarithmic specifies the logarithmic state for scoring function interpolation.
	Logarithmic ScoringFunctionInterpolation = "logarithmic"
	// Quadratic specifies the quadratic state for scoring function interpolation.
	Quadratic ScoringFunctionInterpolation = "quadratic"
)

// SnowballTokenFilterLanguage enumerates the values for snowball token filter language.
type SnowballTokenFilterLanguage string

const (
	// SnowballTokenFilterLanguageArmenian specifies the snowball token filter language armenian state for snowball token
	// filter language.
	SnowballTokenFilterLanguageArmenian SnowballTokenFilterLanguage = "armenian"
	// SnowballTokenFilterLanguageBasque specifies the snowball token filter language basque state for snowball token
	// filter language.
	SnowballTokenFilterLanguageBasque SnowballTokenFilterLanguage = "basque"
	// SnowballTokenFilterLanguageCatalan specifies the snowball token filter language catalan state for snowball token
	// filter language.
	SnowballTokenFilterLanguageCatalan SnowballTokenFilterLanguage = "catalan"
	// SnowballTokenFilterLanguageDanish specifies the snowball token filter language danish state for snowball token
	// filter language.
	SnowballTokenFilterLanguageDanish SnowballTokenFilterLanguage = "danish"
	// SnowballTokenFilterLanguageDutch specifies the snowball token filter language dutch state for snowball token filter
	// language.
	SnowballTokenFilterLanguageDutch SnowballTokenFilterLanguage = "dutch"
	// SnowballTokenFilterLanguageEnglish specifies the snowball token filter language english state for snowball token
	// filter language.
	SnowballTokenFilterLanguageEnglish SnowballTokenFilterLanguage = "english"
	// SnowballTokenFilterLanguageFinnish specifies the snowball token filter language finnish state for snowball token
	// filter language.
	SnowballTokenFilterLanguageFinnish SnowballTokenFilterLanguage = "finnish"
	// SnowballTokenFilterLanguageFrench specifies the snowball token filter language french state for snowball token
	// filter language.
	SnowballTokenFilterLanguageFrench SnowballTokenFilterLanguage = "french"
	// SnowballTokenFilterLanguageGerman specifies the snowball token filter language german state for snowball token
	// filter language.
	SnowballTokenFilterLanguageGerman SnowballTokenFilterLanguage = "german"
	// SnowballTokenFilterLanguageGerman2 specifies the snowball token filter language german 2 state for snowball token
	// filter language.
	SnowballTokenFilterLanguageGerman2 SnowballTokenFilterLanguage = "german2"
	// SnowballTokenFilterLanguageHungarian specifies the snowball token filter language hungarian state for snowball token
	// filter language.
	SnowballTokenFilterLanguageHungarian SnowballTokenFilterLanguage = "hungarian"
	// SnowballTokenFilterLanguageItalian specifies the snowball token filter language italian state for snowball token
	// filter language.
	SnowballTokenFilterLanguageItalian SnowballTokenFilterLanguage = "italian"
	// SnowballTokenFilterLanguageKp specifies the snowball token filter language kp state for snowball token filter
	// language.
	SnowballTokenFilterLanguageKp SnowballTokenFilterLanguage = "kp"
	// SnowballTokenFilterLanguageLovins specifies the snowball token filter language lovins state for snowball token
	// filter language.
	SnowballTokenFilterLanguageLovins SnowballTokenFilterLanguage = "lovins"
	// SnowballTokenFilterLanguageNorwegian specifies the snowball token filter language norwegian state for snowball token
	// filter language.
	SnowballTokenFilterLanguageNorwegian SnowballTokenFilterLanguage = "norwegian"
	// SnowballTokenFilterLanguagePorter specifies the snowball token filter language porter state for snowball token
	// filter language.
	SnowballTokenFilterLanguagePorter SnowballTokenFilterLanguage = "porter"
	// SnowballTokenFilterLanguagePortuguese specifies the snowball token filter language portuguese state for snowball
	// token filter language.
	SnowballTokenFilterLanguagePortuguese SnowballTokenFilterLanguage = "portuguese"
	// SnowballTokenFilterLanguageRomanian specifies the snowball token filter language romanian state for snowball token
	// filter language.
	SnowballTokenFilterLanguageRomanian SnowballTokenFilterLanguage = "romanian"
	// SnowballTokenFilterLanguageRussian specifies the snowball token filter language russian state for snowball token
	// filter language.
	SnowballTokenFilterLanguageRussian SnowballTokenFilterLanguage = "russian"
	// SnowballTokenFilterLanguageSpanish specifies the snowball token filter language spanish state for snowball token
	// filter language.
	SnowballTokenFilterLanguageSpanish SnowballTokenFilterLanguage = "spanish"
	// SnowballTokenFilterLanguageSwedish specifies the snowball token filter language swedish state for snowball token
	// filter language.
	SnowballTokenFilterLanguageSwedish SnowballTokenFilterLanguage = "swedish"
	// SnowballTokenFilterLanguageTurkish specifies the snowball token filter language turkish state for snowball token
	// filter language.
	SnowballTokenFilterLanguageTurkish SnowballTokenFilterLanguage = "turkish"
)

// StemmerTokenFilterLanguage enumerates the values for stemmer token filter language.
type StemmerTokenFilterLanguage string

const (
	// StemmerTokenFilterLanguageArabic specifies the stemmer token filter language arabic state for stemmer token filter
	// language.
	StemmerTokenFilterLanguageArabic StemmerTokenFilterLanguage = "arabic"
	// StemmerTokenFilterLanguageArmenian specifies the stemmer token filter language armenian state for stemmer token
	// filter language.
	StemmerTokenFilterLanguageArmenian StemmerTokenFilterLanguage = "armenian"
	// StemmerTokenFilterLanguageBasque specifies the stemmer token filter language basque state for stemmer token filter
	// language.
	StemmerTokenFilterLanguageBasque StemmerTokenFilterLanguage = "basque"
	// StemmerTokenFilterLanguageBrazilian specifies the stemmer token filter language brazilian state for stemmer token
	// filter language.
	StemmerTokenFilterLanguageBrazilian StemmerTokenFilterLanguage = "brazilian"
	// StemmerTokenFilterLanguageBulgarian specifies the stemmer token filter language bulgarian state for stemmer token
	// filter language.
	StemmerTokenFilterLanguageBulgarian StemmerTokenFilterLanguage = "bulgarian"
	// StemmerTokenFilterLanguageCatalan specifies the stemmer token filter language catalan state for stemmer token filter
	// language.
	StemmerTokenFilterLanguageCatalan StemmerTokenFilterLanguage = "catalan"
	// StemmerTokenFilterLanguageCzech specifies the stemmer token filter language czech state for stemmer token filter
	// language.
	StemmerTokenFilterLanguageCzech StemmerTokenFilterLanguage = "czech"
	// StemmerTokenFilterLanguageDanish specifies the stemmer token filter language danish state for stemmer token filter
	// language.
	StemmerTokenFilterLanguageDanish StemmerTokenFilterLanguage = "danish"
	// StemmerTokenFilterLanguageDutch specifies the stemmer token filter language dutch state for stemmer token filter
	// language.
	StemmerTokenFilterLanguageDutch StemmerTokenFilterLanguage = "dutch"
	// StemmerTokenFilterLanguageDutchKp specifies the stemmer token filter language dutch kp state for stemmer token
	// filter language.
	StemmerTokenFilterLanguageDutchKp StemmerTokenFilterLanguage = "dutchKp"
	// StemmerTokenFilterLanguageEnglish specifies the stemmer token filter language english state for stemmer token filter
	// language.
	StemmerTokenFilterLanguageEnglish StemmerTokenFilterLanguage = "english"
	// StemmerTokenFilterLanguageFinnish specifies the stemmer token filter language finnish state for stemmer token filter
	// language.
	StemmerTokenFilterLanguageFinnish StemmerTokenFilterLanguage = "finnish"
	// StemmerTokenFilterLanguageFrench specifies the stemmer token filter language french state for stemmer token filter
	// language.
	StemmerTokenFilterLanguageFrench StemmerTokenFilterLanguage = "french"
	// StemmerTokenFilterLanguageGalician specifies the stemmer token filter language galician state for stemmer token
	// filter language.
	StemmerTokenFilterLanguageGalician StemmerTokenFilterLanguage = "galician"
	// StemmerTokenFilterLanguageGerman specifies the stemmer token filter language german state for stemmer token filter
	// language.
	StemmerTokenFilterLanguageGerman StemmerTokenFilterLanguage = "german"
	// StemmerTokenFilterLanguageGerman2 specifies the stemmer token filter language german 2 state for stemmer token
	// filter language.
	StemmerTokenFilterLanguageGerman2 StemmerTokenFilterLanguage = "german2"
	// StemmerTokenFilterLanguageGreek specifies the stemmer token filter language greek state for stemmer token filter
	// language.
	StemmerTokenFilterLanguageGreek StemmerTokenFilterLanguage = "greek"
	// StemmerTokenFilterLanguageHindi specifies the stemmer token filter language hindi state for stemmer token filter
	// language.
	StemmerTokenFilterLanguageHindi StemmerTokenFilterLanguage = "hindi"
	// StemmerTokenFilterLanguageHungarian specifies the stemmer token filter language hungarian state for stemmer token
	// filter language.
	StemmerTokenFilterLanguageHungarian StemmerTokenFilterLanguage = "hungarian"
	// StemmerTokenFilterLanguageIndonesian specifies the stemmer token filter language indonesian state for stemmer token
	// filter language.
	StemmerTokenFilterLanguageIndonesian StemmerTokenFilterLanguage = "indonesian"
	// StemmerTokenFilterLanguageIrish specifies the stemmer token filter language irish state for stemmer token filter
	// language.
	StemmerTokenFilterLanguageIrish StemmerTokenFilterLanguage = "irish"
	// StemmerTokenFilterLanguageItalian specifies the stemmer token filter language italian state for stemmer token filter
	// language.
	StemmerTokenFilterLanguageItalian StemmerTokenFilterLanguage = "italian"
	// StemmerTokenFilterLanguageLatvian specifies the stemmer token filter language latvian state for stemmer token filter
	// language.
	StemmerTokenFilterLanguageLatvian StemmerTokenFilterLanguage = "latvian"
	// StemmerTokenFilterLanguageLightEnglish specifies the stemmer token filter language light english state for stemmer
	// token filter language.
	StemmerTokenFilterLanguageLightEnglish StemmerTokenFilterLanguage = "lightEnglish"
	// StemmerTokenFilterLanguageLightFinnish specifies the stemmer token filter language light finnish state for stemmer
	// token filter language.
	StemmerTokenFilterLanguageLightFinnish StemmerTokenFilterLanguage = "lightFinnish"
	// StemmerTokenFilterLanguageLightFrench specifies the stemmer token filter language light french state for stemmer
	// token filter language.
	StemmerTokenFilterLanguageLightFrench StemmerTokenFilterLanguage = "lightFrench"
	// StemmerTokenFilterLanguageLightGerman specifies the stemmer token filter language light german state for stemmer
	// token filter language.
	StemmerTokenFilterLanguageLightGerman StemmerTokenFilterLanguage = "lightGerman"
	// StemmerTokenFilterLanguageLightHungarian specifies the stemmer token filter language light hungarian state for
	// stemmer token filter language.
	StemmerTokenFilterLanguageLightHungarian StemmerTokenFilterLanguage = "lightHungarian"
	// StemmerTokenFilterLanguageLightItalian specifies the stemmer token filter language light italian state for stemmer
	// token filter language.
	StemmerTokenFilterLanguageLightItalian StemmerTokenFilterLanguage = "lightItalian"
	// StemmerTokenFilterLanguageLightNorwegian specifies the stemmer token filter language light norwegian state for
	// stemmer token filter language.
	StemmerTokenFilterLanguageLightNorwegian StemmerTokenFilterLanguage = "lightNorwegian"
	// StemmerTokenFilterLanguageLightNynorsk specifies the stemmer token filter language light nynorsk state for stemmer
	// token filter language.
	StemmerTokenFilterLanguageLightNynorsk StemmerTokenFilterLanguage = "lightNynorsk"
	// StemmerTokenFilterLanguageLightPortuguese specifies the stemmer token filter language light portuguese state for
	// stemmer token filter language.
	StemmerTokenFilterLanguageLightPortuguese StemmerTokenFilterLanguage = "lightPortuguese"
	// StemmerTokenFilterLanguageLightRussian specifies the stemmer token filter language light russian state for stemmer
	// token filter language.
	StemmerTokenFilterLanguageLightRussian StemmerTokenFilterLanguage = "lightRussian"
	// StemmerTokenFilterLanguageLightSpanish specifies the stemmer token filter language light spanish state for stemmer
	// token filter language.
	StemmerTokenFilterLanguageLightSpanish StemmerTokenFilterLanguage = "lightSpanish"
	// StemmerTokenFilterLanguageLightSwedish specifies the stemmer token filter language light swedish state for stemmer
	// token filter language.
	StemmerTokenFilterLanguageLightSwedish StemmerTokenFilterLanguage = "lightSwedish"
	// StemmerTokenFilterLanguageLovins specifies the stemmer token filter language lovins state for stemmer token filter
	// language.
	StemmerTokenFilterLanguageLovins StemmerTokenFilterLanguage = "lovins"
	// StemmerTokenFilterLanguageMinimalEnglish specifies the stemmer token filter language minimal english state for
	// stemmer token filter language.
	StemmerTokenFilterLanguageMinimalEnglish StemmerTokenFilterLanguage = "minimalEnglish"
	// StemmerTokenFilterLanguageMinimalFrench specifies the stemmer token filter language minimal french state for stemmer
	// token filter language.
	StemmerTokenFilterLanguageMinimalFrench StemmerTokenFilterLanguage = "minimalFrench"
	// StemmerTokenFilterLanguageMinimalGalician specifies the stemmer token filter language minimal galician state for
	// stemmer token filter language.
	StemmerTokenFilterLanguageMinimalGalician StemmerTokenFilterLanguage = "minimalGalician"
	// StemmerTokenFilterLanguageMinimalGerman specifies the stemmer token filter language minimal german state for stemmer
	// token filter language.
	StemmerTokenFilterLanguageMinimalGerman StemmerTokenFilterLanguage = "minimalGerman"
	// StemmerTokenFilterLanguageMinimalNorwegian specifies the stemmer token filter language minimal norwegian state for
	// stemmer token filter language.
	StemmerTokenFilterLanguageMinimalNorwegian StemmerTokenFilterLanguage = "minimalNorwegian"
	// StemmerTokenFilterLanguageMinimalNynorsk specifies the stemmer token filter language minimal nynorsk state for
	// stemmer token filter language.
	StemmerTokenFilterLanguageMinimalNynorsk StemmerTokenFilterLanguage = "minimalNynorsk"
	// StemmerTokenFilterLanguageMinimalPortuguese specifies the stemmer token filter language minimal portuguese state for
	// stemmer token filter language.
	StemmerTokenFilterLanguageMinimalPortuguese StemmerTokenFilterLanguage = "minimalPortuguese"
	// StemmerTokenFilterLanguageNorwegian specifies the stemmer token filter language norwegian state for stemmer token
	// filter language.
	StemmerTokenFilterLanguageNorwegian StemmerTokenFilterLanguage = "norwegian"
	// StemmerTokenFilterLanguagePorter2 specifies the stemmer token filter language porter 2 state for stemmer token
	// filter language.
	StemmerTokenFilterLanguagePorter2 StemmerTokenFilterLanguage = "porter2"
	// StemmerTokenFilterLanguagePortuguese specifies the stemmer token filter language portuguese state for stemmer token
	// filter language.
	StemmerTokenFilterLanguagePortuguese StemmerTokenFilterLanguage = "portuguese"
	// StemmerTokenFilterLanguagePortugueseRslp specifies the stemmer token filter language portuguese rslp state for
	// stemmer token filter language.
	StemmerTokenFilterLanguagePortugueseRslp StemmerTokenFilterLanguage = "portugueseRslp"
	// StemmerTokenFilterLanguagePossessiveEnglish specifies the stemmer token filter language possessive english state for
	// stemmer token filter language.
	StemmerTokenFilterLanguagePossessiveEnglish StemmerTokenFilterLanguage = "possessiveEnglish"
	// StemmerTokenFilterLanguageRomanian specifies the stemmer token filter language romanian state for stemmer token
	// filter language.
	StemmerTokenFilterLanguageRomanian StemmerTokenFilterLanguage = "romanian"
	// StemmerTokenFilterLanguageRussian specifies the stemmer token filter language russian state for stemmer token filter
	// language.
	StemmerTokenFilterLanguageRussian StemmerTokenFilterLanguage = "russian"
	// StemmerTokenFilterLanguageSorani specifies the stemmer token filter language sorani state for stemmer token filter
	// language.
	StemmerTokenFilterLanguageSorani StemmerTokenFilterLanguage = "sorani"
	// StemmerTokenFilterLanguageSpanish specifies the stemmer token filter language spanish state for stemmer token filter
	// language.
	StemmerTokenFilterLanguageSpanish StemmerTokenFilterLanguage = "spanish"
	// StemmerTokenFilterLanguageSwedish specifies the stemmer token filter language swedish state for stemmer token filter
	// language.
	StemmerTokenFilterLanguageSwedish StemmerTokenFilterLanguage = "swedish"
	// StemmerTokenFilterLanguageTurkish specifies the stemmer token filter language turkish state for stemmer token filter
	// language.
	StemmerTokenFilterLanguageTurkish StemmerTokenFilterLanguage = "turkish"
)

// StopwordsList enumerates the values for stopwords list.
type StopwordsList string

const (
	// StopwordsListArabic specifies the stopwords list arabic state for stopwords list.
	StopwordsListArabic StopwordsList = "arabic"
	// StopwordsListArmenian specifies the stopwords list armenian state for stopwords list.
	StopwordsListArmenian StopwordsList = "armenian"
	// StopwordsListBasque specifies the stopwords list basque state for stopwords list.
	StopwordsListBasque StopwordsList = "basque"
	// StopwordsListBrazilian specifies the stopwords list brazilian state for stopwords list.
	StopwordsListBrazilian StopwordsList = "brazilian"
	// StopwordsListBulgarian specifies the stopwords list bulgarian state for stopwords list.
	StopwordsListBulgarian StopwordsList = "bulgarian"
	// StopwordsListCatalan specifies the stopwords list catalan state for stopwords list.
	StopwordsListCatalan StopwordsList = "catalan"
	// StopwordsListCzech specifies the stopwords list czech state for stopwords list.
	StopwordsListCzech StopwordsList = "czech"
	// StopwordsListDanish specifies the stopwords list danish state for stopwords list.
	StopwordsListDanish StopwordsList = "danish"
	// StopwordsListDutch specifies the stopwords list dutch state for stopwords list.
	StopwordsListDutch StopwordsList = "dutch"
	// StopwordsListEnglish specifies the stopwords list english state for stopwords list.
	StopwordsListEnglish StopwordsList = "english"
	// StopwordsListFinnish specifies the stopwords list finnish state for stopwords list.
	StopwordsListFinnish StopwordsList = "finnish"
	// StopwordsListFrench specifies the stopwords list french state for stopwords list.
	StopwordsListFrench StopwordsList = "french"
	// StopwordsListGalician specifies the stopwords list galician state for stopwords list.
	StopwordsListGalician StopwordsList = "galician"
	// StopwordsListGerman specifies the stopwords list german state for stopwords list.
	StopwordsListGerman StopwordsList = "german"
	// StopwordsListGreek specifies the stopwords list greek state for stopwords list.
	StopwordsListGreek StopwordsList = "greek"
	// StopwordsListHindi specifies the stopwords list hindi state for stopwords list.
	StopwordsListHindi StopwordsList = "hindi"
	// StopwordsListHungarian specifies the stopwords list hungarian state for stopwords list.
	StopwordsListHungarian StopwordsList = "hungarian"
	// StopwordsListIndonesian specifies the stopwords list indonesian state for stopwords list.
	StopwordsListIndonesian StopwordsList = "indonesian"
	// StopwordsListIrish specifies the stopwords list irish state for stopwords list.
	StopwordsListIrish StopwordsList = "irish"
	// StopwordsListItalian specifies the stopwords list italian state for stopwords list.
	StopwordsListItalian StopwordsList = "italian"
	// StopwordsListLatvian specifies the stopwords list latvian state for stopwords list.
	StopwordsListLatvian StopwordsList = "latvian"
	// StopwordsListNorwegian specifies the stopwords list norwegian state for stopwords list.
	StopwordsListNorwegian StopwordsList = "norwegian"
	// StopwordsListPersian specifies the stopwords list persian state for stopwords list.
	StopwordsListPersian StopwordsList = "persian"
	// StopwordsListPortuguese specifies the stopwords list portuguese state for stopwords list.
	StopwordsListPortuguese StopwordsList = "portuguese"
	// StopwordsListRomanian specifies the stopwords list romanian state for stopwords list.
	StopwordsListRomanian StopwordsList = "romanian"
	// StopwordsListRussian specifies the stopwords list russian state for stopwords list.
	StopwordsListRussian StopwordsList = "russian"
	// StopwordsListSorani specifies the stopwords list sorani state for stopwords list.
	StopwordsListSorani StopwordsList = "sorani"
	// StopwordsListSpanish specifies the stopwords list spanish state for stopwords list.
	StopwordsListSpanish StopwordsList = "spanish"
	// StopwordsListSwedish specifies the stopwords list swedish state for stopwords list.
	StopwordsListSwedish StopwordsList = "swedish"
	// StopwordsListThai specifies the stopwords list thai state for stopwords list.
	StopwordsListThai StopwordsList = "thai"
	// StopwordsListTurkish specifies the stopwords list turkish state for stopwords list.
	StopwordsListTurkish StopwordsList = "turkish"
)

// SuggesterSearchMode enumerates the values for suggester search mode.
type SuggesterSearchMode string

const (
	// AnalyzingInfixMatching specifies the analyzing infix matching state for suggester search mode.
	AnalyzingInfixMatching SuggesterSearchMode = "analyzingInfixMatching"
)

// TokenCharacterKind enumerates the values for token character kind.
type TokenCharacterKind string

const (
	// Digit specifies the digit state for token character kind.
	Digit TokenCharacterKind = "digit"
	// Letter specifies the letter state for token character kind.
	Letter TokenCharacterKind = "letter"
	// Punctuation specifies the punctuation state for token character kind.
	Punctuation TokenCharacterKind = "punctuation"
	// Symbol specifies the symbol state for token character kind.
	Symbol TokenCharacterKind = "symbol"
	// Whitespace specifies the whitespace state for token character kind.
	Whitespace TokenCharacterKind = "whitespace"
)

// Type enumerates the values for type.
type Type string

const (
	// TypeDistance specifies the type distance state for type.
	TypeDistance Type = "distance"
	// TypeFreshness specifies the type freshness state for type.
	TypeFreshness Type = "freshness"
	// TypeMagnitude specifies the type magnitude state for type.
	TypeMagnitude Type = "magnitude"
	// TypeTag specifies the type tag state for type.
	TypeTag Type = "tag"
)

// Analyzer is abstract base class for analyzers.
type Analyzer interface {
	AsCustomAnalyzer() (*CustomAnalyzer, bool)
	AsPatternAnalyzer() (*PatternAnalyzer, bool)
	AsStandardAnalyzer() (*StandardAnalyzer, bool)
	AsStopAnalyzer() (*StopAnalyzer, bool)
}

func unmarshalAnalyzer(body []byte) (Analyzer, error) {
	var m map[string]interface{}
	err := json.Unmarshal(body, &m)
	if err != nil {
		return nil, err
	}

	switch m["@odata.type"] {
	case string(OdataTypeMicrosoftAzureSearchCustomAnalyzer):
		var ca CustomAnalyzer
		err := json.Unmarshal(body, &ca)
		return ca, err
	case string(OdataTypeMicrosoftAzureSearchPatternAnalyzer):
		var pa PatternAnalyzer
		err := json.Unmarshal(body, &pa)
		return pa, err
	case string(OdataTypeMicrosoftAzureSearchStandardAnalyzer):
		var sa StandardAnalyzer
		err := json.Unmarshal(body, &sa)
		return sa, err
	case string(OdataTypeMicrosoftAzureSearchStopAnalyzer):
		var sa StopAnalyzer
		err := json.Unmarshal(body, &sa)
		return sa, err
	default:
		return nil, errors.New("Unsupported type")
	}
}
func unmarshalAnalyzerArray(body []byte) ([]Analyzer, error) {
	var rawMessages []*json.RawMessage
	err := json.Unmarshal(body, &rawMessages)
	if err != nil {
		return nil, err
	}

	aArray := make([]Analyzer, len(rawMessages))

	for index, rawMessage := range rawMessages {
		a, err := unmarshalAnalyzer(*rawMessage)
		if err != nil {
			return nil, err
		}
		aArray[index] = a
	}
	return aArray, nil
}

// AnalyzeRequest is specifies some text and analysis components used to break that text into tokens.
type AnalyzeRequest struct {
	Text         *string            `json:"text,omitempty"`
	Analyzer     *AnalyzerName      `json:"analyzer,omitempty"`
	Tokenizer    *TokenizerName     `json:"tokenizer,omitempty"`
	TokenFilters *[]TokenFilterName `json:"tokenFilters,omitempty"`
	CharFilters  *[]CharFilterName  `json:"charFilters,omitempty"`
}

// AnalyzeResult is the result of testing an analyzer on text.
type AnalyzeResult struct {
	autorest.Response `json:"-"`
	Tokens            *[]TokenInfo `json:"tokens,omitempty"`
}

// AnalyzerName is defines the names of all text analyzers supported by Azure Search.
type AnalyzerName struct {
	Name *string `json:"name,omitempty"`
}

// ASCIIFoldingTokenFilter is converts alphabetic, numeric, and symbolic Unicode characters which are not in the first
// 127 ASCII characters (the "Basic Latin" Unicode block) into their ASCII equivalents, if such equivalents exist. This
// token filter is implemented using Apache Lucene.
type ASCIIFoldingTokenFilter struct {
	Name             *string    `json:"name,omitempty"`
	OdataType        OdataType2 `json:"@odata.type,omitempty"`
	PreserveOriginal *bool      `json:"preserveOriginal,omitempty"`
}

// MarshalJSON is the custom marshaler for ASCIIFoldingTokenFilter.
func (aftf ASCIIFoldingTokenFilter) MarshalJSON() ([]byte, error) {
	aftf.OdataType = OdataTypeMicrosoftAzureSearchASCIIFoldingTokenFilter
	type Alias ASCIIFoldingTokenFilter
	return json.Marshal(&struct {
		Alias
	}{
		Alias: (Alias)(aftf),
	})
}

// AsASCIIFoldingTokenFilter is the TokenFilter implementation for ASCIIFoldingTokenFilter.
func (aftf ASCIIFoldingTokenFilter) AsASCIIFoldingTokenFilter() (*ASCIIFoldingTokenFilter, bool) {
	return &aftf, true
}

// AsCjkBigramTokenFilter is the TokenFilter implementation for ASCIIFoldingTokenFilter.
func (aftf ASCIIFoldingTokenFilter) AsCjkBigramTokenFilter() (*CjkBigramTokenFilter, bool) {
	return nil, false
}

// AsCommonGramTokenFilter is the TokenFilter implementation for ASCIIFoldingTokenFilter.
func (aftf ASCIIFoldingTokenFilter) AsCommonGramTokenFilter() (*CommonGramTokenFilter, bool) {
	return nil, false
}

// AsDictionaryDecompounderTokenFilter is the TokenFilter implementation for ASCIIFoldingTokenFilter.
func (aftf ASCIIFoldingTokenFilter) AsDictionaryDecompounderTokenFilter() (*DictionaryDecompounderTokenFilter, bool) {
	return nil, false
}

// AsEdgeNGramTokenFilter is the TokenFilter implementation for ASCIIFoldingTokenFilter.
func (aftf ASCIIFoldingTokenFilter) AsEdgeNGramTokenFilter() (*EdgeNGramTokenFilter, bool) {
	return nil, false
}

// AsEdgeNGramTokenFilterV2 is the TokenFilter implementation for ASCIIFoldingTokenFilter.
func (aftf ASCIIFoldingTokenFilter) AsEdgeNGramTokenFilterV2() (*EdgeNGramTokenFilterV2, bool) {
	return nil, false
}

// AsElisionTokenFilter is the TokenFilter implementation for ASCIIFoldingTokenFilter.
func (aftf ASCIIFoldingTokenFilter) AsElisionTokenFilter() (*ElisionTokenFilter, bool) {
	return nil, false
}

// AsKeepTokenFilter is the TokenFilter implementation for ASCIIFoldingTokenFilter.
func (aftf ASCIIFoldingTokenFilter) AsKeepTokenFilter() (*KeepTokenFilter, bool) {
	return nil, false
}

// AsKeywordMarkerTokenFilter is the TokenFilter implementation for ASCIIFoldingTokenFilter.
func (aftf ASCIIFoldingTokenFilter) AsKeywordMarkerTokenFilter() (*KeywordMarkerTokenFilter, bool) {
	return nil, false
}

// AsLengthTokenFilter is the TokenFilter implementation for ASCIIFoldingTokenFilter.
func (aftf ASCIIFoldingTokenFilter) AsLengthTokenFilter() (*LengthTokenFilter, bool) {
	return nil, false
}

// AsLimitTokenFilter is the TokenFilter implementation for ASCIIFoldingTokenFilter.
func (aftf ASCIIFoldingTokenFilter) AsLimitTokenFilter() (*LimitTokenFilter, bool) {
	return nil, false
}

// AsNGramTokenFilter is the TokenFilter implementation for ASCIIFoldingTokenFilter.
func (aftf ASCIIFoldingTokenFilter) AsNGramTokenFilter() (*NGramTokenFilter, bool) {
	return nil, false
}

// AsNGramTokenFilterV2 is the TokenFilter implementation for ASCIIFoldingTokenFilter.
func (aftf ASCIIFoldingTokenFilter) AsNGramTokenFilterV2() (*NGramTokenFilterV2, bool) {
	return nil, false
}

// AsPatternCaptureTokenFilter is the TokenFilter implementation for ASCIIFoldingTokenFilter.
func (aftf ASCIIFoldingTokenFilter) AsPatternCaptureTokenFilter() (*PatternCaptureTokenFilter, bool) {
	return nil, false
}

// AsPatternReplaceTokenFilter is the TokenFilter implementation for ASCIIFoldingTokenFilter.
func (aftf ASCIIFoldingTokenFilter) AsPatternReplaceTokenFilter() (*PatternReplaceTokenFilter, bool) {
	return nil, false
}

// AsPhoneticTokenFilter is the TokenFilter implementation for ASCIIFoldingTokenFilter.
func (aftf ASCIIFoldingTokenFilter) AsPhoneticTokenFilter() (*PhoneticTokenFilter, bool) {
	return nil, false
}

// AsShingleTokenFilter is the TokenFilter implementation for ASCIIFoldingTokenFilter.
func (aftf ASCIIFoldingTokenFilter) AsShingleTokenFilter() (*ShingleTokenFilter, bool) {
	return nil, false
}

// AsSnowballTokenFilter is the TokenFilter implementation for ASCIIFoldingTokenFilter.
func (aftf ASCIIFoldingTokenFilter) AsSnowballTokenFilter() (*SnowballTokenFilter, bool) {
	return nil, false
}

// AsStemmerTokenFilter is the TokenFilter implementation for ASCIIFoldingTokenFilter.
func (aftf ASCIIFoldingTokenFilter) AsStemmerTokenFilter() (*StemmerTokenFilter, bool) {
	return nil, false
}

// AsStemmerOverrideTokenFilter is the TokenFilter implementation for ASCIIFoldingTokenFilter.
func (aftf ASCIIFoldingTokenFilter) AsStemmerOverrideTokenFilter() (*StemmerOverrideTokenFilter, bool) {
	return nil, false
}

// AsStopwordsTokenFilter is the TokenFilter implementation for ASCIIFoldingTokenFilter.
func (aftf ASCIIFoldingTokenFilter) AsStopwordsTokenFilter() (*StopwordsTokenFilter, bool) {
	return nil, false
}

// AsSynonymTokenFilter is the TokenFilter implementation for ASCIIFoldingTokenFilter.
func (aftf ASCIIFoldingTokenFilter) AsSynonymTokenFilter() (*SynonymTokenFilter, bool) {
	return nil, false
}

// AsTruncateTokenFilter is the TokenFilter implementation for ASCIIFoldingTokenFilter.
func (aftf ASCIIFoldingTokenFilter) AsTruncateTokenFilter() (*TruncateTokenFilter, bool) {
	return nil, false
}

// AsUniqueTokenFilter is the TokenFilter implementation for ASCIIFoldingTokenFilter.
func (aftf ASCIIFoldingTokenFilter) AsUniqueTokenFilter() (*UniqueTokenFilter, bool) {
	return nil, false
}

// AsWordDelimiterTokenFilter is the TokenFilter implementation for ASCIIFoldingTokenFilter.
func (aftf ASCIIFoldingTokenFilter) AsWordDelimiterTokenFilter() (*WordDelimiterTokenFilter, bool) {
	return nil, false
}

// CharFilter is abstract base class for character filters.
type CharFilter interface {
	AsMappingCharFilter() (*MappingCharFilter, bool)
	AsPatternReplaceCharFilter() (*PatternReplaceCharFilter, bool)
}

func unmarshalCharFilter(body []byte) (CharFilter, error) {
	var m map[string]interface{}
	err := json.Unmarshal(body, &m)
	if err != nil {
		return nil, err
	}

	switch m["@odata.type"] {
	case string(OdataTypeMicrosoftAzureSearchMappingCharFilter):
		var mcf MappingCharFilter
		err := json.Unmarshal(body, &mcf)
		return mcf, err
	case string(OdataTypeMicrosoftAzureSearchPatternReplaceCharFilter):
		var prcf PatternReplaceCharFilter
		err := json.Unmarshal(body, &prcf)
		return prcf, err
	default:
		return nil, errors.New("Unsupported type")
	}
}
func unmarshalCharFilterArray(body []byte) ([]CharFilter, error) {
	var rawMessages []*json.RawMessage
	err := json.Unmarshal(body, &rawMessages)
	if err != nil {
		return nil, err
	}

	cfArray := make([]CharFilter, len(rawMessages))

	for index, rawMessage := range rawMessages {
		cf, err := unmarshalCharFilter(*rawMessage)
		if err != nil {
			return nil, err
		}
		cfArray[index] = cf
	}
	return cfArray, nil
}

// CharFilterName is defines the names of all character filters supported by Azure Search.
type CharFilterName struct {
	Name *string `json:"name,omitempty"`
}

// CjkBigramTokenFilter is forms bigrams of CJK terms that are generated from StandardTokenizer. This token filter is
// implemented using Apache Lucene.
type CjkBigramTokenFilter struct {
	Name           *string                        `json:"name,omitempty"`
	OdataType      OdataType2                     `json:"@odata.type,omitempty"`
	IgnoreScripts  *[]CjkBigramTokenFilterScripts `json:"ignoreScripts,omitempty"`
	OutputUnigrams *bool                          `json:"outputUnigrams,omitempty"`
}

// MarshalJSON is the custom marshaler for CjkBigramTokenFilter.
func (cbtf CjkBigramTokenFilter) MarshalJSON() ([]byte, error) {
	cbtf.OdataType = OdataTypeMicrosoftAzureSearchCjkBigramTokenFilter
	type Alias CjkBigramTokenFilter
	return json.Marshal(&struct {
		Alias
	}{
		Alias: (Alias)(cbtf),
	})
}

// AsASCIIFoldingTokenFilter is the TokenFilter implementation for CjkBigramTokenFilter.
func (cbtf CjkBigramTokenFilter) AsASCIIFoldingTokenFilter() (*ASCIIFoldingTokenFilter, bool) {
	return nil, false
}

// AsCjkBigramTokenFilter is the TokenFilter implementation for CjkBigramTokenFilter.
func (cbtf CjkBigramTokenFilter) AsCjkBigramTokenFilter() (*CjkBigramTokenFilter, bool) {
	return &cbtf, true
}

// AsCommonGramTokenFilter is the TokenFilter implementation for CjkBigramTokenFilter.
func (cbtf CjkBigramTokenFilter) AsCommonGramTokenFilter() (*CommonGramTokenFilter, bool) {
	return nil, false
}

// AsDictionaryDecompounderTokenFilter is the TokenFilter implementation for CjkBigramTokenFilter.
func (cbtf CjkBigramTokenFilter) AsDictionaryDecompounderTokenFilter() (*DictionaryDecompounderTokenFilter, bool) {
	return nil, false
}

// AsEdgeNGramTokenFilter is the TokenFilter implementation for CjkBigramTokenFilter.
func (cbtf CjkBigramTokenFilter) AsEdgeNGramTokenFilter() (*EdgeNGramTokenFilter, bool) {
	return nil, false
}

// AsEdgeNGramTokenFilterV2 is the TokenFilter implementation for CjkBigramTokenFilter.
func (cbtf CjkBigramTokenFilter) AsEdgeNGramTokenFilterV2() (*EdgeNGramTokenFilterV2, bool) {
	return nil, false
}

// AsElisionTokenFilter is the TokenFilter implementation for CjkBigramTokenFilter.
func (cbtf CjkBigramTokenFilter) AsElisionTokenFilter() (*ElisionTokenFilter, bool) {
	return nil, false
}

// AsKeepTokenFilter is the TokenFilter implementation for CjkBigramTokenFilter.
func (cbtf CjkBigramTokenFilter) AsKeepTokenFilter() (*KeepTokenFilter, bool) {
	return nil, false
}

// AsKeywordMarkerTokenFilter is the TokenFilter implementation for CjkBigramTokenFilter.
func (cbtf CjkBigramTokenFilter) AsKeywordMarkerTokenFilter() (*KeywordMarkerTokenFilter, bool) {
	return nil, false
}

// AsLengthTokenFilter is the TokenFilter implementation for CjkBigramTokenFilter.
func (cbtf CjkBigramTokenFilter) AsLengthTokenFilter() (*LengthTokenFilter, bool) {
	return nil, false
}

// AsLimitTokenFilter is the TokenFilter implementation for CjkBigramTokenFilter.
func (cbtf CjkBigramTokenFilter) AsLimitTokenFilter() (*LimitTokenFilter, bool) {
	return nil, false
}

// AsNGramTokenFilter is the TokenFilter implementation for CjkBigramTokenFilter.
func (cbtf CjkBigramTokenFilter) AsNGramTokenFilter() (*NGramTokenFilter, bool) {
	return nil, false
}

// AsNGramTokenFilterV2 is the TokenFilter implementation for CjkBigramTokenFilter.
func (cbtf CjkBigramTokenFilter) AsNGramTokenFilterV2() (*NGramTokenFilterV2, bool) {
	return nil, false
}

// AsPatternCaptureTokenFilter is the TokenFilter implementation for CjkBigramTokenFilter.
func (cbtf CjkBigramTokenFilter) AsPatternCaptureTokenFilter() (*PatternCaptureTokenFilter, bool) {
	return nil, false
}

// AsPatternReplaceTokenFilter is the TokenFilter implementation for CjkBigramTokenFilter.
func (cbtf CjkBigramTokenFilter) AsPatternReplaceTokenFilter() (*PatternReplaceTokenFilter, bool) {
	return nil, false
}

// AsPhoneticTokenFilter is the TokenFilter implementation for CjkBigramTokenFilter.
func (cbtf CjkBigramTokenFilter) AsPhoneticTokenFilter() (*PhoneticTokenFilter, bool) {
	return nil, false
}

// AsShingleTokenFilter is the TokenFilter implementation for CjkBigramTokenFilter.
func (cbtf CjkBigramTokenFilter) AsShingleTokenFilter() (*ShingleTokenFilter, bool) {
	return nil, false
}

// AsSnowballTokenFilter is the TokenFilter implementation for CjkBigramTokenFilter.
func (cbtf CjkBigramTokenFilter) AsSnowballTokenFilter() (*SnowballTokenFilter, bool) {
	return nil, false
}

// AsStemmerTokenFilter is the TokenFilter implementation for CjkBigramTokenFilter.
func (cbtf CjkBigramTokenFilter) AsStemmerTokenFilter() (*StemmerTokenFilter, bool) {
	return nil, false
}

// AsStemmerOverrideTokenFilter is the TokenFilter implementation for CjkBigramTokenFilter.
func (cbtf CjkBigramTokenFilter) AsStemmerOverrideTokenFilter() (*StemmerOverrideTokenFilter, bool) {
	return nil, false
}

// AsStopwordsTokenFilter is the TokenFilter implementation for CjkBigramTokenFilter.
func (cbtf CjkBigramTokenFilter) AsStopwordsTokenFilter() (*StopwordsTokenFilter, bool) {
	return nil, false
}

// AsSynonymTokenFilter is the TokenFilter implementation for CjkBigramTokenFilter.
func (cbtf CjkBigramTokenFilter) AsSynonymTokenFilter() (*SynonymTokenFilter, bool) {
	return nil, false
}

// AsTruncateTokenFilter is the TokenFilter implementation for CjkBigramTokenFilter.
func (cbtf CjkBigramTokenFilter) AsTruncateTokenFilter() (*TruncateTokenFilter, bool) {
	return nil, false
}

// AsUniqueTokenFilter is the TokenFilter implementation for CjkBigramTokenFilter.
func (cbtf CjkBigramTokenFilter) AsUniqueTokenFilter() (*UniqueTokenFilter, bool) {
	return nil, false
}

// AsWordDelimiterTokenFilter is the TokenFilter implementation for CjkBigramTokenFilter.
func (cbtf CjkBigramTokenFilter) AsWordDelimiterTokenFilter() (*WordDelimiterTokenFilter, bool) {
	return nil, false
}

// ClassicTokenizer is grammar-based tokenizer that is suitable for processing most European-language documents. This
// tokenizer is implemented using Apache Lucene.
type ClassicTokenizer struct {
	Name           *string    `json:"name,omitempty"`
	OdataType      OdataType1 `json:"@odata.type,omitempty"`
	MaxTokenLength *int32     `json:"maxTokenLength,omitempty"`
}

// MarshalJSON is the custom marshaler for ClassicTokenizer.
func (ct ClassicTokenizer) MarshalJSON() ([]byte, error) {
	ct.OdataType = OdataTypeMicrosoftAzureSearchClassicTokenizer
	type Alias ClassicTokenizer
	return json.Marshal(&struct {
		Alias
	}{
		Alias: (Alias)(ct),
	})
}

// AsClassicTokenizer is the Tokenizer implementation for ClassicTokenizer.
func (ct ClassicTokenizer) AsClassicTokenizer() (*ClassicTokenizer, bool) {
	return &ct, true
}

// AsEdgeNGramTokenizer is the Tokenizer implementation for ClassicTokenizer.
func (ct ClassicTokenizer) AsEdgeNGramTokenizer() (*EdgeNGramTokenizer, bool) {
	return nil, false
}

// AsKeywordTokenizer is the Tokenizer implementation for ClassicTokenizer.
func (ct ClassicTokenizer) AsKeywordTokenizer() (*KeywordTokenizer, bool) {
	return nil, false
}

// AsKeywordTokenizerV2 is the Tokenizer implementation for ClassicTokenizer.
func (ct ClassicTokenizer) AsKeywordTokenizerV2() (*KeywordTokenizerV2, bool) {
	return nil, false
}

// AsMicrosoftLanguageTokenizer is the Tokenizer implementation for ClassicTokenizer.
func (ct ClassicTokenizer) AsMicrosoftLanguageTokenizer() (*MicrosoftLanguageTokenizer, bool) {
	return nil, false
}

// AsMicrosoftLanguageStemmingTokenizer is the Tokenizer implementation for ClassicTokenizer.
func (ct ClassicTokenizer) AsMicrosoftLanguageStemmingTokenizer() (*MicrosoftLanguageStemmingTokenizer, bool) {
	return nil, false
}

// AsNGramTokenizer is the Tokenizer implementation for ClassicTokenizer.
func (ct ClassicTokenizer) AsNGramTokenizer() (*NGramTokenizer, bool) {
	return nil, false
}

// AsPathHierarchyTokenizer is the Tokenizer implementation for ClassicTokenizer.
func (ct ClassicTokenizer) AsPathHierarchyTokenizer() (*PathHierarchyTokenizer, bool) {
	return nil, false
}

// AsPathHierarchyTokenizerV2 is the Tokenizer implementation for ClassicTokenizer.
func (ct ClassicTokenizer) AsPathHierarchyTokenizerV2() (*PathHierarchyTokenizerV2, bool) {
	return nil, false
}

// AsPatternTokenizer is the Tokenizer implementation for ClassicTokenizer.
func (ct ClassicTokenizer) AsPatternTokenizer() (*PatternTokenizer, bool) {
	return nil, false
}

// AsStandardTokenizer is the Tokenizer implementation for ClassicTokenizer.
func (ct ClassicTokenizer) AsStandardTokenizer() (*StandardTokenizer, bool) {
	return nil, false
}

// AsStandardTokenizerV2 is the Tokenizer implementation for ClassicTokenizer.
func (ct ClassicTokenizer) AsStandardTokenizerV2() (*StandardTokenizerV2, bool) {
	return nil, false
}

// AsUaxURLEmailTokenizer is the Tokenizer implementation for ClassicTokenizer.
func (ct ClassicTokenizer) AsUaxURLEmailTokenizer() (*UaxURLEmailTokenizer, bool) {
	return nil, false
}

// CommonGramTokenFilter is construct bigrams for frequently occurring terms while indexing. Single terms are still
// indexed too, with bigrams overlaid. This token filter is implemented using Apache Lucene.
type CommonGramTokenFilter struct {
	Name         *string    `json:"name,omitempty"`
	OdataType    OdataType2 `json:"@odata.type,omitempty"`
	CommonWords  *[]string  `json:"commonWords,omitempty"`
	IgnoreCase   *bool      `json:"ignoreCase,omitempty"`
	UseQueryMode *bool      `json:"queryMode,omitempty"`
}

// MarshalJSON is the custom marshaler for CommonGramTokenFilter.
func (cgtf CommonGramTokenFilter) MarshalJSON() ([]byte, error) {
	cgtf.OdataType = OdataTypeMicrosoftAzureSearchCommonGramTokenFilter
	type Alias CommonGramTokenFilter
	return json.Marshal(&struct {
		Alias
	}{
		Alias: (Alias)(cgtf),
	})
}

// AsASCIIFoldingTokenFilter is the TokenFilter implementation for CommonGramTokenFilter.
func (cgtf CommonGramTokenFilter) AsASCIIFoldingTokenFilter() (*ASCIIFoldingTokenFilter, bool) {
	return nil, false
}

// AsCjkBigramTokenFilter is the TokenFilter implementation for CommonGramTokenFilter.
func (cgtf CommonGramTokenFilter) AsCjkBigramTokenFilter() (*CjkBigramTokenFilter, bool) {
	return nil, false
}

// AsCommonGramTokenFilter is the TokenFilter implementation for CommonGramTokenFilter.
func (cgtf CommonGramTokenFilter) AsCommonGramTokenFilter() (*CommonGramTokenFilter, bool) {
	return &cgtf, true
}

// AsDictionaryDecompounderTokenFilter is the TokenFilter implementation for CommonGramTokenFilter.
func (cgtf CommonGramTokenFilter) AsDictionaryDecompounderTokenFilter() (*DictionaryDecompounderTokenFilter, bool) {
	return nil, false
}

// AsEdgeNGramTokenFilter is the TokenFilter implementation for CommonGramTokenFilter.
func (cgtf CommonGramTokenFilter) AsEdgeNGramTokenFilter() (*EdgeNGramTokenFilter, bool) {
	return nil, false
}

// AsEdgeNGramTokenFilterV2 is the TokenFilter implementation for CommonGramTokenFilter.
func (cgtf CommonGramTokenFilter) AsEdgeNGramTokenFilterV2() (*EdgeNGramTokenFilterV2, bool) {
	return nil, false
}

// AsElisionTokenFilter is the TokenFilter implementation for CommonGramTokenFilter.
func (cgtf CommonGramTokenFilter) AsElisionTokenFilter() (*ElisionTokenFilter, bool) {
	return nil, false
}

// AsKeepTokenFilter is the TokenFilter implementation for CommonGramTokenFilter.
func (cgtf CommonGramTokenFilter) AsKeepTokenFilter() (*KeepTokenFilter, bool) {
	return nil, false
}

// AsKeywordMarkerTokenFilter is the TokenFilter implementation for CommonGramTokenFilter.
func (cgtf CommonGramTokenFilter) AsKeywordMarkerTokenFilter() (*KeywordMarkerTokenFilter, bool) {
	return nil, false
}

// AsLengthTokenFilter is the TokenFilter implementation for CommonGramTokenFilter.
func (cgtf CommonGramTokenFilter) AsLengthTokenFilter() (*LengthTokenFilter, bool) {
	return nil, false
}

// AsLimitTokenFilter is the TokenFilter implementation for CommonGramTokenFilter.
func (cgtf CommonGramTokenFilter) AsLimitTokenFilter() (*LimitTokenFilter, bool) {
	return nil, false
}

// AsNGramTokenFilter is the TokenFilter implementation for CommonGramTokenFilter.
func (cgtf CommonGramTokenFilter) AsNGramTokenFilter() (*NGramTokenFilter, bool) {
	return nil, false
}

// AsNGramTokenFilterV2 is the TokenFilter implementation for CommonGramTokenFilter.
func (cgtf CommonGramTokenFilter) AsNGramTokenFilterV2() (*NGramTokenFilterV2, bool) {
	return nil, false
}

// AsPatternCaptureTokenFilter is the TokenFilter implementation for CommonGramTokenFilter.
func (cgtf CommonGramTokenFilter) AsPatternCaptureTokenFilter() (*PatternCaptureTokenFilter, bool) {
	return nil, false
}

// AsPatternReplaceTokenFilter is the TokenFilter implementation for CommonGramTokenFilter.
func (cgtf CommonGramTokenFilter) AsPatternReplaceTokenFilter() (*PatternReplaceTokenFilter, bool) {
	return nil, false
}

// AsPhoneticTokenFilter is the TokenFilter implementation for CommonGramTokenFilter.
func (cgtf CommonGramTokenFilter) AsPhoneticTokenFilter() (*PhoneticTokenFilter, bool) {
	return nil, false
}

// AsShingleTokenFilter is the TokenFilter implementation for CommonGramTokenFilter.
func (cgtf CommonGramTokenFilter) AsShingleTokenFilter() (*ShingleTokenFilter, bool) {
	return nil, false
}

// AsSnowballTokenFilter is the TokenFilter implementation for CommonGramTokenFilter.
func (cgtf CommonGramTokenFilter) AsSnowballTokenFilter() (*SnowballTokenFilter, bool) {
	return nil, false
}

// AsStemmerTokenFilter is the TokenFilter implementation for CommonGramTokenFilter.
func (cgtf CommonGramTokenFilter) AsStemmerTokenFilter() (*StemmerTokenFilter, bool) {
	return nil, false
}

// AsStemmerOverrideTokenFilter is the TokenFilter implementation for CommonGramTokenFilter.
func (cgtf CommonGramTokenFilter) AsStemmerOverrideTokenFilter() (*StemmerOverrideTokenFilter, bool) {
	return nil, false
}

// AsStopwordsTokenFilter is the TokenFilter implementation for CommonGramTokenFilter.
func (cgtf CommonGramTokenFilter) AsStopwordsTokenFilter() (*StopwordsTokenFilter, bool) {
	return nil, false
}

// AsSynonymTokenFilter is the TokenFilter implementation for CommonGramTokenFilter.
func (cgtf CommonGramTokenFilter) AsSynonymTokenFilter() (*SynonymTokenFilter, bool) {
	return nil, false
}

// AsTruncateTokenFilter is the TokenFilter implementation for CommonGramTokenFilter.
func (cgtf CommonGramTokenFilter) AsTruncateTokenFilter() (*TruncateTokenFilter, bool) {
	return nil, false
}

// AsUniqueTokenFilter is the TokenFilter implementation for CommonGramTokenFilter.
func (cgtf CommonGramTokenFilter) AsUniqueTokenFilter() (*UniqueTokenFilter, bool) {
	return nil, false
}

// AsWordDelimiterTokenFilter is the TokenFilter implementation for CommonGramTokenFilter.
func (cgtf CommonGramTokenFilter) AsWordDelimiterTokenFilter() (*WordDelimiterTokenFilter, bool) {
	return nil, false
}

// CorsOptions is defines options to control Cross-Origin Resource Sharing (CORS) for an index.
type CorsOptions struct {
	AllowedOrigins  *[]string `json:"allowedOrigins,omitempty"`
	MaxAgeInSeconds *int64    `json:"maxAgeInSeconds,omitempty"`
}

// CustomAnalyzer is allows you to take control over the process of converting text into indexable/searchable tokens.
// It's a user-defined configuration consisting of a single predefined tokenizer and one or more filters. The tokenizer
// is responsible for breaking text into tokens, and the filters for modifying tokens emitted by the tokenizer.
type CustomAnalyzer struct {
	Name         *string            `json:"name,omitempty"`
	OdataType    OdataType          `json:"@odata.type,omitempty"`
	Tokenizer    *TokenizerName     `json:"tokenizer,omitempty"`
	TokenFilters *[]TokenFilterName `json:"tokenFilters,omitempty"`
	CharFilters  *[]CharFilterName  `json:"charFilters,omitempty"`
}

// MarshalJSON is the custom marshaler for CustomAnalyzer.
func (ca CustomAnalyzer) MarshalJSON() ([]byte, error) {
	ca.OdataType = OdataTypeMicrosoftAzureSearchCustomAnalyzer
	type Alias CustomAnalyzer
	return json.Marshal(&struct {
		Alias
	}{
		Alias: (Alias)(ca),
	})
}

// AsCustomAnalyzer is the Analyzer implementation for CustomAnalyzer.
func (ca CustomAnalyzer) AsCustomAnalyzer() (*CustomAnalyzer, bool) {
	return &ca, true
}

// AsPatternAnalyzer is the Analyzer implementation for CustomAnalyzer.
func (ca CustomAnalyzer) AsPatternAnalyzer() (*PatternAnalyzer, bool) {
	return nil, false
}

// AsStandardAnalyzer is the Analyzer implementation for CustomAnalyzer.
func (ca CustomAnalyzer) AsStandardAnalyzer() (*StandardAnalyzer, bool) {
	return nil, false
}

// AsStopAnalyzer is the Analyzer implementation for CustomAnalyzer.
func (ca CustomAnalyzer) AsStopAnalyzer() (*StopAnalyzer, bool) {
	return nil, false
}

// DataChangeDetectionPolicy is abstract base class for data change detection policies.
type DataChangeDetectionPolicy interface {
	AsHighWaterMarkChangeDetectionPolicy() (*HighWaterMarkChangeDetectionPolicy, bool)
	AsSQLIntegratedChangeTrackingPolicy() (*SQLIntegratedChangeTrackingPolicy, bool)
}

func unmarshalDataChangeDetectionPolicy(body []byte) (DataChangeDetectionPolicy, error) {
	var m map[string]interface{}
	err := json.Unmarshal(body, &m)
	if err != nil {
		return nil, err
	}

	switch m["@odata.type"] {
	case string(OdataTypeMicrosoftAzureSearchHighWaterMarkChangeDetectionPolicy):
		var hwmcdp HighWaterMarkChangeDetectionPolicy
		err := json.Unmarshal(body, &hwmcdp)
		return hwmcdp, err
	case string(OdataTypeMicrosoftAzureSearchSQLIntegratedChangeTrackingPolicy):
		var sictp SQLIntegratedChangeTrackingPolicy
		err := json.Unmarshal(body, &sictp)
		return sictp, err
	default:
		return nil, errors.New("Unsupported type")
	}
}
func unmarshalDataChangeDetectionPolicyArray(body []byte) ([]DataChangeDetectionPolicy, error) {
	var rawMessages []*json.RawMessage
	err := json.Unmarshal(body, &rawMessages)
	if err != nil {
		return nil, err
	}

	dcdpArray := make([]DataChangeDetectionPolicy, len(rawMessages))

	for index, rawMessage := range rawMessages {
		dcdp, err := unmarshalDataChangeDetectionPolicy(*rawMessage)
		if err != nil {
			return nil, err
		}
		dcdpArray[index] = dcdp
	}
	return dcdpArray, nil
}

// DataContainer is represents information about the entity (such as Azure SQL table or DocumentDb collection) that
// will be indexed.
type DataContainer struct {
	Name  *string `json:"name,omitempty"`
	Query *string `json:"query,omitempty"`
}

// DataDeletionDetectionPolicy is abstract base class for data deletion detection policies.
type DataDeletionDetectionPolicy interface {
	AsSoftDeleteColumnDeletionDetectionPolicy() (*SoftDeleteColumnDeletionDetectionPolicy, bool)
}

func unmarshalDataDeletionDetectionPolicy(body []byte) (DataDeletionDetectionPolicy, error) {
	var m map[string]interface{}
	err := json.Unmarshal(body, &m)
	if err != nil {
		return nil, err
	}

	switch m["@odata.type"] {
	case string(OdataTypeMicrosoftAzureSearchSoftDeleteColumnDeletionDetectionPolicy):
		var sdcddp SoftDeleteColumnDeletionDetectionPolicy
		err := json.Unmarshal(body, &sdcddp)
		return sdcddp, err
	default:
		return nil, errors.New("Unsupported type")
	}
}
func unmarshalDataDeletionDetectionPolicyArray(body []byte) ([]DataDeletionDetectionPolicy, error) {
	var rawMessages []*json.RawMessage
	err := json.Unmarshal(body, &rawMessages)
	if err != nil {
		return nil, err
	}

	dddpArray := make([]DataDeletionDetectionPolicy, len(rawMessages))

	for index, rawMessage := range rawMessages {
		dddp, err := unmarshalDataDeletionDetectionPolicy(*rawMessage)
		if err != nil {
			return nil, err
		}
		dddpArray[index] = dddp
	}
	return dddpArray, nil
}

// DataSource is represents a datasource definition in Azure Search, which can be used to configure an indexer.
type DataSource struct {
	autorest.Response           `json:"-"`
	Name                        *string                     `json:"name,omitempty"`
	Description                 *string                     `json:"description,omitempty"`
	Type                        *DataSourceType             `json:"type,omitempty"`
	Credentials                 *DataSourceCredentials      `json:"credentials,omitempty"`
	Container                   *DataContainer              `json:"container,omitempty"`
	DataChangeDetectionPolicy   DataChangeDetectionPolicy   `json:"dataChangeDetectionPolicy,omitempty"`
	DataDeletionDetectionPolicy DataDeletionDetectionPolicy `json:"dataDeletionDetectionPolicy,omitempty"`
	ETag                        *string                     `json:"@odata.etag,omitempty"`
}

// UnmarshalJSON is the custom unmarshaler for DataSource struct.
func (ds *DataSource) UnmarshalJSON(body []byte) error {
	var m map[string]*json.RawMessage
	err := json.Unmarshal(body, &m)
	if err != nil {
		return err
	}
	var v *json.RawMessage

	v = m["name"]
	if v != nil {
		var name string
		err = json.Unmarshal(*m["name"], &name)
		if err != nil {
			return err
		}
		ds.Name = &name
	}

	v = m["description"]
	if v != nil {
		var description string
		err = json.Unmarshal(*m["description"], &description)
		if err != nil {
			return err
		}
		ds.Description = &description
	}

	v = m["type"]
	if v != nil {
		var typeVar DataSourceType
		err = json.Unmarshal(*m["type"], &typeVar)
		if err != nil {
			return err
		}
		ds.Type = &typeVar
	}

	v = m["credentials"]
	if v != nil {
		var credentials DataSourceCredentials
		err = json.Unmarshal(*m["credentials"], &credentials)
		if err != nil {
			return err
		}
		ds.Credentials = &credentials
	}

	v = m["container"]
	if v != nil {
		var containerVar DataContainer
		err = json.Unmarshal(*m["container"], &containerVar)
		if err != nil {
			return err
		}
		ds.Container = &containerVar
	}

	v = m["dataChangeDetectionPolicy"]
	if v != nil {
		dataChangeDetectionPolicy, err := unmarshalDataChangeDetectionPolicy(*m["dataChangeDetectionPolicy"])
		if err != nil {
			return err
		}
		ds.DataChangeDetectionPolicy = dataChangeDetectionPolicy
	}

	v = m["dataDeletionDetectionPolicy"]
	if v != nil {
		dataDeletionDetectionPolicy, err := unmarshalDataDeletionDetectionPolicy(*m["dataDeletionDetectionPolicy"])
		if err != nil {
			return err
		}
		ds.DataDeletionDetectionPolicy = dataDeletionDetectionPolicy
	}

	v = m["@odata.etag"]
	if v != nil {
		var odataetag string
		err = json.Unmarshal(*m["@odata.etag"], &odataetag)
		if err != nil {
			return err
		}
		ds.ETag = &odataetag
	}

	return nil
}

// DataSourceCredentials is represents credentials that can be used to connect to a datasource.
type DataSourceCredentials struct {
	ConnectionString *string `json:"connectionString,omitempty"`
}

// DataSourceListResult is response from a List Datasources request. If successful, it includes the full definitions of
// all datasources.
type DataSourceListResult struct {
	autorest.Response `json:"-"`
	DataSources       *[]DataSource `json:"value,omitempty"`
}

// DataSourceType is defines the type of an Azure Search datasource.
type DataSourceType struct {
	Name *string `json:"name,omitempty"`
}

// DataType is defines the data type of a field in an Azure Search index.
type DataType struct {
	Name *string `json:"name,omitempty"`
}

// DictionaryDecompounderTokenFilter is decomposes compound words found in many Germanic languages. This token filter
// is implemented using Apache Lucene.
type DictionaryDecompounderTokenFilter struct {
	Name             *string    `json:"name,omitempty"`
	OdataType        OdataType2 `json:"@odata.type,omitempty"`
	WordList         *[]string  `json:"wordList,omitempty"`
	MinWordSize      *int32     `json:"minWordSize,omitempty"`
	MinSubwordSize   *int32     `json:"minSubwordSize,omitempty"`
	MaxSubwordSize   *int32     `json:"maxSubwordSize,omitempty"`
	OnlyLongestMatch *bool      `json:"onlyLongestMatch,omitempty"`
}

// MarshalJSON is the custom marshaler for DictionaryDecompounderTokenFilter.
func (ddtf DictionaryDecompounderTokenFilter) MarshalJSON() ([]byte, error) {
	ddtf.OdataType = OdataTypeMicrosoftAzureSearchDictionaryDecompounderTokenFilter
	type Alias DictionaryDecompounderTokenFilter
	return json.Marshal(&struct {
		Alias
	}{
		Alias: (Alias)(ddtf),
	})
}

// AsASCIIFoldingTokenFilter is the TokenFilter implementation for DictionaryDecompounderTokenFilter.
func (ddtf DictionaryDecompounderTokenFilter) AsASCIIFoldingTokenFilter() (*ASCIIFoldingTokenFilter, bool) {
	return nil, false
}

// AsCjkBigramTokenFilter is the TokenFilter implementation for DictionaryDecompounderTokenFilter.
func (ddtf DictionaryDecompounderTokenFilter) AsCjkBigramTokenFilter() (*CjkBigramTokenFilter, bool) {
	return nil, false
}

// AsCommonGramTokenFilter is the TokenFilter implementation for DictionaryDecompounderTokenFilter.
func (ddtf DictionaryDecompounderTokenFilter) AsCommonGramTokenFilter() (*CommonGramTokenFilter, bool) {
	return nil, false
}

// AsDictionaryDecompounderTokenFilter is the TokenFilter implementation for DictionaryDecompounderTokenFilter.
func (ddtf DictionaryDecompounderTokenFilter) AsDictionaryDecompounderTokenFilter() (*DictionaryDecompounderTokenFilter, bool) {
	return &ddtf, true
}

// AsEdgeNGramTokenFilter is the TokenFilter implementation for DictionaryDecompounderTokenFilter.
func (ddtf DictionaryDecompounderTokenFilter) AsEdgeNGramTokenFilter() (*EdgeNGramTokenFilter, bool) {
	return nil, false
}

// AsEdgeNGramTokenFilterV2 is the TokenFilter implementation for DictionaryDecompounderTokenFilter.
func (ddtf DictionaryDecompounderTokenFilter) AsEdgeNGramTokenFilterV2() (*EdgeNGramTokenFilterV2, bool) {
	return nil, false
}

// AsElisionTokenFilter is the TokenFilter implementation for DictionaryDecompounderTokenFilter.
func (ddtf DictionaryDecompounderTokenFilter) AsElisionTokenFilter() (*ElisionTokenFilter, bool) {
	return nil, false
}

// AsKeepTokenFilter is the TokenFilter implementation for DictionaryDecompounderTokenFilter.
func (ddtf DictionaryDecompounderTokenFilter) AsKeepTokenFilter() (*KeepTokenFilter, bool) {
	return nil, false
}

// AsKeywordMarkerTokenFilter is the TokenFilter implementation for DictionaryDecompounderTokenFilter.
func (ddtf DictionaryDecompounderTokenFilter) AsKeywordMarkerTokenFilter() (*KeywordMarkerTokenFilter, bool) {
	return nil, false
}

// AsLengthTokenFilter is the TokenFilter implementation for DictionaryDecompounderTokenFilter.
func (ddtf DictionaryDecompounderTokenFilter) AsLengthTokenFilter() (*LengthTokenFilter, bool) {
	return nil, false
}

// AsLimitTokenFilter is the TokenFilter implementation for DictionaryDecompounderTokenFilter.
func (ddtf DictionaryDecompounderTokenFilter) AsLimitTokenFilter() (*LimitTokenFilter, bool) {
	return nil, false
}

// AsNGramTokenFilter is the TokenFilter implementation for DictionaryDecompounderTokenFilter.
func (ddtf DictionaryDecompounderTokenFilter) AsNGramTokenFilter() (*NGramTokenFilter, bool) {
	return nil, false
}

// AsNGramTokenFilterV2 is the TokenFilter implementation for DictionaryDecompounderTokenFilter.
func (ddtf DictionaryDecompounderTokenFilter) AsNGramTokenFilterV2() (*NGramTokenFilterV2, bool) {
	return nil, false
}

// AsPatternCaptureTokenFilter is the TokenFilter implementation for DictionaryDecompounderTokenFilter.
func (ddtf DictionaryDecompounderTokenFilter) AsPatternCaptureTokenFilter() (*PatternCaptureTokenFilter, bool) {
	return nil, false
}

// AsPatternReplaceTokenFilter is the TokenFilter implementation for DictionaryDecompounderTokenFilter.
func (ddtf DictionaryDecompounderTokenFilter) AsPatternReplaceTokenFilter() (*PatternReplaceTokenFilter, bool) {
	return nil, false
}

// AsPhoneticTokenFilter is the TokenFilter implementation for DictionaryDecompounderTokenFilter.
func (ddtf DictionaryDecompounderTokenFilter) AsPhoneticTokenFilter() (*PhoneticTokenFilter, bool) {
	return nil, false
}

// AsShingleTokenFilter is the TokenFilter implementation for DictionaryDecompounderTokenFilter.
func (ddtf DictionaryDecompounderTokenFilter) AsShingleTokenFilter() (*ShingleTokenFilter, bool) {
	return nil, false
}

// AsSnowballTokenFilter is the TokenFilter implementation for DictionaryDecompounderTokenFilter.
func (ddtf DictionaryDecompounderTokenFilter) AsSnowballTokenFilter() (*SnowballTokenFilter, bool) {
	return nil, false
}

// AsStemmerTokenFilter is the TokenFilter implementation for DictionaryDecompounderTokenFilter.
func (ddtf DictionaryDecompounderTokenFilter) AsStemmerTokenFilter() (*StemmerTokenFilter, bool) {
	return nil, false
}

// AsStemmerOverrideTokenFilter is the TokenFilter implementation for DictionaryDecompounderTokenFilter.
func (ddtf DictionaryDecompounderTokenFilter) AsStemmerOverrideTokenFilter() (*StemmerOverrideTokenFilter, bool) {
	return nil, false
}

// AsStopwordsTokenFilter is the TokenFilter implementation for DictionaryDecompounderTokenFilter.
func (ddtf DictionaryDecompounderTokenFilter) AsStopwordsTokenFilter() (*StopwordsTokenFilter, bool) {
	return nil, false
}

// AsSynonymTokenFilter is the TokenFilter implementation for DictionaryDecompounderTokenFilter.
func (ddtf DictionaryDecompounderTokenFilter) AsSynonymTokenFilter() (*SynonymTokenFilter, bool) {
	return nil, false
}

// AsTruncateTokenFilter is the TokenFilter implementation for DictionaryDecompounderTokenFilter.
func (ddtf DictionaryDecompounderTokenFilter) AsTruncateTokenFilter() (*TruncateTokenFilter, bool) {
	return nil, false
}

// AsUniqueTokenFilter is the TokenFilter implementation for DictionaryDecompounderTokenFilter.
func (ddtf DictionaryDecompounderTokenFilter) AsUniqueTokenFilter() (*UniqueTokenFilter, bool) {
	return nil, false
}

// AsWordDelimiterTokenFilter is the TokenFilter implementation for DictionaryDecompounderTokenFilter.
func (ddtf DictionaryDecompounderTokenFilter) AsWordDelimiterTokenFilter() (*WordDelimiterTokenFilter, bool) {
	return nil, false
}

// DistanceScoringFunction is defines a function that boosts scores based on distance from a geographic location.
type DistanceScoringFunction struct {
	FieldName     *string                      `json:"fieldName,omitempty"`
	Boost         *float64                     `json:"boost,omitempty"`
	Interpolation ScoringFunctionInterpolation `json:"interpolation,omitempty"`
	Type          Type                         `json:"type,omitempty"`
	Parameters    *DistanceScoringParameters   `json:"distance,omitempty"`
}

// MarshalJSON is the custom marshaler for DistanceScoringFunction.
func (dsf DistanceScoringFunction) MarshalJSON() ([]byte, error) {
	dsf.Type = TypeDistance
	type Alias DistanceScoringFunction
	return json.Marshal(&struct {
		Alias
	}{
		Alias: (Alias)(dsf),
	})
}

// AsDistanceScoringFunction is the ScoringFunction implementation for DistanceScoringFunction.
func (dsf DistanceScoringFunction) AsDistanceScoringFunction() (*DistanceScoringFunction, bool) {
	return &dsf, true
}

// AsFreshnessScoringFunction is the ScoringFunction implementation for DistanceScoringFunction.
func (dsf DistanceScoringFunction) AsFreshnessScoringFunction() (*FreshnessScoringFunction, bool) {
	return nil, false
}

// AsMagnitudeScoringFunction is the ScoringFunction implementation for DistanceScoringFunction.
func (dsf DistanceScoringFunction) AsMagnitudeScoringFunction() (*MagnitudeScoringFunction, bool) {
	return nil, false
}

// AsTagScoringFunction is the ScoringFunction implementation for DistanceScoringFunction.
func (dsf DistanceScoringFunction) AsTagScoringFunction() (*TagScoringFunction, bool) {
	return nil, false
}

// DistanceScoringParameters is provides parameter values to a distance scoring function.
type DistanceScoringParameters struct {
	ReferencePointParameter *string  `json:"referencePointParameter,omitempty"`
	BoostingDistance        *float64 `json:"boostingDistance,omitempty"`
}

// DocumentIndexResult is response containing the status of operations for all documents in the indexing request.
type DocumentIndexResult struct {
	Results *[]IndexingResult `json:"value,omitempty"`
}

// EdgeNGramTokenFilter is generates n-grams of the given size(s) starting from the front or the back of an input
// token. This token filter is implemented using Apache Lucene.
type EdgeNGramTokenFilter struct {
	Name      *string                  `json:"name,omitempty"`
	OdataType OdataType2               `json:"@odata.type,omitempty"`
	MinGram   *int32                   `json:"minGram,omitempty"`
	MaxGram   *int32                   `json:"maxGram,omitempty"`
	Side      EdgeNGramTokenFilterSide `json:"side,omitempty"`
}

// MarshalJSON is the custom marshaler for EdgeNGramTokenFilter.
func (engtf EdgeNGramTokenFilter) MarshalJSON() ([]byte, error) {
	engtf.OdataType = OdataTypeMicrosoftAzureSearchEdgeNGramTokenFilter
	type Alias EdgeNGramTokenFilter
	return json.Marshal(&struct {
		Alias
	}{
		Alias: (Alias)(engtf),
	})
}

// AsASCIIFoldingTokenFilter is the TokenFilter implementation for EdgeNGramTokenFilter.
func (engtf EdgeNGramTokenFilter) AsASCIIFoldingTokenFilter() (*ASCIIFoldingTokenFilter, bool) {
	return nil, false
}

// AsCjkBigramTokenFilter is the TokenFilter implementation for EdgeNGramTokenFilter.
func (engtf EdgeNGramTokenFilter) AsCjkBigramTokenFilter() (*CjkBigramTokenFilter, bool) {
	return nil, false
}

// AsCommonGramTokenFilter is the TokenFilter implementation for EdgeNGramTokenFilter.
func (engtf EdgeNGramTokenFilter) AsCommonGramTokenFilter() (*CommonGramTokenFilter, bool) {
	return nil, false
}

// AsDictionaryDecompounderTokenFilter is the TokenFilter implementation for EdgeNGramTokenFilter.
func (engtf EdgeNGramTokenFilter) AsDictionaryDecompounderTokenFilter() (*DictionaryDecompounderTokenFilter, bool) {
	return nil, false
}

// AsEdgeNGramTokenFilter is the TokenFilter implementation for EdgeNGramTokenFilter.
func (engtf EdgeNGramTokenFilter) AsEdgeNGramTokenFilter() (*EdgeNGramTokenFilter, bool) {
	return &engtf, true
}

// AsEdgeNGramTokenFilterV2 is the TokenFilter implementation for EdgeNGramTokenFilter.
func (engtf EdgeNGramTokenFilter) AsEdgeNGramTokenFilterV2() (*EdgeNGramTokenFilterV2, bool) {
	return nil, false
}

// AsElisionTokenFilter is the TokenFilter implementation for EdgeNGramTokenFilter.
func (engtf EdgeNGramTokenFilter) AsElisionTokenFilter() (*ElisionTokenFilter, bool) {
	return nil, false
}

// AsKeepTokenFilter is the TokenFilter implementation for EdgeNGramTokenFilter.
func (engtf EdgeNGramTokenFilter) AsKeepTokenFilter() (*KeepTokenFilter, bool) {
	return nil, false
}

// AsKeywordMarkerTokenFilter is the TokenFilter implementation for EdgeNGramTokenFilter.
func (engtf EdgeNGramTokenFilter) AsKeywordMarkerTokenFilter() (*KeywordMarkerTokenFilter, bool) {
	return nil, false
}

// AsLengthTokenFilter is the TokenFilter implementation for EdgeNGramTokenFilter.
func (engtf EdgeNGramTokenFilter) AsLengthTokenFilter() (*LengthTokenFilter, bool) {
	return nil, false
}

// AsLimitTokenFilter is the TokenFilter implementation for EdgeNGramTokenFilter.
func (engtf EdgeNGramTokenFilter) AsLimitTokenFilter() (*LimitTokenFilter, bool) {
	return nil, false
}

// AsNGramTokenFilter is the TokenFilter implementation for EdgeNGramTokenFilter.
func (engtf EdgeNGramTokenFilter) AsNGramTokenFilter() (*NGramTokenFilter, bool) {
	return nil, false
}

// AsNGramTokenFilterV2 is the TokenFilter implementation for EdgeNGramTokenFilter.
func (engtf EdgeNGramTokenFilter) AsNGramTokenFilterV2() (*NGramTokenFilterV2, bool) {
	return nil, false
}

// AsPatternCaptureTokenFilter is the TokenFilter implementation for EdgeNGramTokenFilter.
func (engtf EdgeNGramTokenFilter) AsPatternCaptureTokenFilter() (*PatternCaptureTokenFilter, bool) {
	return nil, false
}

// AsPatternReplaceTokenFilter is the TokenFilter implementation for EdgeNGramTokenFilter.
func (engtf EdgeNGramTokenFilter) AsPatternReplaceTokenFilter() (*PatternReplaceTokenFilter, bool) {
	return nil, false
}

// AsPhoneticTokenFilter is the TokenFilter implementation for EdgeNGramTokenFilter.
func (engtf EdgeNGramTokenFilter) AsPhoneticTokenFilter() (*PhoneticTokenFilter, bool) {
	return nil, false
}

// AsShingleTokenFilter is the TokenFilter implementation for EdgeNGramTokenFilter.
func (engtf EdgeNGramTokenFilter) AsShingleTokenFilter() (*ShingleTokenFilter, bool) {
	return nil, false
}

// AsSnowballTokenFilter is the TokenFilter implementation for EdgeNGramTokenFilter.
func (engtf EdgeNGramTokenFilter) AsSnowballTokenFilter() (*SnowballTokenFilter, bool) {
	return nil, false
}

// AsStemmerTokenFilter is the TokenFilter implementation for EdgeNGramTokenFilter.
func (engtf EdgeNGramTokenFilter) AsStemmerTokenFilter() (*StemmerTokenFilter, bool) {
	return nil, false
}

// AsStemmerOverrideTokenFilter is the TokenFilter implementation for EdgeNGramTokenFilter.
func (engtf EdgeNGramTokenFilter) AsStemmerOverrideTokenFilter() (*StemmerOverrideTokenFilter, bool) {
	return nil, false
}

// AsStopwordsTokenFilter is the TokenFilter implementation for EdgeNGramTokenFilter.
func (engtf EdgeNGramTokenFilter) AsStopwordsTokenFilter() (*StopwordsTokenFilter, bool) {
	return nil, false
}

// AsSynonymTokenFilter is the TokenFilter implementation for EdgeNGramTokenFilter.
func (engtf EdgeNGramTokenFilter) AsSynonymTokenFilter() (*SynonymTokenFilter, bool) {
	return nil, false
}

// AsTruncateTokenFilter is the TokenFilter implementation for EdgeNGramTokenFilter.
func (engtf EdgeNGramTokenFilter) AsTruncateTokenFilter() (*TruncateTokenFilter, bool) {
	return nil, false
}

// AsUniqueTokenFilter is the TokenFilter implementation for EdgeNGramTokenFilter.
func (engtf EdgeNGramTokenFilter) AsUniqueTokenFilter() (*UniqueTokenFilter, bool) {
	return nil, false
}

// AsWordDelimiterTokenFilter is the TokenFilter implementation for EdgeNGramTokenFilter.
func (engtf EdgeNGramTokenFilter) AsWordDelimiterTokenFilter() (*WordDelimiterTokenFilter, bool) {
	return nil, false
}

// EdgeNGramTokenFilterV2 is generates n-grams of the given size(s) starting from the front or the back of an input
// token. This token filter is implemented using Apache Lucene.
type EdgeNGramTokenFilterV2 struct {
	Name      *string                  `json:"name,omitempty"`
	OdataType OdataType2               `json:"@odata.type,omitempty"`
	MinGram   *int32                   `json:"minGram,omitempty"`
	MaxGram   *int32                   `json:"maxGram,omitempty"`
	Side      EdgeNGramTokenFilterSide `json:"side,omitempty"`
}

// MarshalJSON is the custom marshaler for EdgeNGramTokenFilterV2.
func (engtfv EdgeNGramTokenFilterV2) MarshalJSON() ([]byte, error) {
	engtfv.OdataType = OdataTypeMicrosoftAzureSearchEdgeNGramTokenFilterV2
	type Alias EdgeNGramTokenFilterV2
	return json.Marshal(&struct {
		Alias
	}{
		Alias: (Alias)(engtfv),
	})
}

// AsASCIIFoldingTokenFilter is the TokenFilter implementation for EdgeNGramTokenFilterV2.
func (engtfv EdgeNGramTokenFilterV2) AsASCIIFoldingTokenFilter() (*ASCIIFoldingTokenFilter, bool) {
	return nil, false
}

// AsCjkBigramTokenFilter is the TokenFilter implementation for EdgeNGramTokenFilterV2.
func (engtfv EdgeNGramTokenFilterV2) AsCjkBigramTokenFilter() (*CjkBigramTokenFilter, bool) {
	return nil, false
}

// AsCommonGramTokenFilter is the TokenFilter implementation for EdgeNGramTokenFilterV2.
func (engtfv EdgeNGramTokenFilterV2) AsCommonGramTokenFilter() (*CommonGramTokenFilter, bool) {
	return nil, false
}

// AsDictionaryDecompounderTokenFilter is the TokenFilter implementation for EdgeNGramTokenFilterV2.
func (engtfv EdgeNGramTokenFilterV2) AsDictionaryDecompounderTokenFilter() (*DictionaryDecompounderTokenFilter, bool) {
	return nil, false
}

// AsEdgeNGramTokenFilter is the TokenFilter implementation for EdgeNGramTokenFilterV2.
func (engtfv EdgeNGramTokenFilterV2) AsEdgeNGramTokenFilter() (*EdgeNGramTokenFilter, bool) {
	return nil, false
}

// AsEdgeNGramTokenFilterV2 is the TokenFilter implementation for EdgeNGramTokenFilterV2.
func (engtfv EdgeNGramTokenFilterV2) AsEdgeNGramTokenFilterV2() (*EdgeNGramTokenFilterV2, bool) {
	return &engtfv, true
}

// AsElisionTokenFilter is the TokenFilter implementation for EdgeNGramTokenFilterV2.
func (engtfv EdgeNGramTokenFilterV2) AsElisionTokenFilter() (*ElisionTokenFilter, bool) {
	return nil, false
}

// AsKeepTokenFilter is the TokenFilter implementation for EdgeNGramTokenFilterV2.
func (engtfv EdgeNGramTokenFilterV2) AsKeepTokenFilter() (*KeepTokenFilter, bool) {
	return nil, false
}

// AsKeywordMarkerTokenFilter is the TokenFilter implementation for EdgeNGramTokenFilterV2.
func (engtfv EdgeNGramTokenFilterV2) AsKeywordMarkerTokenFilter() (*KeywordMarkerTokenFilter, bool) {
	return nil, false
}

// AsLengthTokenFilter is the TokenFilter implementation for EdgeNGramTokenFilterV2.
func (engtfv EdgeNGramTokenFilterV2) AsLengthTokenFilter() (*LengthTokenFilter, bool) {
	return nil, false
}

// AsLimitTokenFilter is the TokenFilter implementation for EdgeNGramTokenFilterV2.
func (engtfv EdgeNGramTokenFilterV2) AsLimitTokenFilter() (*LimitTokenFilter, bool) {
	return nil, false
}

// AsNGramTokenFilter is the TokenFilter implementation for EdgeNGramTokenFilterV2.
func (engtfv EdgeNGramTokenFilterV2) AsNGramTokenFilter() (*NGramTokenFilter, bool) {
	return nil, false
}

// AsNGramTokenFilterV2 is the TokenFilter implementation for EdgeNGramTokenFilterV2.
func (engtfv EdgeNGramTokenFilterV2) AsNGramTokenFilterV2() (*NGramTokenFilterV2, bool) {
	return nil, false
}

// AsPatternCaptureTokenFilter is the TokenFilter implementation for EdgeNGramTokenFilterV2.
func (engtfv EdgeNGramTokenFilterV2) AsPatternCaptureTokenFilter() (*PatternCaptureTokenFilter, bool) {
	return nil, false
}

// AsPatternReplaceTokenFilter is the TokenFilter implementation for EdgeNGramTokenFilterV2.
func (engtfv EdgeNGramTokenFilterV2) AsPatternReplaceTokenFilter() (*PatternReplaceTokenFilter, bool) {
	return nil, false
}

// AsPhoneticTokenFilter is the TokenFilter implementation for EdgeNGramTokenFilterV2.
func (engtfv EdgeNGramTokenFilterV2) AsPhoneticTokenFilter() (*PhoneticTokenFilter, bool) {
	return nil, false
}

// AsShingleTokenFilter is the TokenFilter implementation for EdgeNGramTokenFilterV2.
func (engtfv EdgeNGramTokenFilterV2) AsShingleTokenFilter() (*ShingleTokenFilter, bool) {
	return nil, false
}

// AsSnowballTokenFilter is the TokenFilter implementation for EdgeNGramTokenFilterV2.
func (engtfv EdgeNGramTokenFilterV2) AsSnowballTokenFilter() (*SnowballTokenFilter, bool) {
	return nil, false
}

// AsStemmerTokenFilter is the TokenFilter implementation for EdgeNGramTokenFilterV2.
func (engtfv EdgeNGramTokenFilterV2) AsStemmerTokenFilter() (*StemmerTokenFilter, bool) {
	return nil, false
}

// AsStemmerOverrideTokenFilter is the TokenFilter implementation for EdgeNGramTokenFilterV2.
func (engtfv EdgeNGramTokenFilterV2) AsStemmerOverrideTokenFilter() (*StemmerOverrideTokenFilter, bool) {
	return nil, false
}

// AsStopwordsTokenFilter is the TokenFilter implementation for EdgeNGramTokenFilterV2.
func (engtfv EdgeNGramTokenFilterV2) AsStopwordsTokenFilter() (*StopwordsTokenFilter, bool) {
	return nil, false
}

// AsSynonymTokenFilter is the TokenFilter implementation for EdgeNGramTokenFilterV2.
func (engtfv EdgeNGramTokenFilterV2) AsSynonymTokenFilter() (*SynonymTokenFilter, bool) {
	return nil, false
}

// AsTruncateTokenFilter is the TokenFilter implementation for EdgeNGramTokenFilterV2.
func (engtfv EdgeNGramTokenFilterV2) AsTruncateTokenFilter() (*TruncateTokenFilter, bool) {
	return nil, false
}

// AsUniqueTokenFilter is the TokenFilter implementation for EdgeNGramTokenFilterV2.
func (engtfv EdgeNGramTokenFilterV2) AsUniqueTokenFilter() (*UniqueTokenFilter, bool) {
	return nil, false
}

// AsWordDelimiterTokenFilter is the TokenFilter implementation for EdgeNGramTokenFilterV2.
func (engtfv EdgeNGramTokenFilterV2) AsWordDelimiterTokenFilter() (*WordDelimiterTokenFilter, bool) {
	return nil, false
}

// EdgeNGramTokenizer is tokenizes the input from an edge into n-grams of the given size(s). This tokenizer is
// implemented using Apache Lucene.
type EdgeNGramTokenizer struct {
	Name       *string               `json:"name,omitempty"`
	OdataType  OdataType1            `json:"@odata.type,omitempty"`
	MinGram    *int32                `json:"minGram,omitempty"`
	MaxGram    *int32                `json:"maxGram,omitempty"`
	TokenChars *[]TokenCharacterKind `json:"tokenChars,omitempty"`
}

// MarshalJSON is the custom marshaler for EdgeNGramTokenizer.
func (engt EdgeNGramTokenizer) MarshalJSON() ([]byte, error) {
	engt.OdataType = OdataTypeMicrosoftAzureSearchEdgeNGramTokenizer
	type Alias EdgeNGramTokenizer
	return json.Marshal(&struct {
		Alias
	}{
		Alias: (Alias)(engt),
	})
}

// AsClassicTokenizer is the Tokenizer implementation for EdgeNGramTokenizer.
func (engt EdgeNGramTokenizer) AsClassicTokenizer() (*ClassicTokenizer, bool) {
	return nil, false
}

// AsEdgeNGramTokenizer is the Tokenizer implementation for EdgeNGramTokenizer.
func (engt EdgeNGramTokenizer) AsEdgeNGramTokenizer() (*EdgeNGramTokenizer, bool) {
	return &engt, true
}

// AsKeywordTokenizer is the Tokenizer implementation for EdgeNGramTokenizer.
func (engt EdgeNGramTokenizer) AsKeywordTokenizer() (*KeywordTokenizer, bool) {
	return nil, false
}

// AsKeywordTokenizerV2 is the Tokenizer implementation for EdgeNGramTokenizer.
func (engt EdgeNGramTokenizer) AsKeywordTokenizerV2() (*KeywordTokenizerV2, bool) {
	return nil, false
}

// AsMicrosoftLanguageTokenizer is the Tokenizer implementation for EdgeNGramTokenizer.
func (engt EdgeNGramTokenizer) AsMicrosoftLanguageTokenizer() (*MicrosoftLanguageTokenizer, bool) {
	return nil, false
}

// AsMicrosoftLanguageStemmingTokenizer is the Tokenizer implementation for EdgeNGramTokenizer.
func (engt EdgeNGramTokenizer) AsMicrosoftLanguageStemmingTokenizer() (*MicrosoftLanguageStemmingTokenizer, bool) {
	return nil, false
}

// AsNGramTokenizer is the Tokenizer implementation for EdgeNGramTokenizer.
func (engt EdgeNGramTokenizer) AsNGramTokenizer() (*NGramTokenizer, bool) {
	return nil, false
}

// AsPathHierarchyTokenizer is the Tokenizer implementation for EdgeNGramTokenizer.
func (engt EdgeNGramTokenizer) AsPathHierarchyTokenizer() (*PathHierarchyTokenizer, bool) {
	return nil, false
}

// AsPathHierarchyTokenizerV2 is the Tokenizer implementation for EdgeNGramTokenizer.
func (engt EdgeNGramTokenizer) AsPathHierarchyTokenizerV2() (*PathHierarchyTokenizerV2, bool) {
	return nil, false
}

// AsPatternTokenizer is the Tokenizer implementation for EdgeNGramTokenizer.
func (engt EdgeNGramTokenizer) AsPatternTokenizer() (*PatternTokenizer, bool) {
	return nil, false
}

// AsStandardTokenizer is the Tokenizer implementation for EdgeNGramTokenizer.
func (engt EdgeNGramTokenizer) AsStandardTokenizer() (*StandardTokenizer, bool) {
	return nil, false
}

// AsStandardTokenizerV2 is the Tokenizer implementation for EdgeNGramTokenizer.
func (engt EdgeNGramTokenizer) AsStandardTokenizerV2() (*StandardTokenizerV2, bool) {
	return nil, false
}

// AsUaxURLEmailTokenizer is the Tokenizer implementation for EdgeNGramTokenizer.
func (engt EdgeNGramTokenizer) AsUaxURLEmailTokenizer() (*UaxURLEmailTokenizer, bool) {
	return nil, false
}

// ElisionTokenFilter is removes elisions. For example, "l'avion" (the plane) will be converted to "avion" (plane).
// This token filter is implemented using Apache Lucene.
type ElisionTokenFilter struct {
	Name      *string    `json:"name,omitempty"`
	OdataType OdataType2 `json:"@odata.type,omitempty"`
	Articles  *[]string  `json:"articles,omitempty"`
}

// MarshalJSON is the custom marshaler for ElisionTokenFilter.
func (etf ElisionTokenFilter) MarshalJSON() ([]byte, error) {
	etf.OdataType = OdataTypeMicrosoftAzureSearchElisionTokenFilter
	type Alias ElisionTokenFilter
	return json.Marshal(&struct {
		Alias
	}{
		Alias: (Alias)(etf),
	})
}

// AsASCIIFoldingTokenFilter is the TokenFilter implementation for ElisionTokenFilter.
func (etf ElisionTokenFilter) AsASCIIFoldingTokenFilter() (*ASCIIFoldingTokenFilter, bool) {
	return nil, false
}

// AsCjkBigramTokenFilter is the TokenFilter implementation for ElisionTokenFilter.
func (etf ElisionTokenFilter) AsCjkBigramTokenFilter() (*CjkBigramTokenFilter, bool) {
	return nil, false
}

// AsCommonGramTokenFilter is the TokenFilter implementation for ElisionTokenFilter.
func (etf ElisionTokenFilter) AsCommonGramTokenFilter() (*CommonGramTokenFilter, bool) {
	return nil, false
}

// AsDictionaryDecompounderTokenFilter is the TokenFilter implementation for ElisionTokenFilter.
func (etf ElisionTokenFilter) AsDictionaryDecompounderTokenFilter() (*DictionaryDecompounderTokenFilter, bool) {
	return nil, false
}

// AsEdgeNGramTokenFilter is the TokenFilter implementation for ElisionTokenFilter.
func (etf ElisionTokenFilter) AsEdgeNGramTokenFilter() (*EdgeNGramTokenFilter, bool) {
	return nil, false
}

// AsEdgeNGramTokenFilterV2 is the TokenFilter implementation for ElisionTokenFilter.
func (etf ElisionTokenFilter) AsEdgeNGramTokenFilterV2() (*EdgeNGramTokenFilterV2, bool) {
	return nil, false
}

// AsElisionTokenFilter is the TokenFilter implementation for ElisionTokenFilter.
func (etf ElisionTokenFilter) AsElisionTokenFilter() (*ElisionTokenFilter, bool) {
	return &etf, true
}

// AsKeepTokenFilter is the TokenFilter implementation for ElisionTokenFilter.
func (etf ElisionTokenFilter) AsKeepTokenFilter() (*KeepTokenFilter, bool) {
	return nil, false
}

// AsKeywordMarkerTokenFilter is the TokenFilter implementation for ElisionTokenFilter.
func (etf ElisionTokenFilter) AsKeywordMarkerTokenFilter() (*KeywordMarkerTokenFilter, bool) {
	return nil, false
}

// AsLengthTokenFilter is the TokenFilter implementation for ElisionTokenFilter.
func (etf ElisionTokenFilter) AsLengthTokenFilter() (*LengthTokenFilter, bool) {
	return nil, false
}

// AsLimitTokenFilter is the TokenFilter implementation for ElisionTokenFilter.
func (etf ElisionTokenFilter) AsLimitTokenFilter() (*LimitTokenFilter, bool) {
	return nil, false
}

// AsNGramTokenFilter is the TokenFilter implementation for ElisionTokenFilter.
func (etf ElisionTokenFilter) AsNGramTokenFilter() (*NGramTokenFilter, bool) {
	return nil, false
}

// AsNGramTokenFilterV2 is the TokenFilter implementation for ElisionTokenFilter.
func (etf ElisionTokenFilter) AsNGramTokenFilterV2() (*NGramTokenFilterV2, bool) {
	return nil, false
}

// AsPatternCaptureTokenFilter is the TokenFilter implementation for ElisionTokenFilter.
func (etf ElisionTokenFilter) AsPatternCaptureTokenFilter() (*PatternCaptureTokenFilter, bool) {
	return nil, false
}

// AsPatternReplaceTokenFilter is the TokenFilter implementation for ElisionTokenFilter.
func (etf ElisionTokenFilter) AsPatternReplaceTokenFilter() (*PatternReplaceTokenFilter, bool) {
	return nil, false
}

// AsPhoneticTokenFilter is the TokenFilter implementation for ElisionTokenFilter.
func (etf ElisionTokenFilter) AsPhoneticTokenFilter() (*PhoneticTokenFilter, bool) {
	return nil, false
}

// AsShingleTokenFilter is the TokenFilter implementation for ElisionTokenFilter.
func (etf ElisionTokenFilter) AsShingleTokenFilter() (*ShingleTokenFilter, bool) {
	return nil, false
}

// AsSnowballTokenFilter is the TokenFilter implementation for ElisionTokenFilter.
func (etf ElisionTokenFilter) AsSnowballTokenFilter() (*SnowballTokenFilter, bool) {
	return nil, false
}

// AsStemmerTokenFilter is the TokenFilter implementation for ElisionTokenFilter.
func (etf ElisionTokenFilter) AsStemmerTokenFilter() (*StemmerTokenFilter, bool) {
	return nil, false
}

// AsStemmerOverrideTokenFilter is the TokenFilter implementation for ElisionTokenFilter.
func (etf ElisionTokenFilter) AsStemmerOverrideTokenFilter() (*StemmerOverrideTokenFilter, bool) {
	return nil, false
}

// AsStopwordsTokenFilter is the TokenFilter implementation for ElisionTokenFilter.
func (etf ElisionTokenFilter) AsStopwordsTokenFilter() (*StopwordsTokenFilter, bool) {
	return nil, false
}

// AsSynonymTokenFilter is the TokenFilter implementation for ElisionTokenFilter.
func (etf ElisionTokenFilter) AsSynonymTokenFilter() (*SynonymTokenFilter, bool) {
	return nil, false
}

// AsTruncateTokenFilter is the TokenFilter implementation for ElisionTokenFilter.
func (etf ElisionTokenFilter) AsTruncateTokenFilter() (*TruncateTokenFilter, bool) {
	return nil, false
}

// AsUniqueTokenFilter is the TokenFilter implementation for ElisionTokenFilter.
func (etf ElisionTokenFilter) AsUniqueTokenFilter() (*UniqueTokenFilter, bool) {
	return nil, false
}

// AsWordDelimiterTokenFilter is the TokenFilter implementation for ElisionTokenFilter.
func (etf ElisionTokenFilter) AsWordDelimiterTokenFilter() (*WordDelimiterTokenFilter, bool) {
	return nil, false
}

// Field is represents a field in an index definition in Azure Search, which describes the name, data type, and search
// behavior of a field.
type Field struct {
	Name           *string       `json:"name,omitempty"`
	Type           *DataType     `json:"type,omitempty"`
	Analyzer       *AnalyzerName `json:"analyzer,omitempty"`
	SearchAnalyzer *AnalyzerName `json:"searchAnalyzer,omitempty"`
	IndexAnalyzer  *AnalyzerName `json:"indexAnalyzer,omitempty"`
	IsKey          *bool         `json:"key,omitempty"`
	IsSearchable   *bool         `json:"searchable,omitempty"`
	IsFilterable   *bool         `json:"filterable,omitempty"`
	IsSortable     *bool         `json:"sortable,omitempty"`
	IsFacetable    *bool         `json:"facetable,omitempty"`
	IsRetrievable  *bool         `json:"retrievable,omitempty"`
}

// FieldMapping is defines a mapping between a field in a data source and a target field in an index.
type FieldMapping struct {
	SourceFieldName *string               `json:"sourceFieldName,omitempty"`
	TargetFieldName *string               `json:"targetFieldName,omitempty"`
	MappingFunction *FieldMappingFunction `json:"mappingFunction,omitempty"`
}

// FieldMappingFunction is represents a function that transforms a value from a data source before indexing.
type FieldMappingFunction struct {
	Name       *string                             `json:"name,omitempty"`
	Parameters *map[string]*map[string]interface{} `json:"parameters,omitempty"`
}

// FreshnessScoringFunction is defines a function that boosts scores based on the value of a date-time field.
type FreshnessScoringFunction struct {
	FieldName     *string                      `json:"fieldName,omitempty"`
	Boost         *float64                     `json:"boost,omitempty"`
	Interpolation ScoringFunctionInterpolation `json:"interpolation,omitempty"`
	Type          Type                         `json:"type,omitempty"`
	Parameters    *FreshnessScoringParameters  `json:"freshness,omitempty"`
}

// MarshalJSON is the custom marshaler for FreshnessScoringFunction.
func (fsf FreshnessScoringFunction) MarshalJSON() ([]byte, error) {
	fsf.Type = TypeFreshness
	type Alias FreshnessScoringFunction
	return json.Marshal(&struct {
		Alias
	}{
		Alias: (Alias)(fsf),
	})
}

// AsDistanceScoringFunction is the ScoringFunction implementation for FreshnessScoringFunction.
func (fsf FreshnessScoringFunction) AsDistanceScoringFunction() (*DistanceScoringFunction, bool) {
	return nil, false
}

// AsFreshnessScoringFunction is the ScoringFunction implementation for FreshnessScoringFunction.
func (fsf FreshnessScoringFunction) AsFreshnessScoringFunction() (*FreshnessScoringFunction, bool) {
	return &fsf, true
}

// AsMagnitudeScoringFunction is the ScoringFunction implementation for FreshnessScoringFunction.
func (fsf FreshnessScoringFunction) AsMagnitudeScoringFunction() (*MagnitudeScoringFunction, bool) {
	return nil, false
}

// AsTagScoringFunction is the ScoringFunction implementation for FreshnessScoringFunction.
func (fsf FreshnessScoringFunction) AsTagScoringFunction() (*TagScoringFunction, bool) {
	return nil, false
}

// FreshnessScoringParameters is provides parameter values to a freshness scoring function.
type FreshnessScoringParameters struct {
	BoostingDuration *string `json:"boostingDuration,omitempty"`
}

// HighWaterMarkChangeDetectionPolicy is defines a data change detection policy that captures changes based on the
// value of a high water mark column.
type HighWaterMarkChangeDetectionPolicy struct {
	OdataType               OdataType4 `json:"@odata.type,omitempty"`
	HighWaterMarkColumnName *string    `json:"highWaterMarkColumnName,omitempty"`
}

// MarshalJSON is the custom marshaler for HighWaterMarkChangeDetectionPolicy.
func (hwmcdp HighWaterMarkChangeDetectionPolicy) MarshalJSON() ([]byte, error) {
	hwmcdp.OdataType = OdataTypeMicrosoftAzureSearchHighWaterMarkChangeDetectionPolicy
	type Alias HighWaterMarkChangeDetectionPolicy
	return json.Marshal(&struct {
		Alias
	}{
		Alias: (Alias)(hwmcdp),
	})
}

// AsHighWaterMarkChangeDetectionPolicy is the DataChangeDetectionPolicy implementation for HighWaterMarkChangeDetectionPolicy.
func (hwmcdp HighWaterMarkChangeDetectionPolicy) AsHighWaterMarkChangeDetectionPolicy() (*HighWaterMarkChangeDetectionPolicy, bool) {
	return &hwmcdp, true
}

// AsSQLIntegratedChangeTrackingPolicy is the DataChangeDetectionPolicy implementation for HighWaterMarkChangeDetectionPolicy.
func (hwmcdp HighWaterMarkChangeDetectionPolicy) AsSQLIntegratedChangeTrackingPolicy() (*SQLIntegratedChangeTrackingPolicy, bool) {
	return nil, false
}

// Index is represents an index definition in Azure Search, which describes the fields and search behavior of an index.
type Index struct {
	autorest.Response     `json:"-"`
	Name                  *string           `json:"name,omitempty"`
	Fields                *[]Field          `json:"fields,omitempty"`
	ScoringProfiles       *[]ScoringProfile `json:"scoringProfiles,omitempty"`
	DefaultScoringProfile *string           `json:"defaultScoringProfile,omitempty"`
	CorsOptions           *CorsOptions      `json:"corsOptions,omitempty"`
	Suggesters            *[]Suggester      `json:"suggesters,omitempty"`
	Analyzers             *[]Analyzer       `json:"analyzers,omitempty"`
	Tokenizers            *[]Tokenizer      `json:"tokenizers,omitempty"`
	TokenFilters          *[]TokenFilter    `json:"tokenFilters,omitempty"`
	CharFilters           *[]CharFilter     `json:"charFilters,omitempty"`
	ETag                  *string           `json:"@odata.etag,omitempty"`
}

// UnmarshalJSON is the custom unmarshaler for Index struct.
func (i *Index) UnmarshalJSON(body []byte) error {
	var m map[string]*json.RawMessage
	err := json.Unmarshal(body, &m)
	if err != nil {
		return err
	}
	var v *json.RawMessage

	v = m["name"]
	if v != nil {
		var name string
		err = json.Unmarshal(*m["name"], &name)
		if err != nil {
			return err
		}
		i.Name = &name
	}

	v = m["fields"]
	if v != nil {
		var fields []Field
		err = json.Unmarshal(*m["fields"], &fields)
		if err != nil {
			return err
		}
		i.Fields = &fields
	}

	v = m["scoringProfiles"]
	if v != nil {
		var scoringProfiles []ScoringProfile
		err = json.Unmarshal(*m["scoringProfiles"], &scoringProfiles)
		if err != nil {
			return err
		}
		i.ScoringProfiles = &scoringProfiles
	}

	v = m["defaultScoringProfile"]
	if v != nil {
		var defaultScoringProfile string
		err = json.Unmarshal(*m["defaultScoringProfile"], &defaultScoringProfile)
		if err != nil {
			return err
		}
		i.DefaultScoringProfile = &defaultScoringProfile
	}

	v = m["corsOptions"]
	if v != nil {
		var corsOptions CorsOptions
		err = json.Unmarshal(*m["corsOptions"], &corsOptions)
		if err != nil {
			return err
		}
		i.CorsOptions = &corsOptions
	}

	v = m["suggesters"]
	if v != nil {
		var suggesters []Suggester
		err = json.Unmarshal(*m["suggesters"], &suggesters)
		if err != nil {
			return err
		}
		i.Suggesters = &suggesters
	}

	v = m["analyzers"]
	if v != nil {
		analyzers, err := unmarshalAnalyzerArray(*m["analyzers"])
		if err != nil {
			return err
		}
		i.Analyzers = &analyzers
	}

	v = m["tokenizers"]
	if v != nil {
		tokenizers, err := unmarshalTokenizerArray(*m["tokenizers"])
		if err != nil {
			return err
		}
		i.Tokenizers = &tokenizers
	}

	v = m["tokenFilters"]
	if v != nil {
		tokenFilters, err := unmarshalTokenFilterArray(*m["tokenFilters"])
		if err != nil {
			return err
		}
		i.TokenFilters = &tokenFilters
	}

	v = m["charFilters"]
	if v != nil {
		charFilters, err := unmarshalCharFilterArray(*m["charFilters"])
		if err != nil {
			return err
		}
		i.CharFilters = &charFilters
	}

	v = m["@odata.etag"]
	if v != nil {
		var odataetag string
		err = json.Unmarshal(*m["@odata.etag"], &odataetag)
		if err != nil {
			return err
		}
		i.ETag = &odataetag
	}

	return nil
}

// Indexer is represents an Azure Search indexer.
type Indexer struct {
	autorest.Response `json:"-"`
	Name              *string             `json:"name,omitempty"`
	Description       *string             `json:"description,omitempty"`
	DataSourceName    *string             `json:"dataSourceName,omitempty"`
	TargetIndexName   *string             `json:"targetIndexName,omitempty"`
	Schedule          *IndexingSchedule   `json:"schedule,omitempty"`
	Parameters        *IndexingParameters `json:"parameters,omitempty"`
	FieldMappings     *[]FieldMapping     `json:"fieldMappings,omitempty"`
	IsDisabled        *bool               `json:"disabled,omitempty"`
	ETag              *string             `json:"@odata.etag,omitempty"`
}

// IndexerExecutionInfo is represents the current status and execution history of an indexer.
type IndexerExecutionInfo struct {
	autorest.Response `json:"-"`
	Status            IndexerStatus             `json:"status,omitempty"`
	LastResult        *IndexerExecutionResult   `json:"lastResult,omitempty"`
	ExecutionHistory  *[]IndexerExecutionResult `json:"executionHistory,omitempty"`
}

// IndexerExecutionResult is represents the result of an individual indexer execution.
type IndexerExecutionResult struct {
	Status               IndexerExecutionStatus `json:"status,omitempty"`
	ErrorMessage         *string                `json:"errorMessage,omitempty"`
	StartTime            *date.Time             `json:"startTime,omitempty"`
	EndTime              *date.Time             `json:"endTime,omitempty"`
	Errors               *[]ItemError           `json:"errors,omitempty"`
	ItemCount            *int32                 `json:"itemsProcessed,omitempty"`
	FailedItemCount      *int32                 `json:"itemsFailed,omitempty"`
	InitialTrackingState *string                `json:"initialTrackingState,omitempty"`
	FinalTrackingState   *string                `json:"finalTrackingState,omitempty"`
}

// IndexerListResult is response from a List Indexers request. If successful, it includes the full definitions of all
// indexers.
type IndexerListResult struct {
	autorest.Response `json:"-"`
	Indexers          *[]Indexer `json:"value,omitempty"`
}

// IndexGetStatisticsResult is statistics for a given index. Statistics are collected periodically and are not
// guaranteed to always be up-to-date.
type IndexGetStatisticsResult struct {
	autorest.Response `json:"-"`
	DocumentCount     *int64 `json:"documentCount,omitempty"`
	StorageSize       *int64 `json:"storageSize,omitempty"`
}

// IndexingParameters is represents parameters for indexer execution.
type IndexingParameters struct {
	BatchSize              *int32                              `json:"batchSize,omitempty"`
	MaxFailedItems         *int32                              `json:"maxFailedItems,omitempty"`
	MaxFailedItemsPerBatch *int32                              `json:"maxFailedItemsPerBatch,omitempty"`
	Base64EncodeKeys       *bool                               `json:"base64EncodeKeys,omitempty"`
	Configuration          *map[string]*map[string]interface{} `json:"configuration,omitempty"`
}

// IndexingResult is status of an indexing operation for a single document.
type IndexingResult struct {
	Key          *string `json:"key,omitempty"`
	ErrorMessage *string `json:"errorMessage,omitempty"`
	Succeeded    *bool   `json:"status,omitempty"`
	StatusCode   *int32  `json:"statusCode,omitempty"`
}

// IndexingSchedule is represents a schedule for indexer execution.
type IndexingSchedule struct {
	Interval  *string    `json:"interval,omitempty"`
	StartTime *date.Time `json:"startTime,omitempty"`
}

// IndexListResult is response from a List Indexes request. If successful, it includes the full definitions of all
// indexes.
type IndexListResult struct {
	autorest.Response `json:"-"`
	Indexes           *[]Index `json:"value,omitempty"`
}

// Int64 is
type Int64 struct {
	autorest.Response `json:"-"`
	Value             *int64 `json:"value,omitempty"`
}

// ItemError is represents an item- or document-level indexing error.
type ItemError struct {
	Key          *string `json:"key,omitempty"`
	ErrorMessage *string `json:"errorMessage,omitempty"`
}

// KeepTokenFilter is a token filter that only keeps tokens with text contained in a specified list of words. This
// token filter is implemented using Apache Lucene.
type KeepTokenFilter struct {
	Name               *string    `json:"name,omitempty"`
	OdataType          OdataType2 `json:"@odata.type,omitempty"`
	KeepWords          *[]string  `json:"keepWords,omitempty"`
	LowerCaseKeepWords *bool      `json:"keepWordsCase,omitempty"`
}

// MarshalJSON is the custom marshaler for KeepTokenFilter.
func (ktf KeepTokenFilter) MarshalJSON() ([]byte, error) {
	ktf.OdataType = OdataTypeMicrosoftAzureSearchKeepTokenFilter
	type Alias KeepTokenFilter
	return json.Marshal(&struct {
		Alias
	}{
		Alias: (Alias)(ktf),
	})
}

// AsASCIIFoldingTokenFilter is the TokenFilter implementation for KeepTokenFilter.
func (ktf KeepTokenFilter) AsASCIIFoldingTokenFilter() (*ASCIIFoldingTokenFilter, bool) {
	return nil, false
}

// AsCjkBigramTokenFilter is the TokenFilter implementation for KeepTokenFilter.
func (ktf KeepTokenFilter) AsCjkBigramTokenFilter() (*CjkBigramTokenFilter, bool) {
	return nil, false
}

// AsCommonGramTokenFilter is the TokenFilter implementation for KeepTokenFilter.
func (ktf KeepTokenFilter) AsCommonGramTokenFilter() (*CommonGramTokenFilter, bool) {
	return nil, false
}

// AsDictionaryDecompounderTokenFilter is the TokenFilter implementation for KeepTokenFilter.
func (ktf KeepTokenFilter) AsDictionaryDecompounderTokenFilter() (*DictionaryDecompounderTokenFilter, bool) {
	return nil, false
}

// AsEdgeNGramTokenFilter is the TokenFilter implementation for KeepTokenFilter.
func (ktf KeepTokenFilter) AsEdgeNGramTokenFilter() (*EdgeNGramTokenFilter, bool) {
	return nil, false
}

// AsEdgeNGramTokenFilterV2 is the TokenFilter implementation for KeepTokenFilter.
func (ktf KeepTokenFilter) AsEdgeNGramTokenFilterV2() (*EdgeNGramTokenFilterV2, bool) {
	return nil, false
}

// AsElisionTokenFilter is the TokenFilter implementation for KeepTokenFilter.
func (ktf KeepTokenFilter) AsElisionTokenFilter() (*ElisionTokenFilter, bool) {
	return nil, false
}

// AsKeepTokenFilter is the TokenFilter implementation for KeepTokenFilter.
func (ktf KeepTokenFilter) AsKeepTokenFilter() (*KeepTokenFilter, bool) {
	return &ktf, true
}

// AsKeywordMarkerTokenFilter is the TokenFilter implementation for KeepTokenFilter.
func (ktf KeepTokenFilter) AsKeywordMarkerTokenFilter() (*KeywordMarkerTokenFilter, bool) {
	return nil, false
}

// AsLengthTokenFilter is the TokenFilter implementation for KeepTokenFilter.
func (ktf KeepTokenFilter) AsLengthTokenFilter() (*LengthTokenFilter, bool) {
	return nil, false
}

// AsLimitTokenFilter is the TokenFilter implementation for KeepTokenFilter.
func (ktf KeepTokenFilter) AsLimitTokenFilter() (*LimitTokenFilter, bool) {
	return nil, false
}

// AsNGramTokenFilter is the TokenFilter implementation for KeepTokenFilter.
func (ktf KeepTokenFilter) AsNGramTokenFilter() (*NGramTokenFilter, bool) {
	return nil, false
}

// AsNGramTokenFilterV2 is the TokenFilter implementation for KeepTokenFilter.
func (ktf KeepTokenFilter) AsNGramTokenFilterV2() (*NGramTokenFilterV2, bool) {
	return nil, false
}

// AsPatternCaptureTokenFilter is the TokenFilter implementation for KeepTokenFilter.
func (ktf KeepTokenFilter) AsPatternCaptureTokenFilter() (*PatternCaptureTokenFilter, bool) {
	return nil, false
}

// AsPatternReplaceTokenFilter is the TokenFilter implementation for KeepTokenFilter.
func (ktf KeepTokenFilter) AsPatternReplaceTokenFilter() (*PatternReplaceTokenFilter, bool) {
	return nil, false
}

// AsPhoneticTokenFilter is the TokenFilter implementation for KeepTokenFilter.
func (ktf KeepTokenFilter) AsPhoneticTokenFilter() (*PhoneticTokenFilter, bool) {
	return nil, false
}

// AsShingleTokenFilter is the TokenFilter implementation for KeepTokenFilter.
func (ktf KeepTokenFilter) AsShingleTokenFilter() (*ShingleTokenFilter, bool) {
	return nil, false
}

// AsSnowballTokenFilter is the TokenFilter implementation for KeepTokenFilter.
func (ktf KeepTokenFilter) AsSnowballTokenFilter() (*SnowballTokenFilter, bool) {
	return nil, false
}

// AsStemmerTokenFilter is the TokenFilter implementation for KeepTokenFilter.
func (ktf KeepTokenFilter) AsStemmerTokenFilter() (*StemmerTokenFilter, bool) {
	return nil, false
}

// AsStemmerOverrideTokenFilter is the TokenFilter implementation for KeepTokenFilter.
func (ktf KeepTokenFilter) AsStemmerOverrideTokenFilter() (*StemmerOverrideTokenFilter, bool) {
	return nil, false
}

// AsStopwordsTokenFilter is the TokenFilter implementation for KeepTokenFilter.
func (ktf KeepTokenFilter) AsStopwordsTokenFilter() (*StopwordsTokenFilter, bool) {
	return nil, false
}

// AsSynonymTokenFilter is the TokenFilter implementation for KeepTokenFilter.
func (ktf KeepTokenFilter) AsSynonymTokenFilter() (*SynonymTokenFilter, bool) {
	return nil, false
}

// AsTruncateTokenFilter is the TokenFilter implementation for KeepTokenFilter.
func (ktf KeepTokenFilter) AsTruncateTokenFilter() (*TruncateTokenFilter, bool) {
	return nil, false
}

// AsUniqueTokenFilter is the TokenFilter implementation for KeepTokenFilter.
func (ktf KeepTokenFilter) AsUniqueTokenFilter() (*UniqueTokenFilter, bool) {
	return nil, false
}

// AsWordDelimiterTokenFilter is the TokenFilter implementation for KeepTokenFilter.
func (ktf KeepTokenFilter) AsWordDelimiterTokenFilter() (*WordDelimiterTokenFilter, bool) {
	return nil, false
}

// KeywordMarkerTokenFilter is marks terms as keywords. This token filter is implemented using Apache Lucene.
type KeywordMarkerTokenFilter struct {
	Name       *string    `json:"name,omitempty"`
	OdataType  OdataType2 `json:"@odata.type,omitempty"`
	Keywords   *[]string  `json:"keywords,omitempty"`
	IgnoreCase *bool      `json:"ignoreCase,omitempty"`
}

// MarshalJSON is the custom marshaler for KeywordMarkerTokenFilter.
func (kmtf KeywordMarkerTokenFilter) MarshalJSON() ([]byte, error) {
	kmtf.OdataType = OdataTypeMicrosoftAzureSearchKeywordMarkerTokenFilter
	type Alias KeywordMarkerTokenFilter
	return json.Marshal(&struct {
		Alias
	}{
		Alias: (Alias)(kmtf),
	})
}

// AsASCIIFoldingTokenFilter is the TokenFilter implementation for KeywordMarkerTokenFilter.
func (kmtf KeywordMarkerTokenFilter) AsASCIIFoldingTokenFilter() (*ASCIIFoldingTokenFilter, bool) {
	return nil, false
}

// AsCjkBigramTokenFilter is the TokenFilter implementation for KeywordMarkerTokenFilter.
func (kmtf KeywordMarkerTokenFilter) AsCjkBigramTokenFilter() (*CjkBigramTokenFilter, bool) {
	return nil, false
}

// AsCommonGramTokenFilter is the TokenFilter implementation for KeywordMarkerTokenFilter.
func (kmtf KeywordMarkerTokenFilter) AsCommonGramTokenFilter() (*CommonGramTokenFilter, bool) {
	return nil, false
}

// AsDictionaryDecompounderTokenFilter is the TokenFilter implementation for KeywordMarkerTokenFilter.
func (kmtf KeywordMarkerTokenFilter) AsDictionaryDecompounderTokenFilter() (*DictionaryDecompounderTokenFilter, bool) {
	return nil, false
}

// AsEdgeNGramTokenFilter is the TokenFilter implementation for KeywordMarkerTokenFilter.
func (kmtf KeywordMarkerTokenFilter) AsEdgeNGramTokenFilter() (*EdgeNGramTokenFilter, bool) {
	return nil, false
}

// AsEdgeNGramTokenFilterV2 is the TokenFilter implementation for KeywordMarkerTokenFilter.
func (kmtf KeywordMarkerTokenFilter) AsEdgeNGramTokenFilterV2() (*EdgeNGramTokenFilterV2, bool) {
	return nil, false
}

// AsElisionTokenFilter is the TokenFilter implementation for KeywordMarkerTokenFilter.
func (kmtf KeywordMarkerTokenFilter) AsElisionTokenFilter() (*ElisionTokenFilter, bool) {
	return nil, false
}

// AsKeepTokenFilter is the TokenFilter implementation for KeywordMarkerTokenFilter.
func (kmtf KeywordMarkerTokenFilter) AsKeepTokenFilter() (*KeepTokenFilter, bool) {
	return nil, false
}

// AsKeywordMarkerTokenFilter is the TokenFilter implementation for KeywordMarkerTokenFilter.
func (kmtf KeywordMarkerTokenFilter) AsKeywordMarkerTokenFilter() (*KeywordMarkerTokenFilter, bool) {
	return &kmtf, true
}

// AsLengthTokenFilter is the TokenFilter implementation for KeywordMarkerTokenFilter.
func (kmtf KeywordMarkerTokenFilter) AsLengthTokenFilter() (*LengthTokenFilter, bool) {
	return nil, false
}

// AsLimitTokenFilter is the TokenFilter implementation for KeywordMarkerTokenFilter.
func (kmtf KeywordMarkerTokenFilter) AsLimitTokenFilter() (*LimitTokenFilter, bool) {
	return nil, false
}

// AsNGramTokenFilter is the TokenFilter implementation for KeywordMarkerTokenFilter.
func (kmtf KeywordMarkerTokenFilter) AsNGramTokenFilter() (*NGramTokenFilter, bool) {
	return nil, false
}

// AsNGramTokenFilterV2 is the TokenFilter implementation for KeywordMarkerTokenFilter.
func (kmtf KeywordMarkerTokenFilter) AsNGramTokenFilterV2() (*NGramTokenFilterV2, bool) {
	return nil, false
}

// AsPatternCaptureTokenFilter is the TokenFilter implementation for KeywordMarkerTokenFilter.
func (kmtf KeywordMarkerTokenFilter) AsPatternCaptureTokenFilter() (*PatternCaptureTokenFilter, bool) {
	return nil, false
}

// AsPatternReplaceTokenFilter is the TokenFilter implementation for KeywordMarkerTokenFilter.
func (kmtf KeywordMarkerTokenFilter) AsPatternReplaceTokenFilter() (*PatternReplaceTokenFilter, bool) {
	return nil, false
}

// AsPhoneticTokenFilter is the TokenFilter implementation for KeywordMarkerTokenFilter.
func (kmtf KeywordMarkerTokenFilter) AsPhoneticTokenFilter() (*PhoneticTokenFilter, bool) {
	return nil, false
}

// AsShingleTokenFilter is the TokenFilter implementation for KeywordMarkerTokenFilter.
func (kmtf KeywordMarkerTokenFilter) AsShingleTokenFilter() (*ShingleTokenFilter, bool) {
	return nil, false
}

// AsSnowballTokenFilter is the TokenFilter implementation for KeywordMarkerTokenFilter.
func (kmtf KeywordMarkerTokenFilter) AsSnowballTokenFilter() (*SnowballTokenFilter, bool) {
	return nil, false
}

// AsStemmerTokenFilter is the TokenFilter implementation for KeywordMarkerTokenFilter.
func (kmtf KeywordMarkerTokenFilter) AsStemmerTokenFilter() (*StemmerTokenFilter, bool) {
	return nil, false
}

// AsStemmerOverrideTokenFilter is the TokenFilter implementation for KeywordMarkerTokenFilter.
func (kmtf KeywordMarkerTokenFilter) AsStemmerOverrideTokenFilter() (*StemmerOverrideTokenFilter, bool) {
	return nil, false
}

// AsStopwordsTokenFilter is the TokenFilter implementation for KeywordMarkerTokenFilter.
func (kmtf KeywordMarkerTokenFilter) AsStopwordsTokenFilter() (*StopwordsTokenFilter, bool) {
	return nil, false
}

// AsSynonymTokenFilter is the TokenFilter implementation for KeywordMarkerTokenFilter.
func (kmtf KeywordMarkerTokenFilter) AsSynonymTokenFilter() (*SynonymTokenFilter, bool) {
	return nil, false
}

// AsTruncateTokenFilter is the TokenFilter implementation for KeywordMarkerTokenFilter.
func (kmtf KeywordMarkerTokenFilter) AsTruncateTokenFilter() (*TruncateTokenFilter, bool) {
	return nil, false
}

// AsUniqueTokenFilter is the TokenFilter implementation for KeywordMarkerTokenFilter.
func (kmtf KeywordMarkerTokenFilter) AsUniqueTokenFilter() (*UniqueTokenFilter, bool) {
	return nil, false
}

// AsWordDelimiterTokenFilter is the TokenFilter implementation for KeywordMarkerTokenFilter.
func (kmtf KeywordMarkerTokenFilter) AsWordDelimiterTokenFilter() (*WordDelimiterTokenFilter, bool) {
	return nil, false
}

// KeywordTokenizer is emits the entire input as a single token. This tokenizer is implemented using Apache Lucene.
type KeywordTokenizer struct {
	Name       *string    `json:"name,omitempty"`
	OdataType  OdataType1 `json:"@odata.type,omitempty"`
	BufferSize *int32     `json:"bufferSize,omitempty"`
}

// MarshalJSON is the custom marshaler for KeywordTokenizer.
func (kt KeywordTokenizer) MarshalJSON() ([]byte, error) {
	kt.OdataType = OdataTypeMicrosoftAzureSearchKeywordTokenizer
	type Alias KeywordTokenizer
	return json.Marshal(&struct {
		Alias
	}{
		Alias: (Alias)(kt),
	})
}

// AsClassicTokenizer is the Tokenizer implementation for KeywordTokenizer.
func (kt KeywordTokenizer) AsClassicTokenizer() (*ClassicTokenizer, bool) {
	return nil, false
}

// AsEdgeNGramTokenizer is the Tokenizer implementation for KeywordTokenizer.
func (kt KeywordTokenizer) AsEdgeNGramTokenizer() (*EdgeNGramTokenizer, bool) {
	return nil, false
}

// AsKeywordTokenizer is the Tokenizer implementation for KeywordTokenizer.
func (kt KeywordTokenizer) AsKeywordTokenizer() (*KeywordTokenizer, bool) {
	return &kt, true
}

// AsKeywordTokenizerV2 is the Tokenizer implementation for KeywordTokenizer.
func (kt KeywordTokenizer) AsKeywordTokenizerV2() (*KeywordTokenizerV2, bool) {
	return nil, false
}

// AsMicrosoftLanguageTokenizer is the Tokenizer implementation for KeywordTokenizer.
func (kt KeywordTokenizer) AsMicrosoftLanguageTokenizer() (*MicrosoftLanguageTokenizer, bool) {
	return nil, false
}

// AsMicrosoftLanguageStemmingTokenizer is the Tokenizer implementation for KeywordTokenizer.
func (kt KeywordTokenizer) AsMicrosoftLanguageStemmingTokenizer() (*MicrosoftLanguageStemmingTokenizer, bool) {
	return nil, false
}

// AsNGramTokenizer is the Tokenizer implementation for KeywordTokenizer.
func (kt KeywordTokenizer) AsNGramTokenizer() (*NGramTokenizer, bool) {
	return nil, false
}

// AsPathHierarchyTokenizer is the Tokenizer implementation for KeywordTokenizer.
func (kt KeywordTokenizer) AsPathHierarchyTokenizer() (*PathHierarchyTokenizer, bool) {
	return nil, false
}

// AsPathHierarchyTokenizerV2 is the Tokenizer implementation for KeywordTokenizer.
func (kt KeywordTokenizer) AsPathHierarchyTokenizerV2() (*PathHierarchyTokenizerV2, bool) {
	return nil, false
}

// AsPatternTokenizer is the Tokenizer implementation for KeywordTokenizer.
func (kt KeywordTokenizer) AsPatternTokenizer() (*PatternTokenizer, bool) {
	return nil, false
}

// AsStandardTokenizer is the Tokenizer implementation for KeywordTokenizer.
func (kt KeywordTokenizer) AsStandardTokenizer() (*StandardTokenizer, bool) {
	return nil, false
}

// AsStandardTokenizerV2 is the Tokenizer implementation for KeywordTokenizer.
func (kt KeywordTokenizer) AsStandardTokenizerV2() (*StandardTokenizerV2, bool) {
	return nil, false
}

// AsUaxURLEmailTokenizer is the Tokenizer implementation for KeywordTokenizer.
func (kt KeywordTokenizer) AsUaxURLEmailTokenizer() (*UaxURLEmailTokenizer, bool) {
	return nil, false
}

// KeywordTokenizerV2 is emits the entire input as a single token.
type KeywordTokenizerV2 struct {
	Name           *string    `json:"name,omitempty"`
	OdataType      OdataType1 `json:"@odata.type,omitempty"`
	MaxTokenLength *int32     `json:"maxTokenLength,omitempty"`
}

// MarshalJSON is the custom marshaler for KeywordTokenizerV2.
func (ktv KeywordTokenizerV2) MarshalJSON() ([]byte, error) {
	ktv.OdataType = OdataTypeMicrosoftAzureSearchKeywordTokenizerV2
	type Alias KeywordTokenizerV2
	return json.Marshal(&struct {
		Alias
	}{
		Alias: (Alias)(ktv),
	})
}

// AsClassicTokenizer is the Tokenizer implementation for KeywordTokenizerV2.
func (ktv KeywordTokenizerV2) AsClassicTokenizer() (*ClassicTokenizer, bool) {
	return nil, false
}

// AsEdgeNGramTokenizer is the Tokenizer implementation for KeywordTokenizerV2.
func (ktv KeywordTokenizerV2) AsEdgeNGramTokenizer() (*EdgeNGramTokenizer, bool) {
	return nil, false
}

// AsKeywordTokenizer is the Tokenizer implementation for KeywordTokenizerV2.
func (ktv KeywordTokenizerV2) AsKeywordTokenizer() (*KeywordTokenizer, bool) {
	return nil, false
}

// AsKeywordTokenizerV2 is the Tokenizer implementation for KeywordTokenizerV2.
func (ktv KeywordTokenizerV2) AsKeywordTokenizerV2() (*KeywordTokenizerV2, bool) {
	return &ktv, true
}

// AsMicrosoftLanguageTokenizer is the Tokenizer implementation for KeywordTokenizerV2.
func (ktv KeywordTokenizerV2) AsMicrosoftLanguageTokenizer() (*MicrosoftLanguageTokenizer, bool) {
	return nil, false
}

// AsMicrosoftLanguageStemmingTokenizer is the Tokenizer implementation for KeywordTokenizerV2.
func (ktv KeywordTokenizerV2) AsMicrosoftLanguageStemmingTokenizer() (*MicrosoftLanguageStemmingTokenizer, bool) {
	return nil, false
}

// AsNGramTokenizer is the Tokenizer implementation for KeywordTokenizerV2.
func (ktv KeywordTokenizerV2) AsNGramTokenizer() (*NGramTokenizer, bool) {
	return nil, false
}

// AsPathHierarchyTokenizer is the Tokenizer implementation for KeywordTokenizerV2.
func (ktv KeywordTokenizerV2) AsPathHierarchyTokenizer() (*PathHierarchyTokenizer, bool) {
	return nil, false
}

// AsPathHierarchyTokenizerV2 is the Tokenizer implementation for KeywordTokenizerV2.
func (ktv KeywordTokenizerV2) AsPathHierarchyTokenizerV2() (*PathHierarchyTokenizerV2, bool) {
	return nil, false
}

// AsPatternTokenizer is the Tokenizer implementation for KeywordTokenizerV2.
func (ktv KeywordTokenizerV2) AsPatternTokenizer() (*PatternTokenizer, bool) {
	return nil, false
}

// AsStandardTokenizer is the Tokenizer implementation for KeywordTokenizerV2.
func (ktv KeywordTokenizerV2) AsStandardTokenizer() (*StandardTokenizer, bool) {
	return nil, false
}

// AsStandardTokenizerV2 is the Tokenizer implementation for KeywordTokenizerV2.
func (ktv KeywordTokenizerV2) AsStandardTokenizerV2() (*StandardTokenizerV2, bool) {
	return nil, false
}

// AsUaxURLEmailTokenizer is the Tokenizer implementation for KeywordTokenizerV2.
func (ktv KeywordTokenizerV2) AsUaxURLEmailTokenizer() (*UaxURLEmailTokenizer, bool) {
	return nil, false
}

// LengthTokenFilter is removes words that are too long or too short. This token filter is implemented using Apache
// Lucene.
type LengthTokenFilter struct {
	Name      *string    `json:"name,omitempty"`
	OdataType OdataType2 `json:"@odata.type,omitempty"`
	Min       *int32     `json:"min,omitempty"`
	Max       *int32     `json:"max,omitempty"`
}

// MarshalJSON is the custom marshaler for LengthTokenFilter.
func (ltf LengthTokenFilter) MarshalJSON() ([]byte, error) {
	ltf.OdataType = OdataTypeMicrosoftAzureSearchLengthTokenFilter
	type Alias LengthTokenFilter
	return json.Marshal(&struct {
		Alias
	}{
		Alias: (Alias)(ltf),
	})
}

// AsASCIIFoldingTokenFilter is the TokenFilter implementation for LengthTokenFilter.
func (ltf LengthTokenFilter) AsASCIIFoldingTokenFilter() (*ASCIIFoldingTokenFilter, bool) {
	return nil, false
}

// AsCjkBigramTokenFilter is the TokenFilter implementation for LengthTokenFilter.
func (ltf LengthTokenFilter) AsCjkBigramTokenFilter() (*CjkBigramTokenFilter, bool) {
	return nil, false
}

// AsCommonGramTokenFilter is the TokenFilter implementation for LengthTokenFilter.
func (ltf LengthTokenFilter) AsCommonGramTokenFilter() (*CommonGramTokenFilter, bool) {
	return nil, false
}

// AsDictionaryDecompounderTokenFilter is the TokenFilter implementation for LengthTokenFilter.
func (ltf LengthTokenFilter) AsDictionaryDecompounderTokenFilter() (*DictionaryDecompounderTokenFilter, bool) {
	return nil, false
}

// AsEdgeNGramTokenFilter is the TokenFilter implementation for LengthTokenFilter.
func (ltf LengthTokenFilter) AsEdgeNGramTokenFilter() (*EdgeNGramTokenFilter, bool) {
	return nil, false
}

// AsEdgeNGramTokenFilterV2 is the TokenFilter implementation for LengthTokenFilter.
func (ltf LengthTokenFilter) AsEdgeNGramTokenFilterV2() (*EdgeNGramTokenFilterV2, bool) {
	return nil, false
}

// AsElisionTokenFilter is the TokenFilter implementation for LengthTokenFilter.
func (ltf LengthTokenFilter) AsElisionTokenFilter() (*ElisionTokenFilter, bool) {
	return nil, false
}

// AsKeepTokenFilter is the TokenFilter implementation for LengthTokenFilter.
func (ltf LengthTokenFilter) AsKeepTokenFilter() (*KeepTokenFilter, bool) {
	return nil, false
}

// AsKeywordMarkerTokenFilter is the TokenFilter implementation for LengthTokenFilter.
func (ltf LengthTokenFilter) AsKeywordMarkerTokenFilter() (*KeywordMarkerTokenFilter, bool) {
	return nil, false
}

// AsLengthTokenFilter is the TokenFilter implementation for LengthTokenFilter.
func (ltf LengthTokenFilter) AsLengthTokenFilter() (*LengthTokenFilter, bool) {
	return &ltf, true
}

// AsLimitTokenFilter is the TokenFilter implementation for LengthTokenFilter.
func (ltf LengthTokenFilter) AsLimitTokenFilter() (*LimitTokenFilter, bool) {
	return nil, false
}

// AsNGramTokenFilter is the TokenFilter implementation for LengthTokenFilter.
func (ltf LengthTokenFilter) AsNGramTokenFilter() (*NGramTokenFilter, bool) {
	return nil, false
}

// AsNGramTokenFilterV2 is the TokenFilter implementation for LengthTokenFilter.
func (ltf LengthTokenFilter) AsNGramTokenFilterV2() (*NGramTokenFilterV2, bool) {
	return nil, false
}

// AsPatternCaptureTokenFilter is the TokenFilter implementation for LengthTokenFilter.
func (ltf LengthTokenFilter) AsPatternCaptureTokenFilter() (*PatternCaptureTokenFilter, bool) {
	return nil, false
}

// AsPatternReplaceTokenFilter is the TokenFilter implementation for LengthTokenFilter.
func (ltf LengthTokenFilter) AsPatternReplaceTokenFilter() (*PatternReplaceTokenFilter, bool) {
	return nil, false
}

// AsPhoneticTokenFilter is the TokenFilter implementation for LengthTokenFilter.
func (ltf LengthTokenFilter) AsPhoneticTokenFilter() (*PhoneticTokenFilter, bool) {
	return nil, false
}

// AsShingleTokenFilter is the TokenFilter implementation for LengthTokenFilter.
func (ltf LengthTokenFilter) AsShingleTokenFilter() (*ShingleTokenFilter, bool) {
	return nil, false
}

// AsSnowballTokenFilter is the TokenFilter implementation for LengthTokenFilter.
func (ltf LengthTokenFilter) AsSnowballTokenFilter() (*SnowballTokenFilter, bool) {
	return nil, false
}

// AsStemmerTokenFilter is the TokenFilter implementation for LengthTokenFilter.
func (ltf LengthTokenFilter) AsStemmerTokenFilter() (*StemmerTokenFilter, bool) {
	return nil, false
}

// AsStemmerOverrideTokenFilter is the TokenFilter implementation for LengthTokenFilter.
func (ltf LengthTokenFilter) AsStemmerOverrideTokenFilter() (*StemmerOverrideTokenFilter, bool) {
	return nil, false
}

// AsStopwordsTokenFilter is the TokenFilter implementation for LengthTokenFilter.
func (ltf LengthTokenFilter) AsStopwordsTokenFilter() (*StopwordsTokenFilter, bool) {
	return nil, false
}

// AsSynonymTokenFilter is the TokenFilter implementation for LengthTokenFilter.
func (ltf LengthTokenFilter) AsSynonymTokenFilter() (*SynonymTokenFilter, bool) {
	return nil, false
}

// AsTruncateTokenFilter is the TokenFilter implementation for LengthTokenFilter.
func (ltf LengthTokenFilter) AsTruncateTokenFilter() (*TruncateTokenFilter, bool) {
	return nil, false
}

// AsUniqueTokenFilter is the TokenFilter implementation for LengthTokenFilter.
func (ltf LengthTokenFilter) AsUniqueTokenFilter() (*UniqueTokenFilter, bool) {
	return nil, false
}

// AsWordDelimiterTokenFilter is the TokenFilter implementation for LengthTokenFilter.
func (ltf LengthTokenFilter) AsWordDelimiterTokenFilter() (*WordDelimiterTokenFilter, bool) {
	return nil, false
}

// LimitTokenFilter is limits the number of tokens while indexing. This token filter is implemented using Apache
// Lucene.
type LimitTokenFilter struct {
	Name             *string    `json:"name,omitempty"`
	OdataType        OdataType2 `json:"@odata.type,omitempty"`
	MaxTokenCount    *int32     `json:"maxTokenCount,omitempty"`
	ConsumeAllTokens *bool      `json:"consumeAllTokens,omitempty"`
}

// MarshalJSON is the custom marshaler for LimitTokenFilter.
func (ltf LimitTokenFilter) MarshalJSON() ([]byte, error) {
	ltf.OdataType = OdataTypeMicrosoftAzureSearchLimitTokenFilter
	type Alias LimitTokenFilter
	return json.Marshal(&struct {
		Alias
	}{
		Alias: (Alias)(ltf),
	})
}

// AsASCIIFoldingTokenFilter is the TokenFilter implementation for LimitTokenFilter.
func (ltf LimitTokenFilter) AsASCIIFoldingTokenFilter() (*ASCIIFoldingTokenFilter, bool) {
	return nil, false
}

// AsCjkBigramTokenFilter is the TokenFilter implementation for LimitTokenFilter.
func (ltf LimitTokenFilter) AsCjkBigramTokenFilter() (*CjkBigramTokenFilter, bool) {
	return nil, false
}

// AsCommonGramTokenFilter is the TokenFilter implementation for LimitTokenFilter.
func (ltf LimitTokenFilter) AsCommonGramTokenFilter() (*CommonGramTokenFilter, bool) {
	return nil, false
}

// AsDictionaryDecompounderTokenFilter is the TokenFilter implementation for LimitTokenFilter.
func (ltf LimitTokenFilter) AsDictionaryDecompounderTokenFilter() (*DictionaryDecompounderTokenFilter, bool) {
	return nil, false
}

// AsEdgeNGramTokenFilter is the TokenFilter implementation for LimitTokenFilter.
func (ltf LimitTokenFilter) AsEdgeNGramTokenFilter() (*EdgeNGramTokenFilter, bool) {
	return nil, false
}

// AsEdgeNGramTokenFilterV2 is the TokenFilter implementation for LimitTokenFilter.
func (ltf LimitTokenFilter) AsEdgeNGramTokenFilterV2() (*EdgeNGramTokenFilterV2, bool) {
	return nil, false
}

// AsElisionTokenFilter is the TokenFilter implementation for LimitTokenFilter.
func (ltf LimitTokenFilter) AsElisionTokenFilter() (*ElisionTokenFilter, bool) {
	return nil, false
}

// AsKeepTokenFilter is the TokenFilter implementation for LimitTokenFilter.
func (ltf LimitTokenFilter) AsKeepTokenFilter() (*KeepTokenFilter, bool) {
	return nil, false
}

// AsKeywordMarkerTokenFilter is the TokenFilter implementation for LimitTokenFilter.
func (ltf LimitTokenFilter) AsKeywordMarkerTokenFilter() (*KeywordMarkerTokenFilter, bool) {
	return nil, false
}

// AsLengthTokenFilter is the TokenFilter implementation for LimitTokenFilter.
func (ltf LimitTokenFilter) AsLengthTokenFilter() (*LengthTokenFilter, bool) {
	return nil, false
}

// AsLimitTokenFilter is the TokenFilter implementation for LimitTokenFilter.
func (ltf LimitTokenFilter) AsLimitTokenFilter() (*LimitTokenFilter, bool) {
	return &ltf, true
}

// AsNGramTokenFilter is the TokenFilter implementation for LimitTokenFilter.
func (ltf LimitTokenFilter) AsNGramTokenFilter() (*NGramTokenFilter, bool) {
	return nil, false
}

// AsNGramTokenFilterV2 is the TokenFilter implementation for LimitTokenFilter.
func (ltf LimitTokenFilter) AsNGramTokenFilterV2() (*NGramTokenFilterV2, bool) {
	return nil, false
}

// AsPatternCaptureTokenFilter is the TokenFilter implementation for LimitTokenFilter.
func (ltf LimitTokenFilter) AsPatternCaptureTokenFilter() (*PatternCaptureTokenFilter, bool) {
	return nil, false
}

// AsPatternReplaceTokenFilter is the TokenFilter implementation for LimitTokenFilter.
func (ltf LimitTokenFilter) AsPatternReplaceTokenFilter() (*PatternReplaceTokenFilter, bool) {
	return nil, false
}

// AsPhoneticTokenFilter is the TokenFilter implementation for LimitTokenFilter.
func (ltf LimitTokenFilter) AsPhoneticTokenFilter() (*PhoneticTokenFilter, bool) {
	return nil, false
}

// AsShingleTokenFilter is the TokenFilter implementation for LimitTokenFilter.
func (ltf LimitTokenFilter) AsShingleTokenFilter() (*ShingleTokenFilter, bool) {
	return nil, false
}

// AsSnowballTokenFilter is the TokenFilter implementation for LimitTokenFilter.
func (ltf LimitTokenFilter) AsSnowballTokenFilter() (*SnowballTokenFilter, bool) {
	return nil, false
}

// AsStemmerTokenFilter is the TokenFilter implementation for LimitTokenFilter.
func (ltf LimitTokenFilter) AsStemmerTokenFilter() (*StemmerTokenFilter, bool) {
	return nil, false
}

// AsStemmerOverrideTokenFilter is the TokenFilter implementation for LimitTokenFilter.
func (ltf LimitTokenFilter) AsStemmerOverrideTokenFilter() (*StemmerOverrideTokenFilter, bool) {
	return nil, false
}

// AsStopwordsTokenFilter is the TokenFilter implementation for LimitTokenFilter.
func (ltf LimitTokenFilter) AsStopwordsTokenFilter() (*StopwordsTokenFilter, bool) {
	return nil, false
}

// AsSynonymTokenFilter is the TokenFilter implementation for LimitTokenFilter.
func (ltf LimitTokenFilter) AsSynonymTokenFilter() (*SynonymTokenFilter, bool) {
	return nil, false
}

// AsTruncateTokenFilter is the TokenFilter implementation for LimitTokenFilter.
func (ltf LimitTokenFilter) AsTruncateTokenFilter() (*TruncateTokenFilter, bool) {
	return nil, false
}

// AsUniqueTokenFilter is the TokenFilter implementation for LimitTokenFilter.
func (ltf LimitTokenFilter) AsUniqueTokenFilter() (*UniqueTokenFilter, bool) {
	return nil, false
}

// AsWordDelimiterTokenFilter is the TokenFilter implementation for LimitTokenFilter.
func (ltf LimitTokenFilter) AsWordDelimiterTokenFilter() (*WordDelimiterTokenFilter, bool) {
	return nil, false
}

// MagnitudeScoringFunction is defines a function that boosts scores based on the magnitude of a numeric field.
type MagnitudeScoringFunction struct {
	FieldName     *string                      `json:"fieldName,omitempty"`
	Boost         *float64                     `json:"boost,omitempty"`
	Interpolation ScoringFunctionInterpolation `json:"interpolation,omitempty"`
	Type          Type                         `json:"type,omitempty"`
	Parameters    *MagnitudeScoringParameters  `json:"magnitude,omitempty"`
}

// MarshalJSON is the custom marshaler for MagnitudeScoringFunction.
func (msf MagnitudeScoringFunction) MarshalJSON() ([]byte, error) {
	msf.Type = TypeMagnitude
	type Alias MagnitudeScoringFunction
	return json.Marshal(&struct {
		Alias
	}{
		Alias: (Alias)(msf),
	})
}

// AsDistanceScoringFunction is the ScoringFunction implementation for MagnitudeScoringFunction.
func (msf MagnitudeScoringFunction) AsDistanceScoringFunction() (*DistanceScoringFunction, bool) {
	return nil, false
}

// AsFreshnessScoringFunction is the ScoringFunction implementation for MagnitudeScoringFunction.
func (msf MagnitudeScoringFunction) AsFreshnessScoringFunction() (*FreshnessScoringFunction, bool) {
	return nil, false
}

// AsMagnitudeScoringFunction is the ScoringFunction implementation for MagnitudeScoringFunction.
func (msf MagnitudeScoringFunction) AsMagnitudeScoringFunction() (*MagnitudeScoringFunction, bool) {
	return &msf, true
}

// AsTagScoringFunction is the ScoringFunction implementation for MagnitudeScoringFunction.
func (msf MagnitudeScoringFunction) AsTagScoringFunction() (*TagScoringFunction, bool) {
	return nil, false
}

// MagnitudeScoringParameters is provides parameter values to a magnitude scoring function.
type MagnitudeScoringParameters struct {
	BoostingRangeStart               *float64 `json:"boostingRangeStart,omitempty"`
	BoostingRangeEnd                 *float64 `json:"boostingRangeEnd,omitempty"`
	ShouldBoostBeyondRangeByConstant *bool    `json:"constantBoostBeyondRange,omitempty"`
}

// MappingCharFilter is a character filter that applies mappings defined with the mappings option. Matching is greedy
// (longest pattern matching at a given point wins). Replacement is allowed to be the empty string. This character
// filter is implemented using Apache Lucene.
type MappingCharFilter struct {
	Name      *string    `json:"name,omitempty"`
	OdataType OdataType3 `json:"@odata.type,omitempty"`
	Mappings  *[]string  `json:"mappings,omitempty"`
}

// MarshalJSON is the custom marshaler for MappingCharFilter.
func (mcf MappingCharFilter) MarshalJSON() ([]byte, error) {
	mcf.OdataType = OdataTypeMicrosoftAzureSearchMappingCharFilter
	type Alias MappingCharFilter
	return json.Marshal(&struct {
		Alias
	}{
		Alias: (Alias)(mcf),
	})
}

// AsMappingCharFilter is the CharFilter implementation for MappingCharFilter.
func (mcf MappingCharFilter) AsMappingCharFilter() (*MappingCharFilter, bool) {
	return &mcf, true
}

// AsPatternReplaceCharFilter is the CharFilter implementation for MappingCharFilter.
func (mcf MappingCharFilter) AsPatternReplaceCharFilter() (*PatternReplaceCharFilter, bool) {
	return nil, false
}

// MicrosoftLanguageStemmingTokenizer is divides text using language-specific rules and reduces words to their base
// forms.
type MicrosoftLanguageStemmingTokenizer struct {
	Name              *string                            `json:"name,omitempty"`
	OdataType         OdataType1                         `json:"@odata.type,omitempty"`
	MaxTokenLength    *int32                             `json:"maxTokenLength,omitempty"`
	IsSearchTokenizer *bool                              `json:"isSearchTokenizer,omitempty"`
	Language          MicrosoftStemmingTokenizerLanguage `json:"language,omitempty"`
}

// MarshalJSON is the custom marshaler for MicrosoftLanguageStemmingTokenizer.
func (mlst MicrosoftLanguageStemmingTokenizer) MarshalJSON() ([]byte, error) {
	mlst.OdataType = OdataTypeMicrosoftAzureSearchMicrosoftLanguageStemmingTokenizer
	type Alias MicrosoftLanguageStemmingTokenizer
	return json.Marshal(&struct {
		Alias
	}{
		Alias: (Alias)(mlst),
	})
}

// AsClassicTokenizer is the Tokenizer implementation for MicrosoftLanguageStemmingTokenizer.
func (mlst MicrosoftLanguageStemmingTokenizer) AsClassicTokenizer() (*ClassicTokenizer, bool) {
	return nil, false
}

// AsEdgeNGramTokenizer is the Tokenizer implementation for MicrosoftLanguageStemmingTokenizer.
func (mlst MicrosoftLanguageStemmingTokenizer) AsEdgeNGramTokenizer() (*EdgeNGramTokenizer, bool) {
	return nil, false
}

// AsKeywordTokenizer is the Tokenizer implementation for MicrosoftLanguageStemmingTokenizer.
func (mlst MicrosoftLanguageStemmingTokenizer) AsKeywordTokenizer() (*KeywordTokenizer, bool) {
	return nil, false
}

// AsKeywordTokenizerV2 is the Tokenizer implementation for MicrosoftLanguageStemmingTokenizer.
func (mlst MicrosoftLanguageStemmingTokenizer) AsKeywordTokenizerV2() (*KeywordTokenizerV2, bool) {
	return nil, false
}

// AsMicrosoftLanguageTokenizer is the Tokenizer implementation for MicrosoftLanguageStemmingTokenizer.
func (mlst MicrosoftLanguageStemmingTokenizer) AsMicrosoftLanguageTokenizer() (*MicrosoftLanguageTokenizer, bool) {
	return nil, false
}

// AsMicrosoftLanguageStemmingTokenizer is the Tokenizer implementation for MicrosoftLanguageStemmingTokenizer.
func (mlst MicrosoftLanguageStemmingTokenizer) AsMicrosoftLanguageStemmingTokenizer() (*MicrosoftLanguageStemmingTokenizer, bool) {
	return &mlst, true
}

// AsNGramTokenizer is the Tokenizer implementation for MicrosoftLanguageStemmingTokenizer.
func (mlst MicrosoftLanguageStemmingTokenizer) AsNGramTokenizer() (*NGramTokenizer, bool) {
	return nil, false
}

// AsPathHierarchyTokenizer is the Tokenizer implementation for MicrosoftLanguageStemmingTokenizer.
func (mlst MicrosoftLanguageStemmingTokenizer) AsPathHierarchyTokenizer() (*PathHierarchyTokenizer, bool) {
	return nil, false
}

// AsPathHierarchyTokenizerV2 is the Tokenizer implementation for MicrosoftLanguageStemmingTokenizer.
func (mlst MicrosoftLanguageStemmingTokenizer) AsPathHierarchyTokenizerV2() (*PathHierarchyTokenizerV2, bool) {
	return nil, false
}

// AsPatternTokenizer is the Tokenizer implementation for MicrosoftLanguageStemmingTokenizer.
func (mlst MicrosoftLanguageStemmingTokenizer) AsPatternTokenizer() (*PatternTokenizer, bool) {
	return nil, false
}

// AsStandardTokenizer is the Tokenizer implementation for MicrosoftLanguageStemmingTokenizer.
func (mlst MicrosoftLanguageStemmingTokenizer) AsStandardTokenizer() (*StandardTokenizer, bool) {
	return nil, false
}

// AsStandardTokenizerV2 is the Tokenizer implementation for MicrosoftLanguageStemmingTokenizer.
func (mlst MicrosoftLanguageStemmingTokenizer) AsStandardTokenizerV2() (*StandardTokenizerV2, bool) {
	return nil, false
}

// AsUaxURLEmailTokenizer is the Tokenizer implementation for MicrosoftLanguageStemmingTokenizer.
func (mlst MicrosoftLanguageStemmingTokenizer) AsUaxURLEmailTokenizer() (*UaxURLEmailTokenizer, bool) {
	return nil, false
}

// MicrosoftLanguageTokenizer is divides text using language-specific rules.
type MicrosoftLanguageTokenizer struct {
	Name              *string                    `json:"name,omitempty"`
	OdataType         OdataType1                 `json:"@odata.type,omitempty"`
	MaxTokenLength    *int32                     `json:"maxTokenLength,omitempty"`
	IsSearchTokenizer *bool                      `json:"isSearchTokenizer,omitempty"`
	Language          MicrosoftTokenizerLanguage `json:"language,omitempty"`
}

// MarshalJSON is the custom marshaler for MicrosoftLanguageTokenizer.
func (mlt MicrosoftLanguageTokenizer) MarshalJSON() ([]byte, error) {
	mlt.OdataType = OdataTypeMicrosoftAzureSearchMicrosoftLanguageTokenizer
	type Alias MicrosoftLanguageTokenizer
	return json.Marshal(&struct {
		Alias
	}{
		Alias: (Alias)(mlt),
	})
}

// AsClassicTokenizer is the Tokenizer implementation for MicrosoftLanguageTokenizer.
func (mlt MicrosoftLanguageTokenizer) AsClassicTokenizer() (*ClassicTokenizer, bool) {
	return nil, false
}

// AsEdgeNGramTokenizer is the Tokenizer implementation for MicrosoftLanguageTokenizer.
func (mlt MicrosoftLanguageTokenizer) AsEdgeNGramTokenizer() (*EdgeNGramTokenizer, bool) {
	return nil, false
}

// AsKeywordTokenizer is the Tokenizer implementation for MicrosoftLanguageTokenizer.
func (mlt MicrosoftLanguageTokenizer) AsKeywordTokenizer() (*KeywordTokenizer, bool) {
	return nil, false
}

// AsKeywordTokenizerV2 is the Tokenizer implementation for MicrosoftLanguageTokenizer.
func (mlt MicrosoftLanguageTokenizer) AsKeywordTokenizerV2() (*KeywordTokenizerV2, bool) {
	return nil, false
}

// AsMicrosoftLanguageTokenizer is the Tokenizer implementation for MicrosoftLanguageTokenizer.
func (mlt MicrosoftLanguageTokenizer) AsMicrosoftLanguageTokenizer() (*MicrosoftLanguageTokenizer, bool) {
	return &mlt, true
}

// AsMicrosoftLanguageStemmingTokenizer is the Tokenizer implementation for MicrosoftLanguageTokenizer.
func (mlt MicrosoftLanguageTokenizer) AsMicrosoftLanguageStemmingTokenizer() (*MicrosoftLanguageStemmingTokenizer, bool) {
	return nil, false
}

// AsNGramTokenizer is the Tokenizer implementation for MicrosoftLanguageTokenizer.
func (mlt MicrosoftLanguageTokenizer) AsNGramTokenizer() (*NGramTokenizer, bool) {
	return nil, false
}

// AsPathHierarchyTokenizer is the Tokenizer implementation for MicrosoftLanguageTokenizer.
func (mlt MicrosoftLanguageTokenizer) AsPathHierarchyTokenizer() (*PathHierarchyTokenizer, bool) {
	return nil, false
}

// AsPathHierarchyTokenizerV2 is the Tokenizer implementation for MicrosoftLanguageTokenizer.
func (mlt MicrosoftLanguageTokenizer) AsPathHierarchyTokenizerV2() (*PathHierarchyTokenizerV2, bool) {
	return nil, false
}

// AsPatternTokenizer is the Tokenizer implementation for MicrosoftLanguageTokenizer.
func (mlt MicrosoftLanguageTokenizer) AsPatternTokenizer() (*PatternTokenizer, bool) {
	return nil, false
}

// AsStandardTokenizer is the Tokenizer implementation for MicrosoftLanguageTokenizer.
func (mlt MicrosoftLanguageTokenizer) AsStandardTokenizer() (*StandardTokenizer, bool) {
	return nil, false
}

// AsStandardTokenizerV2 is the Tokenizer implementation for MicrosoftLanguageTokenizer.
func (mlt MicrosoftLanguageTokenizer) AsStandardTokenizerV2() (*StandardTokenizerV2, bool) {
	return nil, false
}

// AsUaxURLEmailTokenizer is the Tokenizer implementation for MicrosoftLanguageTokenizer.
func (mlt MicrosoftLanguageTokenizer) AsUaxURLEmailTokenizer() (*UaxURLEmailTokenizer, bool) {
	return nil, false
}

// NGramTokenFilter is generates n-grams of the given size(s). This token filter is implemented using Apache Lucene.
type NGramTokenFilter struct {
	Name      *string    `json:"name,omitempty"`
	OdataType OdataType2 `json:"@odata.type,omitempty"`
	MinGram   *int32     `json:"minGram,omitempty"`
	MaxGram   *int32     `json:"maxGram,omitempty"`
}

// MarshalJSON is the custom marshaler for NGramTokenFilter.
func (ngtf NGramTokenFilter) MarshalJSON() ([]byte, error) {
	ngtf.OdataType = OdataTypeMicrosoftAzureSearchNGramTokenFilter
	type Alias NGramTokenFilter
	return json.Marshal(&struct {
		Alias
	}{
		Alias: (Alias)(ngtf),
	})
}

// AsASCIIFoldingTokenFilter is the TokenFilter implementation for NGramTokenFilter.
func (ngtf NGramTokenFilter) AsASCIIFoldingTokenFilter() (*ASCIIFoldingTokenFilter, bool) {
	return nil, false
}

// AsCjkBigramTokenFilter is the TokenFilter implementation for NGramTokenFilter.
func (ngtf NGramTokenFilter) AsCjkBigramTokenFilter() (*CjkBigramTokenFilter, bool) {
	return nil, false
}

// AsCommonGramTokenFilter is the TokenFilter implementation for NGramTokenFilter.
func (ngtf NGramTokenFilter) AsCommonGramTokenFilter() (*CommonGramTokenFilter, bool) {
	return nil, false
}

// AsDictionaryDecompounderTokenFilter is the TokenFilter implementation for NGramTokenFilter.
func (ngtf NGramTokenFilter) AsDictionaryDecompounderTokenFilter() (*DictionaryDecompounderTokenFilter, bool) {
	return nil, false
}

// AsEdgeNGramTokenFilter is the TokenFilter implementation for NGramTokenFilter.
func (ngtf NGramTokenFilter) AsEdgeNGramTokenFilter() (*EdgeNGramTokenFilter, bool) {
	return nil, false
}

// AsEdgeNGramTokenFilterV2 is the TokenFilter implementation for NGramTokenFilter.
func (ngtf NGramTokenFilter) AsEdgeNGramTokenFilterV2() (*EdgeNGramTokenFilterV2, bool) {
	return nil, false
}

// AsElisionTokenFilter is the TokenFilter implementation for NGramTokenFilter.
func (ngtf NGramTokenFilter) AsElisionTokenFilter() (*ElisionTokenFilter, bool) {
	return nil, false
}

// AsKeepTokenFilter is the TokenFilter implementation for NGramTokenFilter.
func (ngtf NGramTokenFilter) AsKeepTokenFilter() (*KeepTokenFilter, bool) {
	return nil, false
}

// AsKeywordMarkerTokenFilter is the TokenFilter implementation for NGramTokenFilter.
func (ngtf NGramTokenFilter) AsKeywordMarkerTokenFilter() (*KeywordMarkerTokenFilter, bool) {
	return nil, false
}

// AsLengthTokenFilter is the TokenFilter implementation for NGramTokenFilter.
func (ngtf NGramTokenFilter) AsLengthTokenFilter() (*LengthTokenFilter, bool) {
	return nil, false
}

// AsLimitTokenFilter is the TokenFilter implementation for NGramTokenFilter.
func (ngtf NGramTokenFilter) AsLimitTokenFilter() (*LimitTokenFilter, bool) {
	return nil, false
}

// AsNGramTokenFilter is the TokenFilter implementation for NGramTokenFilter.
func (ngtf NGramTokenFilter) AsNGramTokenFilter() (*NGramTokenFilter, bool) {
	return &ngtf, true
}

// AsNGramTokenFilterV2 is the TokenFilter implementation for NGramTokenFilter.
func (ngtf NGramTokenFilter) AsNGramTokenFilterV2() (*NGramTokenFilterV2, bool) {
	return nil, false
}

// AsPatternCaptureTokenFilter is the TokenFilter implementation for NGramTokenFilter.
func (ngtf NGramTokenFilter) AsPatternCaptureTokenFilter() (*PatternCaptureTokenFilter, bool) {
	return nil, false
}

// AsPatternReplaceTokenFilter is the TokenFilter implementation for NGramTokenFilter.
func (ngtf NGramTokenFilter) AsPatternReplaceTokenFilter() (*PatternReplaceTokenFilter, bool) {
	return nil, false
}

// AsPhoneticTokenFilter is the TokenFilter implementation for NGramTokenFilter.
func (ngtf NGramTokenFilter) AsPhoneticTokenFilter() (*PhoneticTokenFilter, bool) {
	return nil, false
}

// AsShingleTokenFilter is the TokenFilter implementation for NGramTokenFilter.
func (ngtf NGramTokenFilter) AsShingleTokenFilter() (*ShingleTokenFilter, bool) {
	return nil, false
}

// AsSnowballTokenFilter is the TokenFilter implementation for NGramTokenFilter.
func (ngtf NGramTokenFilter) AsSnowballTokenFilter() (*SnowballTokenFilter, bool) {
	return nil, false
}

// AsStemmerTokenFilter is the TokenFilter implementation for NGramTokenFilter.
func (ngtf NGramTokenFilter) AsStemmerTokenFilter() (*StemmerTokenFilter, bool) {
	return nil, false
}

// AsStemmerOverrideTokenFilter is the TokenFilter implementation for NGramTokenFilter.
func (ngtf NGramTokenFilter) AsStemmerOverrideTokenFilter() (*StemmerOverrideTokenFilter, bool) {
	return nil, false
}

// AsStopwordsTokenFilter is the TokenFilter implementation for NGramTokenFilter.
func (ngtf NGramTokenFilter) AsStopwordsTokenFilter() (*StopwordsTokenFilter, bool) {
	return nil, false
}

// AsSynonymTokenFilter is the TokenFilter implementation for NGramTokenFilter.
func (ngtf NGramTokenFilter) AsSynonymTokenFilter() (*SynonymTokenFilter, bool) {
	return nil, false
}

// AsTruncateTokenFilter is the TokenFilter implementation for NGramTokenFilter.
func (ngtf NGramTokenFilter) AsTruncateTokenFilter() (*TruncateTokenFilter, bool) {
	return nil, false
}

// AsUniqueTokenFilter is the TokenFilter implementation for NGramTokenFilter.
func (ngtf NGramTokenFilter) AsUniqueTokenFilter() (*UniqueTokenFilter, bool) {
	return nil, false
}

// AsWordDelimiterTokenFilter is the TokenFilter implementation for NGramTokenFilter.
func (ngtf NGramTokenFilter) AsWordDelimiterTokenFilter() (*WordDelimiterTokenFilter, bool) {
	return nil, false
}

// NGramTokenFilterV2 is generates n-grams of the given size(s). This token filter is implemented using Apache Lucene.
type NGramTokenFilterV2 struct {
	Name      *string    `json:"name,omitempty"`
	OdataType OdataType2 `json:"@odata.type,omitempty"`
	MinGram   *int32     `json:"minGram,omitempty"`
	MaxGram   *int32     `json:"maxGram,omitempty"`
}

// MarshalJSON is the custom marshaler for NGramTokenFilterV2.
func (ngtfv NGramTokenFilterV2) MarshalJSON() ([]byte, error) {
	ngtfv.OdataType = OdataTypeMicrosoftAzureSearchNGramTokenFilterV2
	type Alias NGramTokenFilterV2
	return json.Marshal(&struct {
		Alias
	}{
		Alias: (Alias)(ngtfv),
	})
}

// AsASCIIFoldingTokenFilter is the TokenFilter implementation for NGramTokenFilterV2.
func (ngtfv NGramTokenFilterV2) AsASCIIFoldingTokenFilter() (*ASCIIFoldingTokenFilter, bool) {
	return nil, false
}

// AsCjkBigramTokenFilter is the TokenFilter implementation for NGramTokenFilterV2.
func (ngtfv NGramTokenFilterV2) AsCjkBigramTokenFilter() (*CjkBigramTokenFilter, bool) {
	return nil, false
}

// AsCommonGramTokenFilter is the TokenFilter implementation for NGramTokenFilterV2.
func (ngtfv NGramTokenFilterV2) AsCommonGramTokenFilter() (*CommonGramTokenFilter, bool) {
	return nil, false
}

// AsDictionaryDecompounderTokenFilter is the TokenFilter implementation for NGramTokenFilterV2.
func (ngtfv NGramTokenFilterV2) AsDictionaryDecompounderTokenFilter() (*DictionaryDecompounderTokenFilter, bool) {
	return nil, false
}

// AsEdgeNGramTokenFilter is the TokenFilter implementation for NGramTokenFilterV2.
func (ngtfv NGramTokenFilterV2) AsEdgeNGramTokenFilter() (*EdgeNGramTokenFilter, bool) {
	return nil, false
}

// AsEdgeNGramTokenFilterV2 is the TokenFilter implementation for NGramTokenFilterV2.
func (ngtfv NGramTokenFilterV2) AsEdgeNGramTokenFilterV2() (*EdgeNGramTokenFilterV2, bool) {
	return nil, false
}

// AsElisionTokenFilter is the TokenFilter implementation for NGramTokenFilterV2.
func (ngtfv NGramTokenFilterV2) AsElisionTokenFilter() (*ElisionTokenFilter, bool) {
	return nil, false
}

// AsKeepTokenFilter is the TokenFilter implementation for NGramTokenFilterV2.
func (ngtfv NGramTokenFilterV2) AsKeepTokenFilter() (*KeepTokenFilter, bool) {
	return nil, false
}

// AsKeywordMarkerTokenFilter is the TokenFilter implementation for NGramTokenFilterV2.
func (ngtfv NGramTokenFilterV2) AsKeywordMarkerTokenFilter() (*KeywordMarkerTokenFilter, bool) {
	return nil, false
}

// AsLengthTokenFilter is the TokenFilter implementation for NGramTokenFilterV2.
func (ngtfv NGramTokenFilterV2) AsLengthTokenFilter() (*LengthTokenFilter, bool) {
	return nil, false
}

// AsLimitTokenFilter is the TokenFilter implementation for NGramTokenFilterV2.
func (ngtfv NGramTokenFilterV2) AsLimitTokenFilter() (*LimitTokenFilter, bool) {
	return nil, false
}

// AsNGramTokenFilter is the TokenFilter implementation for NGramTokenFilterV2.
func (ngtfv NGramTokenFilterV2) AsNGramTokenFilter() (*NGramTokenFilter, bool) {
	return nil, false
}

// AsNGramTokenFilterV2 is the TokenFilter implementation for NGramTokenFilterV2.
func (ngtfv NGramTokenFilterV2) AsNGramTokenFilterV2() (*NGramTokenFilterV2, bool) {
	return &ngtfv, true
}

// AsPatternCaptureTokenFilter is the TokenFilter implementation for NGramTokenFilterV2.
func (ngtfv NGramTokenFilterV2) AsPatternCaptureTokenFilter() (*PatternCaptureTokenFilter, bool) {
	return nil, false
}

// AsPatternReplaceTokenFilter is the TokenFilter implementation for NGramTokenFilterV2.
func (ngtfv NGramTokenFilterV2) AsPatternReplaceTokenFilter() (*PatternReplaceTokenFilter, bool) {
	return nil, false
}

// AsPhoneticTokenFilter is the TokenFilter implementation for NGramTokenFilterV2.
func (ngtfv NGramTokenFilterV2) AsPhoneticTokenFilter() (*PhoneticTokenFilter, bool) {
	return nil, false
}

// AsShingleTokenFilter is the TokenFilter implementation for NGramTokenFilterV2.
func (ngtfv NGramTokenFilterV2) AsShingleTokenFilter() (*ShingleTokenFilter, bool) {
	return nil, false
}

// AsSnowballTokenFilter is the TokenFilter implementation for NGramTokenFilterV2.
func (ngtfv NGramTokenFilterV2) AsSnowballTokenFilter() (*SnowballTokenFilter, bool) {
	return nil, false
}

// AsStemmerTokenFilter is the TokenFilter implementation for NGramTokenFilterV2.
func (ngtfv NGramTokenFilterV2) AsStemmerTokenFilter() (*StemmerTokenFilter, bool) {
	return nil, false
}

// AsStemmerOverrideTokenFilter is the TokenFilter implementation for NGramTokenFilterV2.
func (ngtfv NGramTokenFilterV2) AsStemmerOverrideTokenFilter() (*StemmerOverrideTokenFilter, bool) {
	return nil, false
}

// AsStopwordsTokenFilter is the TokenFilter implementation for NGramTokenFilterV2.
func (ngtfv NGramTokenFilterV2) AsStopwordsTokenFilter() (*StopwordsTokenFilter, bool) {
	return nil, false
}

// AsSynonymTokenFilter is the TokenFilter implementation for NGramTokenFilterV2.
func (ngtfv NGramTokenFilterV2) AsSynonymTokenFilter() (*SynonymTokenFilter, bool) {
	return nil, false
}

// AsTruncateTokenFilter is the TokenFilter implementation for NGramTokenFilterV2.
func (ngtfv NGramTokenFilterV2) AsTruncateTokenFilter() (*TruncateTokenFilter, bool) {
	return nil, false
}

// AsUniqueTokenFilter is the TokenFilter implementation for NGramTokenFilterV2.
func (ngtfv NGramTokenFilterV2) AsUniqueTokenFilter() (*UniqueTokenFilter, bool) {
	return nil, false
}

// AsWordDelimiterTokenFilter is the TokenFilter implementation for NGramTokenFilterV2.
func (ngtfv NGramTokenFilterV2) AsWordDelimiterTokenFilter() (*WordDelimiterTokenFilter, bool) {
	return nil, false
}

// NGramTokenizer is tokenizes the input into n-grams of the given size(s). This tokenizer is implemented using Apache
// Lucene.
type NGramTokenizer struct {
	Name       *string               `json:"name,omitempty"`
	OdataType  OdataType1            `json:"@odata.type,omitempty"`
	MinGram    *int32                `json:"minGram,omitempty"`
	MaxGram    *int32                `json:"maxGram,omitempty"`
	TokenChars *[]TokenCharacterKind `json:"tokenChars,omitempty"`
}

// MarshalJSON is the custom marshaler for NGramTokenizer.
func (ngt NGramTokenizer) MarshalJSON() ([]byte, error) {
	ngt.OdataType = OdataTypeMicrosoftAzureSearchNGramTokenizer
	type Alias NGramTokenizer
	return json.Marshal(&struct {
		Alias
	}{
		Alias: (Alias)(ngt),
	})
}

// AsClassicTokenizer is the Tokenizer implementation for NGramTokenizer.
func (ngt NGramTokenizer) AsClassicTokenizer() (*ClassicTokenizer, bool) {
	return nil, false
}

// AsEdgeNGramTokenizer is the Tokenizer implementation for NGramTokenizer.
func (ngt NGramTokenizer) AsEdgeNGramTokenizer() (*EdgeNGramTokenizer, bool) {
	return nil, false
}

// AsKeywordTokenizer is the Tokenizer implementation for NGramTokenizer.
func (ngt NGramTokenizer) AsKeywordTokenizer() (*KeywordTokenizer, bool) {
	return nil, false
}

// AsKeywordTokenizerV2 is the Tokenizer implementation for NGramTokenizer.
func (ngt NGramTokenizer) AsKeywordTokenizerV2() (*KeywordTokenizerV2, bool) {
	return nil, false
}

// AsMicrosoftLanguageTokenizer is the Tokenizer implementation for NGramTokenizer.
func (ngt NGramTokenizer) AsMicrosoftLanguageTokenizer() (*MicrosoftLanguageTokenizer, bool) {
	return nil, false
}

// AsMicrosoftLanguageStemmingTokenizer is the Tokenizer implementation for NGramTokenizer.
func (ngt NGramTokenizer) AsMicrosoftLanguageStemmingTokenizer() (*MicrosoftLanguageStemmingTokenizer, bool) {
	return nil, false
}

// AsNGramTokenizer is the Tokenizer implementation for NGramTokenizer.
func (ngt NGramTokenizer) AsNGramTokenizer() (*NGramTokenizer, bool) {
	return &ngt, true
}

// AsPathHierarchyTokenizer is the Tokenizer implementation for NGramTokenizer.
func (ngt NGramTokenizer) AsPathHierarchyTokenizer() (*PathHierarchyTokenizer, bool) {
	return nil, false
}

// AsPathHierarchyTokenizerV2 is the Tokenizer implementation for NGramTokenizer.
func (ngt NGramTokenizer) AsPathHierarchyTokenizerV2() (*PathHierarchyTokenizerV2, bool) {
	return nil, false
}

// AsPatternTokenizer is the Tokenizer implementation for NGramTokenizer.
func (ngt NGramTokenizer) AsPatternTokenizer() (*PatternTokenizer, bool) {
	return nil, false
}

// AsStandardTokenizer is the Tokenizer implementation for NGramTokenizer.
func (ngt NGramTokenizer) AsStandardTokenizer() (*StandardTokenizer, bool) {
	return nil, false
}

// AsStandardTokenizerV2 is the Tokenizer implementation for NGramTokenizer.
func (ngt NGramTokenizer) AsStandardTokenizerV2() (*StandardTokenizerV2, bool) {
	return nil, false
}

// AsUaxURLEmailTokenizer is the Tokenizer implementation for NGramTokenizer.
func (ngt NGramTokenizer) AsUaxURLEmailTokenizer() (*UaxURLEmailTokenizer, bool) {
	return nil, false
}

// ParametersPayload is parameters for filtering, sorting, faceting, paging, and other search query behaviors.
type ParametersPayload struct {
	Count             *bool     `json:"count,omitempty"`
	Facets            *[]string `json:"facets,omitempty"`
	Filter            *string   `json:"filter,omitempty"`
	Highlight         *string   `json:"highlight,omitempty"`
	HighlightPostTag  *string   `json:"highlightPostTag,omitempty"`
	HighlightPreTag   *string   `json:"highlightPreTag,omitempty"`
	MinimumCoverage   *float64  `json:"minimumCoverage,omitempty"`
	OrderBy           *string   `json:"orderby,omitempty"`
	QueryType         QueryType `json:"queryType,omitempty"`
	ScoringParameters *[]string `json:"scoringParameters,omitempty"`
	ScoringProfile    *string   `json:"scoringProfile,omitempty"`
	SearchProperty    *string   `json:"search,omitempty"`
	SearchFields      *string   `json:"searchFields,omitempty"`
	SearchMode        Mode      `json:"searchMode,omitempty"`
	Select            *string   `json:"select,omitempty"`
	Skip              *int32    `json:"skip,omitempty"`
	Top               *int32    `json:"top,omitempty"`
}

// PathHierarchyTokenizer is tokenizer for path-like hierarchies. This tokenizer is implemented using Apache Lucene.
type PathHierarchyTokenizer struct {
	Name                 *string    `json:"name,omitempty"`
	OdataType            OdataType1 `json:"@odata.type,omitempty"`
	Delimiter            *string    `json:"delimiter,omitempty"`
	Replacement          *string    `json:"replacement,omitempty"`
	BufferSize           *int32     `json:"bufferSize,omitempty"`
	ReverseTokenOrder    *bool      `json:"reverse,omitempty"`
	NumberOfTokensToSkip *int32     `json:"skip,omitempty"`
}

// MarshalJSON is the custom marshaler for PathHierarchyTokenizer.
func (pht PathHierarchyTokenizer) MarshalJSON() ([]byte, error) {
	pht.OdataType = OdataTypeMicrosoftAzureSearchPathHierarchyTokenizer
	type Alias PathHierarchyTokenizer
	return json.Marshal(&struct {
		Alias
	}{
		Alias: (Alias)(pht),
	})
}

// AsClassicTokenizer is the Tokenizer implementation for PathHierarchyTokenizer.
func (pht PathHierarchyTokenizer) AsClassicTokenizer() (*ClassicTokenizer, bool) {
	return nil, false
}

// AsEdgeNGramTokenizer is the Tokenizer implementation for PathHierarchyTokenizer.
func (pht PathHierarchyTokenizer) AsEdgeNGramTokenizer() (*EdgeNGramTokenizer, bool) {
	return nil, false
}

// AsKeywordTokenizer is the Tokenizer implementation for PathHierarchyTokenizer.
func (pht PathHierarchyTokenizer) AsKeywordTokenizer() (*KeywordTokenizer, bool) {
	return nil, false
}

// AsKeywordTokenizerV2 is the Tokenizer implementation for PathHierarchyTokenizer.
func (pht PathHierarchyTokenizer) AsKeywordTokenizerV2() (*KeywordTokenizerV2, bool) {
	return nil, false
}

// AsMicrosoftLanguageTokenizer is the Tokenizer implementation for PathHierarchyTokenizer.
func (pht PathHierarchyTokenizer) AsMicrosoftLanguageTokenizer() (*MicrosoftLanguageTokenizer, bool) {
	return nil, false
}

// AsMicrosoftLanguageStemmingTokenizer is the Tokenizer implementation for PathHierarchyTokenizer.
func (pht PathHierarchyTokenizer) AsMicrosoftLanguageStemmingTokenizer() (*MicrosoftLanguageStemmingTokenizer, bool) {
	return nil, false
}

// AsNGramTokenizer is the Tokenizer implementation for PathHierarchyTokenizer.
func (pht PathHierarchyTokenizer) AsNGramTokenizer() (*NGramTokenizer, bool) {
	return nil, false
}

// AsPathHierarchyTokenizer is the Tokenizer implementation for PathHierarchyTokenizer.
func (pht PathHierarchyTokenizer) AsPathHierarchyTokenizer() (*PathHierarchyTokenizer, bool) {
	return &pht, true
}

// AsPathHierarchyTokenizerV2 is the Tokenizer implementation for PathHierarchyTokenizer.
func (pht PathHierarchyTokenizer) AsPathHierarchyTokenizerV2() (*PathHierarchyTokenizerV2, bool) {
	return nil, false
}

// AsPatternTokenizer is the Tokenizer implementation for PathHierarchyTokenizer.
func (pht PathHierarchyTokenizer) AsPatternTokenizer() (*PatternTokenizer, bool) {
	return nil, false
}

// AsStandardTokenizer is the Tokenizer implementation for PathHierarchyTokenizer.
func (pht PathHierarchyTokenizer) AsStandardTokenizer() (*StandardTokenizer, bool) {
	return nil, false
}

// AsStandardTokenizerV2 is the Tokenizer implementation for PathHierarchyTokenizer.
func (pht PathHierarchyTokenizer) AsStandardTokenizerV2() (*StandardTokenizerV2, bool) {
	return nil, false
}

// AsUaxURLEmailTokenizer is the Tokenizer implementation for PathHierarchyTokenizer.
func (pht PathHierarchyTokenizer) AsUaxURLEmailTokenizer() (*UaxURLEmailTokenizer, bool) {
	return nil, false
}

// PathHierarchyTokenizerV2 is tokenizer for path-like hierarchies. This tokenizer is implemented using Apache Lucene.
type PathHierarchyTokenizerV2 struct {
	Name                 *string    `json:"name,omitempty"`
	OdataType            OdataType1 `json:"@odata.type,omitempty"`
	Delimiter            *string    `json:"delimiter,omitempty"`
	Replacement          *string    `json:"replacement,omitempty"`
	MaxTokenLength       *int32     `json:"maxTokenLength,omitempty"`
	ReverseTokenOrder    *bool      `json:"reverse,omitempty"`
	NumberOfTokensToSkip *int32     `json:"skip,omitempty"`
}

// MarshalJSON is the custom marshaler for PathHierarchyTokenizerV2.
func (phtv PathHierarchyTokenizerV2) MarshalJSON() ([]byte, error) {
	phtv.OdataType = OdataTypeMicrosoftAzureSearchPathHierarchyTokenizerV2
	type Alias PathHierarchyTokenizerV2
	return json.Marshal(&struct {
		Alias
	}{
		Alias: (Alias)(phtv),
	})
}

// AsClassicTokenizer is the Tokenizer implementation for PathHierarchyTokenizerV2.
func (phtv PathHierarchyTokenizerV2) AsClassicTokenizer() (*ClassicTokenizer, bool) {
	return nil, false
}

// AsEdgeNGramTokenizer is the Tokenizer implementation for PathHierarchyTokenizerV2.
func (phtv PathHierarchyTokenizerV2) AsEdgeNGramTokenizer() (*EdgeNGramTokenizer, bool) {
	return nil, false
}

// AsKeywordTokenizer is the Tokenizer implementation for PathHierarchyTokenizerV2.
func (phtv PathHierarchyTokenizerV2) AsKeywordTokenizer() (*KeywordTokenizer, bool) {
	return nil, false
}

// AsKeywordTokenizerV2 is the Tokenizer implementation for PathHierarchyTokenizerV2.
func (phtv PathHierarchyTokenizerV2) AsKeywordTokenizerV2() (*KeywordTokenizerV2, bool) {
	return nil, false
}

// AsMicrosoftLanguageTokenizer is the Tokenizer implementation for PathHierarchyTokenizerV2.
func (phtv PathHierarchyTokenizerV2) AsMicrosoftLanguageTokenizer() (*MicrosoftLanguageTokenizer, bool) {
	return nil, false
}

// AsMicrosoftLanguageStemmingTokenizer is the Tokenizer implementation for PathHierarchyTokenizerV2.
func (phtv PathHierarchyTokenizerV2) AsMicrosoftLanguageStemmingTokenizer() (*MicrosoftLanguageStemmingTokenizer, bool) {
	return nil, false
}

// AsNGramTokenizer is the Tokenizer implementation for PathHierarchyTokenizerV2.
func (phtv PathHierarchyTokenizerV2) AsNGramTokenizer() (*NGramTokenizer, bool) {
	return nil, false
}

// AsPathHierarchyTokenizer is the Tokenizer implementation for PathHierarchyTokenizerV2.
func (phtv PathHierarchyTokenizerV2) AsPathHierarchyTokenizer() (*PathHierarchyTokenizer, bool) {
	return nil, false
}

// AsPathHierarchyTokenizerV2 is the Tokenizer implementation for PathHierarchyTokenizerV2.
func (phtv PathHierarchyTokenizerV2) AsPathHierarchyTokenizerV2() (*PathHierarchyTokenizerV2, bool) {
	return &phtv, true
}

// AsPatternTokenizer is the Tokenizer implementation for PathHierarchyTokenizerV2.
func (phtv PathHierarchyTokenizerV2) AsPatternTokenizer() (*PatternTokenizer, bool) {
	return nil, false
}

// AsStandardTokenizer is the Tokenizer implementation for PathHierarchyTokenizerV2.
func (phtv PathHierarchyTokenizerV2) AsStandardTokenizer() (*StandardTokenizer, bool) {
	return nil, false
}

// AsStandardTokenizerV2 is the Tokenizer implementation for PathHierarchyTokenizerV2.
func (phtv PathHierarchyTokenizerV2) AsStandardTokenizerV2() (*StandardTokenizerV2, bool) {
	return nil, false
}

// AsUaxURLEmailTokenizer is the Tokenizer implementation for PathHierarchyTokenizerV2.
func (phtv PathHierarchyTokenizerV2) AsUaxURLEmailTokenizer() (*UaxURLEmailTokenizer, bool) {
	return nil, false
}

// PatternAnalyzer is flexibly separates text into terms via a regular expression pattern. This analyzer is implemented
// using Apache Lucene.
type PatternAnalyzer struct {
	Name           *string     `json:"name,omitempty"`
	OdataType      OdataType   `json:"@odata.type,omitempty"`
	LowerCaseTerms *bool       `json:"lowercase,omitempty"`
	Pattern        *string     `json:"pattern,omitempty"`
	Flags          *RegexFlags `json:"flags,omitempty"`
	Stopwords      *[]string   `json:"stopwords,omitempty"`
}

// MarshalJSON is the custom marshaler for PatternAnalyzer.
func (pa PatternAnalyzer) MarshalJSON() ([]byte, error) {
	pa.OdataType = OdataTypeMicrosoftAzureSearchPatternAnalyzer
	type Alias PatternAnalyzer
	return json.Marshal(&struct {
		Alias
	}{
		Alias: (Alias)(pa),
	})
}

// AsCustomAnalyzer is the Analyzer implementation for PatternAnalyzer.
func (pa PatternAnalyzer) AsCustomAnalyzer() (*CustomAnalyzer, bool) {
	return nil, false
}

// AsPatternAnalyzer is the Analyzer implementation for PatternAnalyzer.
func (pa PatternAnalyzer) AsPatternAnalyzer() (*PatternAnalyzer, bool) {
	return &pa, true
}

// AsStandardAnalyzer is the Analyzer implementation for PatternAnalyzer.
func (pa PatternAnalyzer) AsStandardAnalyzer() (*StandardAnalyzer, bool) {
	return nil, false
}

// AsStopAnalyzer is the Analyzer implementation for PatternAnalyzer.
func (pa PatternAnalyzer) AsStopAnalyzer() (*StopAnalyzer, bool) {
	return nil, false
}

// PatternCaptureTokenFilter is uses Java regexes to emit multiple tokens - one for each capture group in one or more
// patterns. This token filter is implemented using Apache Lucene.
type PatternCaptureTokenFilter struct {
	Name             *string    `json:"name,omitempty"`
	OdataType        OdataType2 `json:"@odata.type,omitempty"`
	Patterns         *[]string  `json:"patterns,omitempty"`
	PreserveOriginal *bool      `json:"preserveOriginal,omitempty"`
}

// MarshalJSON is the custom marshaler for PatternCaptureTokenFilter.
func (pctf PatternCaptureTokenFilter) MarshalJSON() ([]byte, error) {
	pctf.OdataType = OdataTypeMicrosoftAzureSearchPatternCaptureTokenFilter
	type Alias PatternCaptureTokenFilter
	return json.Marshal(&struct {
		Alias
	}{
		Alias: (Alias)(pctf),
	})
}

// AsASCIIFoldingTokenFilter is the TokenFilter implementation for PatternCaptureTokenFilter.
func (pctf PatternCaptureTokenFilter) AsASCIIFoldingTokenFilter() (*ASCIIFoldingTokenFilter, bool) {
	return nil, false
}

// AsCjkBigramTokenFilter is the TokenFilter implementation for PatternCaptureTokenFilter.
func (pctf PatternCaptureTokenFilter) AsCjkBigramTokenFilter() (*CjkBigramTokenFilter, bool) {
	return nil, false
}

// AsCommonGramTokenFilter is the TokenFilter implementation for PatternCaptureTokenFilter.
func (pctf PatternCaptureTokenFilter) AsCommonGramTokenFilter() (*CommonGramTokenFilter, bool) {
	return nil, false
}

// AsDictionaryDecompounderTokenFilter is the TokenFilter implementation for PatternCaptureTokenFilter.
func (pctf PatternCaptureTokenFilter) AsDictionaryDecompounderTokenFilter() (*DictionaryDecompounderTokenFilter, bool) {
	return nil, false
}

// AsEdgeNGramTokenFilter is the TokenFilter implementation for PatternCaptureTokenFilter.
func (pctf PatternCaptureTokenFilter) AsEdgeNGramTokenFilter() (*EdgeNGramTokenFilter, bool) {
	return nil, false
}

// AsEdgeNGramTokenFilterV2 is the TokenFilter implementation for PatternCaptureTokenFilter.
func (pctf PatternCaptureTokenFilter) AsEdgeNGramTokenFilterV2() (*EdgeNGramTokenFilterV2, bool) {
	return nil, false
}

// AsElisionTokenFilter is the TokenFilter implementation for PatternCaptureTokenFilter.
func (pctf PatternCaptureTokenFilter) AsElisionTokenFilter() (*ElisionTokenFilter, bool) {
	return nil, false
}

// AsKeepTokenFilter is the TokenFilter implementation for PatternCaptureTokenFilter.
func (pctf PatternCaptureTokenFilter) AsKeepTokenFilter() (*KeepTokenFilter, bool) {
	return nil, false
}

// AsKeywordMarkerTokenFilter is the TokenFilter implementation for PatternCaptureTokenFilter.
func (pctf PatternCaptureTokenFilter) AsKeywordMarkerTokenFilter() (*KeywordMarkerTokenFilter, bool) {
	return nil, false
}

// AsLengthTokenFilter is the TokenFilter implementation for PatternCaptureTokenFilter.
func (pctf PatternCaptureTokenFilter) AsLengthTokenFilter() (*LengthTokenFilter, bool) {
	return nil, false
}

// AsLimitTokenFilter is the TokenFilter implementation for PatternCaptureTokenFilter.
func (pctf PatternCaptureTokenFilter) AsLimitTokenFilter() (*LimitTokenFilter, bool) {
	return nil, false
}

// AsNGramTokenFilter is the TokenFilter implementation for PatternCaptureTokenFilter.
func (pctf PatternCaptureTokenFilter) AsNGramTokenFilter() (*NGramTokenFilter, bool) {
	return nil, false
}

// AsNGramTokenFilterV2 is the TokenFilter implementation for PatternCaptureTokenFilter.
func (pctf PatternCaptureTokenFilter) AsNGramTokenFilterV2() (*NGramTokenFilterV2, bool) {
	return nil, false
}

// AsPatternCaptureTokenFilter is the TokenFilter implementation for PatternCaptureTokenFilter.
func (pctf PatternCaptureTokenFilter) AsPatternCaptureTokenFilter() (*PatternCaptureTokenFilter, bool) {
	return &pctf, true
}

// AsPatternReplaceTokenFilter is the TokenFilter implementation for PatternCaptureTokenFilter.
func (pctf PatternCaptureTokenFilter) AsPatternReplaceTokenFilter() (*PatternReplaceTokenFilter, bool) {
	return nil, false
}

// AsPhoneticTokenFilter is the TokenFilter implementation for PatternCaptureTokenFilter.
func (pctf PatternCaptureTokenFilter) AsPhoneticTokenFilter() (*PhoneticTokenFilter, bool) {
	return nil, false
}

// AsShingleTokenFilter is the TokenFilter implementation for PatternCaptureTokenFilter.
func (pctf PatternCaptureTokenFilter) AsShingleTokenFilter() (*ShingleTokenFilter, bool) {
	return nil, false
}

// AsSnowballTokenFilter is the TokenFilter implementation for PatternCaptureTokenFilter.
func (pctf PatternCaptureTokenFilter) AsSnowballTokenFilter() (*SnowballTokenFilter, bool) {
	return nil, false
}

// AsStemmerTokenFilter is the TokenFilter implementation for PatternCaptureTokenFilter.
func (pctf PatternCaptureTokenFilter) AsStemmerTokenFilter() (*StemmerTokenFilter, bool) {
	return nil, false
}

// AsStemmerOverrideTokenFilter is the TokenFilter implementation for PatternCaptureTokenFilter.
func (pctf PatternCaptureTokenFilter) AsStemmerOverrideTokenFilter() (*StemmerOverrideTokenFilter, bool) {
	return nil, false
}

// AsStopwordsTokenFilter is the TokenFilter implementation for PatternCaptureTokenFilter.
func (pctf PatternCaptureTokenFilter) AsStopwordsTokenFilter() (*StopwordsTokenFilter, bool) {
	return nil, false
}

// AsSynonymTokenFilter is the TokenFilter implementation for PatternCaptureTokenFilter.
func (pctf PatternCaptureTokenFilter) AsSynonymTokenFilter() (*SynonymTokenFilter, bool) {
	return nil, false
}

// AsTruncateTokenFilter is the TokenFilter implementation for PatternCaptureTokenFilter.
func (pctf PatternCaptureTokenFilter) AsTruncateTokenFilter() (*TruncateTokenFilter, bool) {
	return nil, false
}

// AsUniqueTokenFilter is the TokenFilter implementation for PatternCaptureTokenFilter.
func (pctf PatternCaptureTokenFilter) AsUniqueTokenFilter() (*UniqueTokenFilter, bool) {
	return nil, false
}

// AsWordDelimiterTokenFilter is the TokenFilter implementation for PatternCaptureTokenFilter.
func (pctf PatternCaptureTokenFilter) AsWordDelimiterTokenFilter() (*WordDelimiterTokenFilter, bool) {
	return nil, false
}

// PatternReplaceCharFilter is a character filter that replaces characters in the input string. It uses a regular
// expression to identify character sequences to preserve and a replacement pattern to identify characters to replace.
// For example, given the input text "aa bb aa bb", pattern "(aa)\s+(bb)", and replacement "$1#$2", the result would be
// "aa#bb aa#bb". This character filter is implemented using Apache Lucene.
type PatternReplaceCharFilter struct {
	Name        *string    `json:"name,omitempty"`
	OdataType   OdataType3 `json:"@odata.type,omitempty"`
	Pattern     *string    `json:"pattern,omitempty"`
	Replacement *string    `json:"replacement,omitempty"`
}

// MarshalJSON is the custom marshaler for PatternReplaceCharFilter.
func (prcf PatternReplaceCharFilter) MarshalJSON() ([]byte, error) {
	prcf.OdataType = OdataTypeMicrosoftAzureSearchPatternReplaceCharFilter
	type Alias PatternReplaceCharFilter
	return json.Marshal(&struct {
		Alias
	}{
		Alias: (Alias)(prcf),
	})
}

// AsMappingCharFilter is the CharFilter implementation for PatternReplaceCharFilter.
func (prcf PatternReplaceCharFilter) AsMappingCharFilter() (*MappingCharFilter, bool) {
	return nil, false
}

// AsPatternReplaceCharFilter is the CharFilter implementation for PatternReplaceCharFilter.
func (prcf PatternReplaceCharFilter) AsPatternReplaceCharFilter() (*PatternReplaceCharFilter, bool) {
	return &prcf, true
}

// PatternReplaceTokenFilter is a character filter that replaces characters in the input string. It uses a regular
// expression to identify character sequences to preserve and a replacement pattern to identify characters to replace.
// For example, given the input text "aa bb aa bb", pattern "(aa)\s+(bb)", and replacement "$1#$2", the result would be
// "aa#bb aa#bb". This token filter is implemented using Apache Lucene.
type PatternReplaceTokenFilter struct {
	Name        *string    `json:"name,omitempty"`
	OdataType   OdataType2 `json:"@odata.type,omitempty"`
	Pattern     *string    `json:"pattern,omitempty"`
	Replacement *string    `json:"replacement,omitempty"`
}

// MarshalJSON is the custom marshaler for PatternReplaceTokenFilter.
func (prtf PatternReplaceTokenFilter) MarshalJSON() ([]byte, error) {
	prtf.OdataType = OdataTypeMicrosoftAzureSearchPatternReplaceTokenFilter
	type Alias PatternReplaceTokenFilter
	return json.Marshal(&struct {
		Alias
	}{
		Alias: (Alias)(prtf),
	})
}

// AsASCIIFoldingTokenFilter is the TokenFilter implementation for PatternReplaceTokenFilter.
func (prtf PatternReplaceTokenFilter) AsASCIIFoldingTokenFilter() (*ASCIIFoldingTokenFilter, bool) {
	return nil, false
}

// AsCjkBigramTokenFilter is the TokenFilter implementation for PatternReplaceTokenFilter.
func (prtf PatternReplaceTokenFilter) AsCjkBigramTokenFilter() (*CjkBigramTokenFilter, bool) {
	return nil, false
}

// AsCommonGramTokenFilter is the TokenFilter implementation for PatternReplaceTokenFilter.
func (prtf PatternReplaceTokenFilter) AsCommonGramTokenFilter() (*CommonGramTokenFilter, bool) {
	return nil, false
}

// AsDictionaryDecompounderTokenFilter is the TokenFilter implementation for PatternReplaceTokenFilter.
func (prtf PatternReplaceTokenFilter) AsDictionaryDecompounderTokenFilter() (*DictionaryDecompounderTokenFilter, bool) {
	return nil, false
}

// AsEdgeNGramTokenFilter is the TokenFilter implementation for PatternReplaceTokenFilter.
func (prtf PatternReplaceTokenFilter) AsEdgeNGramTokenFilter() (*EdgeNGramTokenFilter, bool) {
	return nil, false
}

// AsEdgeNGramTokenFilterV2 is the TokenFilter implementation for PatternReplaceTokenFilter.
func (prtf PatternReplaceTokenFilter) AsEdgeNGramTokenFilterV2() (*EdgeNGramTokenFilterV2, bool) {
	return nil, false
}

// AsElisionTokenFilter is the TokenFilter implementation for PatternReplaceTokenFilter.
func (prtf PatternReplaceTokenFilter) AsElisionTokenFilter() (*ElisionTokenFilter, bool) {
	return nil, false
}

// AsKeepTokenFilter is the TokenFilter implementation for PatternReplaceTokenFilter.
func (prtf PatternReplaceTokenFilter) AsKeepTokenFilter() (*KeepTokenFilter, bool) {
	return nil, false
}

// AsKeywordMarkerTokenFilter is the TokenFilter implementation for PatternReplaceTokenFilter.
func (prtf PatternReplaceTokenFilter) AsKeywordMarkerTokenFilter() (*KeywordMarkerTokenFilter, bool) {
	return nil, false
}

// AsLengthTokenFilter is the TokenFilter implementation for PatternReplaceTokenFilter.
func (prtf PatternReplaceTokenFilter) AsLengthTokenFilter() (*LengthTokenFilter, bool) {
	return nil, false
}

// AsLimitTokenFilter is the TokenFilter implementation for PatternReplaceTokenFilter.
func (prtf PatternReplaceTokenFilter) AsLimitTokenFilter() (*LimitTokenFilter, bool) {
	return nil, false
}

// AsNGramTokenFilter is the TokenFilter implementation for PatternReplaceTokenFilter.
func (prtf PatternReplaceTokenFilter) AsNGramTokenFilter() (*NGramTokenFilter, bool) {
	return nil, false
}

// AsNGramTokenFilterV2 is the TokenFilter implementation for PatternReplaceTokenFilter.
func (prtf PatternReplaceTokenFilter) AsNGramTokenFilterV2() (*NGramTokenFilterV2, bool) {
	return nil, false
}

// AsPatternCaptureTokenFilter is the TokenFilter implementation for PatternReplaceTokenFilter.
func (prtf PatternReplaceTokenFilter) AsPatternCaptureTokenFilter() (*PatternCaptureTokenFilter, bool) {
	return nil, false
}

// AsPatternReplaceTokenFilter is the TokenFilter implementation for PatternReplaceTokenFilter.
func (prtf PatternReplaceTokenFilter) AsPatternReplaceTokenFilter() (*PatternReplaceTokenFilter, bool) {
	return &prtf, true
}

// AsPhoneticTokenFilter is the TokenFilter implementation for PatternReplaceTokenFilter.
func (prtf PatternReplaceTokenFilter) AsPhoneticTokenFilter() (*PhoneticTokenFilter, bool) {
	return nil, false
}

// AsShingleTokenFilter is the TokenFilter implementation for PatternReplaceTokenFilter.
func (prtf PatternReplaceTokenFilter) AsShingleTokenFilter() (*ShingleTokenFilter, bool) {
	return nil, false
}

// AsSnowballTokenFilter is the TokenFilter implementation for PatternReplaceTokenFilter.
func (prtf PatternReplaceTokenFilter) AsSnowballTokenFilter() (*SnowballTokenFilter, bool) {
	return nil, false
}

// AsStemmerTokenFilter is the TokenFilter implementation for PatternReplaceTokenFilter.
func (prtf PatternReplaceTokenFilter) AsStemmerTokenFilter() (*StemmerTokenFilter, bool) {
	return nil, false
}

// AsStemmerOverrideTokenFilter is the TokenFilter implementation for PatternReplaceTokenFilter.
func (prtf PatternReplaceTokenFilter) AsStemmerOverrideTokenFilter() (*StemmerOverrideTokenFilter, bool) {
	return nil, false
}

// AsStopwordsTokenFilter is the TokenFilter implementation for PatternReplaceTokenFilter.
func (prtf PatternReplaceTokenFilter) AsStopwordsTokenFilter() (*StopwordsTokenFilter, bool) {
	return nil, false
}

// AsSynonymTokenFilter is the TokenFilter implementation for PatternReplaceTokenFilter.
func (prtf PatternReplaceTokenFilter) AsSynonymTokenFilter() (*SynonymTokenFilter, bool) {
	return nil, false
}

// AsTruncateTokenFilter is the TokenFilter implementation for PatternReplaceTokenFilter.
func (prtf PatternReplaceTokenFilter) AsTruncateTokenFilter() (*TruncateTokenFilter, bool) {
	return nil, false
}

// AsUniqueTokenFilter is the TokenFilter implementation for PatternReplaceTokenFilter.
func (prtf PatternReplaceTokenFilter) AsUniqueTokenFilter() (*UniqueTokenFilter, bool) {
	return nil, false
}

// AsWordDelimiterTokenFilter is the TokenFilter implementation for PatternReplaceTokenFilter.
func (prtf PatternReplaceTokenFilter) AsWordDelimiterTokenFilter() (*WordDelimiterTokenFilter, bool) {
	return nil, false
}

// PatternTokenizer is tokenizer that uses regex pattern matching to construct distinct tokens. This tokenizer is
// implemented using Apache Lucene.
type PatternTokenizer struct {
	Name      *string     `json:"name,omitempty"`
	OdataType OdataType1  `json:"@odata.type,omitempty"`
	Pattern   *string     `json:"pattern,omitempty"`
	Flags     *RegexFlags `json:"flags,omitempty"`
	Group     *int32      `json:"group,omitempty"`
}

// MarshalJSON is the custom marshaler for PatternTokenizer.
func (pt PatternTokenizer) MarshalJSON() ([]byte, error) {
	pt.OdataType = OdataTypeMicrosoftAzureSearchPatternTokenizer
	type Alias PatternTokenizer
	return json.Marshal(&struct {
		Alias
	}{
		Alias: (Alias)(pt),
	})
}

// AsClassicTokenizer is the Tokenizer implementation for PatternTokenizer.
func (pt PatternTokenizer) AsClassicTokenizer() (*ClassicTokenizer, bool) {
	return nil, false
}

// AsEdgeNGramTokenizer is the Tokenizer implementation for PatternTokenizer.
func (pt PatternTokenizer) AsEdgeNGramTokenizer() (*EdgeNGramTokenizer, bool) {
	return nil, false
}

// AsKeywordTokenizer is the Tokenizer implementation for PatternTokenizer.
func (pt PatternTokenizer) AsKeywordTokenizer() (*KeywordTokenizer, bool) {
	return nil, false
}

// AsKeywordTokenizerV2 is the Tokenizer implementation for PatternTokenizer.
func (pt PatternTokenizer) AsKeywordTokenizerV2() (*KeywordTokenizerV2, bool) {
	return nil, false
}

// AsMicrosoftLanguageTokenizer is the Tokenizer implementation for PatternTokenizer.
func (pt PatternTokenizer) AsMicrosoftLanguageTokenizer() (*MicrosoftLanguageTokenizer, bool) {
	return nil, false
}

// AsMicrosoftLanguageStemmingTokenizer is the Tokenizer implementation for PatternTokenizer.
func (pt PatternTokenizer) AsMicrosoftLanguageStemmingTokenizer() (*MicrosoftLanguageStemmingTokenizer, bool) {
	return nil, false
}

// AsNGramTokenizer is the Tokenizer implementation for PatternTokenizer.
func (pt PatternTokenizer) AsNGramTokenizer() (*NGramTokenizer, bool) {
	return nil, false
}

// AsPathHierarchyTokenizer is the Tokenizer implementation for PatternTokenizer.
func (pt PatternTokenizer) AsPathHierarchyTokenizer() (*PathHierarchyTokenizer, bool) {
	return nil, false
}

// AsPathHierarchyTokenizerV2 is the Tokenizer implementation for PatternTokenizer.
func (pt PatternTokenizer) AsPathHierarchyTokenizerV2() (*PathHierarchyTokenizerV2, bool) {
	return nil, false
}

// AsPatternTokenizer is the Tokenizer implementation for PatternTokenizer.
func (pt PatternTokenizer) AsPatternTokenizer() (*PatternTokenizer, bool) {
	return &pt, true
}

// AsStandardTokenizer is the Tokenizer implementation for PatternTokenizer.
func (pt PatternTokenizer) AsStandardTokenizer() (*StandardTokenizer, bool) {
	return nil, false
}

// AsStandardTokenizerV2 is the Tokenizer implementation for PatternTokenizer.
func (pt PatternTokenizer) AsStandardTokenizerV2() (*StandardTokenizerV2, bool) {
	return nil, false
}

// AsUaxURLEmailTokenizer is the Tokenizer implementation for PatternTokenizer.
func (pt PatternTokenizer) AsUaxURLEmailTokenizer() (*UaxURLEmailTokenizer, bool) {
	return nil, false
}

// PhoneticTokenFilter is create tokens for phonetic matches. This token filter is implemented using Apache Lucene.
type PhoneticTokenFilter struct {
	Name                  *string         `json:"name,omitempty"`
	OdataType             OdataType2      `json:"@odata.type,omitempty"`
	Encoder               PhoneticEncoder `json:"encoder,omitempty"`
	ReplaceOriginalTokens *bool           `json:"replace,omitempty"`
}

// MarshalJSON is the custom marshaler for PhoneticTokenFilter.
func (ptf PhoneticTokenFilter) MarshalJSON() ([]byte, error) {
	ptf.OdataType = OdataTypeMicrosoftAzureSearchPhoneticTokenFilter
	type Alias PhoneticTokenFilter
	return json.Marshal(&struct {
		Alias
	}{
		Alias: (Alias)(ptf),
	})
}

// AsASCIIFoldingTokenFilter is the TokenFilter implementation for PhoneticTokenFilter.
func (ptf PhoneticTokenFilter) AsASCIIFoldingTokenFilter() (*ASCIIFoldingTokenFilter, bool) {
	return nil, false
}

// AsCjkBigramTokenFilter is the TokenFilter implementation for PhoneticTokenFilter.
func (ptf PhoneticTokenFilter) AsCjkBigramTokenFilter() (*CjkBigramTokenFilter, bool) {
	return nil, false
}

// AsCommonGramTokenFilter is the TokenFilter implementation for PhoneticTokenFilter.
func (ptf PhoneticTokenFilter) AsCommonGramTokenFilter() (*CommonGramTokenFilter, bool) {
	return nil, false
}

// AsDictionaryDecompounderTokenFilter is the TokenFilter implementation for PhoneticTokenFilter.
func (ptf PhoneticTokenFilter) AsDictionaryDecompounderTokenFilter() (*DictionaryDecompounderTokenFilter, bool) {
	return nil, false
}

// AsEdgeNGramTokenFilter is the TokenFilter implementation for PhoneticTokenFilter.
func (ptf PhoneticTokenFilter) AsEdgeNGramTokenFilter() (*EdgeNGramTokenFilter, bool) {
	return nil, false
}

// AsEdgeNGramTokenFilterV2 is the TokenFilter implementation for PhoneticTokenFilter.
func (ptf PhoneticTokenFilter) AsEdgeNGramTokenFilterV2() (*EdgeNGramTokenFilterV2, bool) {
	return nil, false
}

// AsElisionTokenFilter is the TokenFilter implementation for PhoneticTokenFilter.
func (ptf PhoneticTokenFilter) AsElisionTokenFilter() (*ElisionTokenFilter, bool) {
	return nil, false
}

// AsKeepTokenFilter is the TokenFilter implementation for PhoneticTokenFilter.
func (ptf PhoneticTokenFilter) AsKeepTokenFilter() (*KeepTokenFilter, bool) {
	return nil, false
}

// AsKeywordMarkerTokenFilter is the TokenFilter implementation for PhoneticTokenFilter.
func (ptf PhoneticTokenFilter) AsKeywordMarkerTokenFilter() (*KeywordMarkerTokenFilter, bool) {
	return nil, false
}

// AsLengthTokenFilter is the TokenFilter implementation for PhoneticTokenFilter.
func (ptf PhoneticTokenFilter) AsLengthTokenFilter() (*LengthTokenFilter, bool) {
	return nil, false
}

// AsLimitTokenFilter is the TokenFilter implementation for PhoneticTokenFilter.
func (ptf PhoneticTokenFilter) AsLimitTokenFilter() (*LimitTokenFilter, bool) {
	return nil, false
}

// AsNGramTokenFilter is the TokenFilter implementation for PhoneticTokenFilter.
func (ptf PhoneticTokenFilter) AsNGramTokenFilter() (*NGramTokenFilter, bool) {
	return nil, false
}

// AsNGramTokenFilterV2 is the TokenFilter implementation for PhoneticTokenFilter.
func (ptf PhoneticTokenFilter) AsNGramTokenFilterV2() (*NGramTokenFilterV2, bool) {
	return nil, false
}

// AsPatternCaptureTokenFilter is the TokenFilter implementation for PhoneticTokenFilter.
func (ptf PhoneticTokenFilter) AsPatternCaptureTokenFilter() (*PatternCaptureTokenFilter, bool) {
	return nil, false
}

// AsPatternReplaceTokenFilter is the TokenFilter implementation for PhoneticTokenFilter.
func (ptf PhoneticTokenFilter) AsPatternReplaceTokenFilter() (*PatternReplaceTokenFilter, bool) {
	return nil, false
}

// AsPhoneticTokenFilter is the TokenFilter implementation for PhoneticTokenFilter.
func (ptf PhoneticTokenFilter) AsPhoneticTokenFilter() (*PhoneticTokenFilter, bool) {
	return &ptf, true
}

// AsShingleTokenFilter is the TokenFilter implementation for PhoneticTokenFilter.
func (ptf PhoneticTokenFilter) AsShingleTokenFilter() (*ShingleTokenFilter, bool) {
	return nil, false
}

// AsSnowballTokenFilter is the TokenFilter implementation for PhoneticTokenFilter.
func (ptf PhoneticTokenFilter) AsSnowballTokenFilter() (*SnowballTokenFilter, bool) {
	return nil, false
}

// AsStemmerTokenFilter is the TokenFilter implementation for PhoneticTokenFilter.
func (ptf PhoneticTokenFilter) AsStemmerTokenFilter() (*StemmerTokenFilter, bool) {
	return nil, false
}

// AsStemmerOverrideTokenFilter is the TokenFilter implementation for PhoneticTokenFilter.
func (ptf PhoneticTokenFilter) AsStemmerOverrideTokenFilter() (*StemmerOverrideTokenFilter, bool) {
	return nil, false
}

// AsStopwordsTokenFilter is the TokenFilter implementation for PhoneticTokenFilter.
func (ptf PhoneticTokenFilter) AsStopwordsTokenFilter() (*StopwordsTokenFilter, bool) {
	return nil, false
}

// AsSynonymTokenFilter is the TokenFilter implementation for PhoneticTokenFilter.
func (ptf PhoneticTokenFilter) AsSynonymTokenFilter() (*SynonymTokenFilter, bool) {
	return nil, false
}

// AsTruncateTokenFilter is the TokenFilter implementation for PhoneticTokenFilter.
func (ptf PhoneticTokenFilter) AsTruncateTokenFilter() (*TruncateTokenFilter, bool) {
	return nil, false
}

// AsUniqueTokenFilter is the TokenFilter implementation for PhoneticTokenFilter.
func (ptf PhoneticTokenFilter) AsUniqueTokenFilter() (*UniqueTokenFilter, bool) {
	return nil, false
}

// AsWordDelimiterTokenFilter is the TokenFilter implementation for PhoneticTokenFilter.
func (ptf PhoneticTokenFilter) AsWordDelimiterTokenFilter() (*WordDelimiterTokenFilter, bool) {
	return nil, false
}

// RegexFlags is defines flags that can be combined to control how regular expressions are used in the pattern analyzer
// and pattern tokenizer.
type RegexFlags struct {
	Name *string `json:"name,omitempty"`
}

// ScoringFunction is abstract base class for functions that can modify document scores during ranking.
type ScoringFunction interface {
	AsDistanceScoringFunction() (*DistanceScoringFunction, bool)
	AsFreshnessScoringFunction() (*FreshnessScoringFunction, bool)
	AsMagnitudeScoringFunction() (*MagnitudeScoringFunction, bool)
	AsTagScoringFunction() (*TagScoringFunction, bool)
}

func unmarshalScoringFunction(body []byte) (ScoringFunction, error) {
	var m map[string]interface{}
	err := json.Unmarshal(body, &m)
	if err != nil {
		return nil, err
	}

	switch m["type"] {
	case string(TypeDistance):
		var dsf DistanceScoringFunction
		err := json.Unmarshal(body, &dsf)
		return dsf, err
	case string(TypeFreshness):
		var fsf FreshnessScoringFunction
		err := json.Unmarshal(body, &fsf)
		return fsf, err
	case string(TypeMagnitude):
		var msf MagnitudeScoringFunction
		err := json.Unmarshal(body, &msf)
		return msf, err
	case string(TypeTag):
		var tsf TagScoringFunction
		err := json.Unmarshal(body, &tsf)
		return tsf, err
	default:
		return nil, errors.New("Unsupported type")
	}
}
func unmarshalScoringFunctionArray(body []byte) ([]ScoringFunction, error) {
	var rawMessages []*json.RawMessage
	err := json.Unmarshal(body, &rawMessages)
	if err != nil {
		return nil, err
	}

	sfArray := make([]ScoringFunction, len(rawMessages))

	for index, rawMessage := range rawMessages {
		sf, err := unmarshalScoringFunction(*rawMessage)
		if err != nil {
			return nil, err
		}
		sfArray[index] = sf
	}
	return sfArray, nil
}

// ScoringProfile is defines parameters for an Azure Search index that influence scoring in search queries.
type ScoringProfile struct {
	Name                *string                    `json:"name,omitempty"`
	TextWeights         *TextWeights               `json:"text,omitempty"`
	Functions           *[]ScoringFunction         `json:"functions,omitempty"`
	FunctionAggregation ScoringFunctionAggregation `json:"functionAggregation,omitempty"`
}

// UnmarshalJSON is the custom unmarshaler for ScoringProfile struct.
func (sp *ScoringProfile) UnmarshalJSON(body []byte) error {
	var m map[string]*json.RawMessage
	err := json.Unmarshal(body, &m)
	if err != nil {
		return err
	}
	var v *json.RawMessage

	v = m["name"]
	if v != nil {
		var name string
		err = json.Unmarshal(*m["name"], &name)
		if err != nil {
			return err
		}
		sp.Name = &name
	}

	v = m["text"]
	if v != nil {
		var textVar TextWeights
		err = json.Unmarshal(*m["text"], &textVar)
		if err != nil {
			return err
		}
		sp.TextWeights = &textVar
	}

	v = m["functions"]
	if v != nil {
		functions, err := unmarshalScoringFunctionArray(*m["functions"])
		if err != nil {
			return err
		}
		sp.Functions = &functions
	}

	v = m["functionAggregation"]
	if v != nil {
		var functionAggregation ScoringFunctionAggregation
		err = json.Unmarshal(*m["functionAggregation"], &functionAggregation)
		if err != nil {
			return err
		}
		sp.FunctionAggregation = functionAggregation
	}

	return nil
}

// ShingleTokenFilter is creates combinations of tokens as a single token. This token filter is implemented using
// Apache Lucene.
type ShingleTokenFilter struct {
	Name                       *string    `json:"name,omitempty"`
	OdataType                  OdataType2 `json:"@odata.type,omitempty"`
	MaxShingleSize             *int32     `json:"maxShingleSize,omitempty"`
	MinShingleSize             *int32     `json:"minShingleSize,omitempty"`
	OutputUnigrams             *bool      `json:"outputUnigrams,omitempty"`
	OutputUnigramsIfNoShingles *bool      `json:"outputUnigramsIfNoShingles,omitempty"`
	TokenSeparator             *string    `json:"tokenSeparator,omitempty"`
	FilterToken                *string    `json:"filterToken,omitempty"`
}

// MarshalJSON is the custom marshaler for ShingleTokenFilter.
func (stf ShingleTokenFilter) MarshalJSON() ([]byte, error) {
	stf.OdataType = OdataTypeMicrosoftAzureSearchShingleTokenFilter
	type Alias ShingleTokenFilter
	return json.Marshal(&struct {
		Alias
	}{
		Alias: (Alias)(stf),
	})
}

// AsASCIIFoldingTokenFilter is the TokenFilter implementation for ShingleTokenFilter.
func (stf ShingleTokenFilter) AsASCIIFoldingTokenFilter() (*ASCIIFoldingTokenFilter, bool) {
	return nil, false
}

// AsCjkBigramTokenFilter is the TokenFilter implementation for ShingleTokenFilter.
func (stf ShingleTokenFilter) AsCjkBigramTokenFilter() (*CjkBigramTokenFilter, bool) {
	return nil, false
}

// AsCommonGramTokenFilter is the TokenFilter implementation for ShingleTokenFilter.
func (stf ShingleTokenFilter) AsCommonGramTokenFilter() (*CommonGramTokenFilter, bool) {
	return nil, false
}

// AsDictionaryDecompounderTokenFilter is the TokenFilter implementation for ShingleTokenFilter.
func (stf ShingleTokenFilter) AsDictionaryDecompounderTokenFilter() (*DictionaryDecompounderTokenFilter, bool) {
	return nil, false
}

// AsEdgeNGramTokenFilter is the TokenFilter implementation for ShingleTokenFilter.
func (stf ShingleTokenFilter) AsEdgeNGramTokenFilter() (*EdgeNGramTokenFilter, bool) {
	return nil, false
}

// AsEdgeNGramTokenFilterV2 is the TokenFilter implementation for ShingleTokenFilter.
func (stf ShingleTokenFilter) AsEdgeNGramTokenFilterV2() (*EdgeNGramTokenFilterV2, bool) {
	return nil, false
}

// AsElisionTokenFilter is the TokenFilter implementation for ShingleTokenFilter.
func (stf ShingleTokenFilter) AsElisionTokenFilter() (*ElisionTokenFilter, bool) {
	return nil, false
}

// AsKeepTokenFilter is the TokenFilter implementation for ShingleTokenFilter.
func (stf ShingleTokenFilter) AsKeepTokenFilter() (*KeepTokenFilter, bool) {
	return nil, false
}

// AsKeywordMarkerTokenFilter is the TokenFilter implementation for ShingleTokenFilter.
func (stf ShingleTokenFilter) AsKeywordMarkerTokenFilter() (*KeywordMarkerTokenFilter, bool) {
	return nil, false
}

// AsLengthTokenFilter is the TokenFilter implementation for ShingleTokenFilter.
func (stf ShingleTokenFilter) AsLengthTokenFilter() (*LengthTokenFilter, bool) {
	return nil, false
}

// AsLimitTokenFilter is the TokenFilter implementation for ShingleTokenFilter.
func (stf ShingleTokenFilter) AsLimitTokenFilter() (*LimitTokenFilter, bool) {
	return nil, false
}

// AsNGramTokenFilter is the TokenFilter implementation for ShingleTokenFilter.
func (stf ShingleTokenFilter) AsNGramTokenFilter() (*NGramTokenFilter, bool) {
	return nil, false
}

// AsNGramTokenFilterV2 is the TokenFilter implementation for ShingleTokenFilter.
func (stf ShingleTokenFilter) AsNGramTokenFilterV2() (*NGramTokenFilterV2, bool) {
	return nil, false
}

// AsPatternCaptureTokenFilter is the TokenFilter implementation for ShingleTokenFilter.
func (stf ShingleTokenFilter) AsPatternCaptureTokenFilter() (*PatternCaptureTokenFilter, bool) {
	return nil, false
}

// AsPatternReplaceTokenFilter is the TokenFilter implementation for ShingleTokenFilter.
func (stf ShingleTokenFilter) AsPatternReplaceTokenFilter() (*PatternReplaceTokenFilter, bool) {
	return nil, false
}

// AsPhoneticTokenFilter is the TokenFilter implementation for ShingleTokenFilter.
func (stf ShingleTokenFilter) AsPhoneticTokenFilter() (*PhoneticTokenFilter, bool) {
	return nil, false
}

// AsShingleTokenFilter is the TokenFilter implementation for ShingleTokenFilter.
func (stf ShingleTokenFilter) AsShingleTokenFilter() (*ShingleTokenFilter, bool) {
	return &stf, true
}

// AsSnowballTokenFilter is the TokenFilter implementation for ShingleTokenFilter.
func (stf ShingleTokenFilter) AsSnowballTokenFilter() (*SnowballTokenFilter, bool) {
	return nil, false
}

// AsStemmerTokenFilter is the TokenFilter implementation for ShingleTokenFilter.
func (stf ShingleTokenFilter) AsStemmerTokenFilter() (*StemmerTokenFilter, bool) {
	return nil, false
}

// AsStemmerOverrideTokenFilter is the TokenFilter implementation for ShingleTokenFilter.
func (stf ShingleTokenFilter) AsStemmerOverrideTokenFilter() (*StemmerOverrideTokenFilter, bool) {
	return nil, false
}

// AsStopwordsTokenFilter is the TokenFilter implementation for ShingleTokenFilter.
func (stf ShingleTokenFilter) AsStopwordsTokenFilter() (*StopwordsTokenFilter, bool) {
	return nil, false
}

// AsSynonymTokenFilter is the TokenFilter implementation for ShingleTokenFilter.
func (stf ShingleTokenFilter) AsSynonymTokenFilter() (*SynonymTokenFilter, bool) {
	return nil, false
}

// AsTruncateTokenFilter is the TokenFilter implementation for ShingleTokenFilter.
func (stf ShingleTokenFilter) AsTruncateTokenFilter() (*TruncateTokenFilter, bool) {
	return nil, false
}

// AsUniqueTokenFilter is the TokenFilter implementation for ShingleTokenFilter.
func (stf ShingleTokenFilter) AsUniqueTokenFilter() (*UniqueTokenFilter, bool) {
	return nil, false
}

// AsWordDelimiterTokenFilter is the TokenFilter implementation for ShingleTokenFilter.
func (stf ShingleTokenFilter) AsWordDelimiterTokenFilter() (*WordDelimiterTokenFilter, bool) {
	return nil, false
}

// SnowballTokenFilter is a filter that stems words using a Snowball-generated stemmer. This token filter is
// implemented using Apache Lucene.
type SnowballTokenFilter struct {
	Name      *string                     `json:"name,omitempty"`
	OdataType OdataType2                  `json:"@odata.type,omitempty"`
	Language  SnowballTokenFilterLanguage `json:"language,omitempty"`
}

// MarshalJSON is the custom marshaler for SnowballTokenFilter.
func (stf SnowballTokenFilter) MarshalJSON() ([]byte, error) {
	stf.OdataType = OdataTypeMicrosoftAzureSearchSnowballTokenFilter
	type Alias SnowballTokenFilter
	return json.Marshal(&struct {
		Alias
	}{
		Alias: (Alias)(stf),
	})
}

// AsASCIIFoldingTokenFilter is the TokenFilter implementation for SnowballTokenFilter.
func (stf SnowballTokenFilter) AsASCIIFoldingTokenFilter() (*ASCIIFoldingTokenFilter, bool) {
	return nil, false
}

// AsCjkBigramTokenFilter is the TokenFilter implementation for SnowballTokenFilter.
func (stf SnowballTokenFilter) AsCjkBigramTokenFilter() (*CjkBigramTokenFilter, bool) {
	return nil, false
}

// AsCommonGramTokenFilter is the TokenFilter implementation for SnowballTokenFilter.
func (stf SnowballTokenFilter) AsCommonGramTokenFilter() (*CommonGramTokenFilter, bool) {
	return nil, false
}

// AsDictionaryDecompounderTokenFilter is the TokenFilter implementation for SnowballTokenFilter.
func (stf SnowballTokenFilter) AsDictionaryDecompounderTokenFilter() (*DictionaryDecompounderTokenFilter, bool) {
	return nil, false
}

// AsEdgeNGramTokenFilter is the TokenFilter implementation for SnowballTokenFilter.
func (stf SnowballTokenFilter) AsEdgeNGramTokenFilter() (*EdgeNGramTokenFilter, bool) {
	return nil, false
}

// AsEdgeNGramTokenFilterV2 is the TokenFilter implementation for SnowballTokenFilter.
func (stf SnowballTokenFilter) AsEdgeNGramTokenFilterV2() (*EdgeNGramTokenFilterV2, bool) {
	return nil, false
}

// AsElisionTokenFilter is the TokenFilter implementation for SnowballTokenFilter.
func (stf SnowballTokenFilter) AsElisionTokenFilter() (*ElisionTokenFilter, bool) {
	return nil, false
}

// AsKeepTokenFilter is the TokenFilter implementation for SnowballTokenFilter.
func (stf SnowballTokenFilter) AsKeepTokenFilter() (*KeepTokenFilter, bool) {
	return nil, false
}

// AsKeywordMarkerTokenFilter is the TokenFilter implementation for SnowballTokenFilter.
func (stf SnowballTokenFilter) AsKeywordMarkerTokenFilter() (*KeywordMarkerTokenFilter, bool) {
	return nil, false
}

// AsLengthTokenFilter is the TokenFilter implementation for SnowballTokenFilter.
func (stf SnowballTokenFilter) AsLengthTokenFilter() (*LengthTokenFilter, bool) {
	return nil, false
}

// AsLimitTokenFilter is the TokenFilter implementation for SnowballTokenFilter.
func (stf SnowballTokenFilter) AsLimitTokenFilter() (*LimitTokenFilter, bool) {
	return nil, false
}

// AsNGramTokenFilter is the TokenFilter implementation for SnowballTokenFilter.
func (stf SnowballTokenFilter) AsNGramTokenFilter() (*NGramTokenFilter, bool) {
	return nil, false
}

// AsNGramTokenFilterV2 is the TokenFilter implementation for SnowballTokenFilter.
func (stf SnowballTokenFilter) AsNGramTokenFilterV2() (*NGramTokenFilterV2, bool) {
	return nil, false
}

// AsPatternCaptureTokenFilter is the TokenFilter implementation for SnowballTokenFilter.
func (stf SnowballTokenFilter) AsPatternCaptureTokenFilter() (*PatternCaptureTokenFilter, bool) {
	return nil, false
}

// AsPatternReplaceTokenFilter is the TokenFilter implementation for SnowballTokenFilter.
func (stf SnowballTokenFilter) AsPatternReplaceTokenFilter() (*PatternReplaceTokenFilter, bool) {
	return nil, false
}

// AsPhoneticTokenFilter is the TokenFilter implementation for SnowballTokenFilter.
func (stf SnowballTokenFilter) AsPhoneticTokenFilter() (*PhoneticTokenFilter, bool) {
	return nil, false
}

// AsShingleTokenFilter is the TokenFilter implementation for SnowballTokenFilter.
func (stf SnowballTokenFilter) AsShingleTokenFilter() (*ShingleTokenFilter, bool) {
	return nil, false
}

// AsSnowballTokenFilter is the TokenFilter implementation for SnowballTokenFilter.
func (stf SnowballTokenFilter) AsSnowballTokenFilter() (*SnowballTokenFilter, bool) {
	return &stf, true
}

// AsStemmerTokenFilter is the TokenFilter implementation for SnowballTokenFilter.
func (stf SnowballTokenFilter) AsStemmerTokenFilter() (*StemmerTokenFilter, bool) {
	return nil, false
}

// AsStemmerOverrideTokenFilter is the TokenFilter implementation for SnowballTokenFilter.
func (stf SnowballTokenFilter) AsStemmerOverrideTokenFilter() (*StemmerOverrideTokenFilter, bool) {
	return nil, false
}

// AsStopwordsTokenFilter is the TokenFilter implementation for SnowballTokenFilter.
func (stf SnowballTokenFilter) AsStopwordsTokenFilter() (*StopwordsTokenFilter, bool) {
	return nil, false
}

// AsSynonymTokenFilter is the TokenFilter implementation for SnowballTokenFilter.
func (stf SnowballTokenFilter) AsSynonymTokenFilter() (*SynonymTokenFilter, bool) {
	return nil, false
}

// AsTruncateTokenFilter is the TokenFilter implementation for SnowballTokenFilter.
func (stf SnowballTokenFilter) AsTruncateTokenFilter() (*TruncateTokenFilter, bool) {
	return nil, false
}

// AsUniqueTokenFilter is the TokenFilter implementation for SnowballTokenFilter.
func (stf SnowballTokenFilter) AsUniqueTokenFilter() (*UniqueTokenFilter, bool) {
	return nil, false
}

// AsWordDelimiterTokenFilter is the TokenFilter implementation for SnowballTokenFilter.
func (stf SnowballTokenFilter) AsWordDelimiterTokenFilter() (*WordDelimiterTokenFilter, bool) {
	return nil, false
}

// SoftDeleteColumnDeletionDetectionPolicy is defines a data deletion detection policy that implements a soft-deletion
// strategy. It determines whether an item should be deleted based on the value of a designated 'soft delete' column.
type SoftDeleteColumnDeletionDetectionPolicy struct {
	OdataType             OdataType5 `json:"@odata.type,omitempty"`
	SoftDeleteColumnName  *string    `json:"softDeleteColumnName,omitempty"`
	SoftDeleteMarkerValue *string    `json:"softDeleteMarkerValue,omitempty"`
}

// MarshalJSON is the custom marshaler for SoftDeleteColumnDeletionDetectionPolicy.
func (sdcddp SoftDeleteColumnDeletionDetectionPolicy) MarshalJSON() ([]byte, error) {
	sdcddp.OdataType = OdataTypeMicrosoftAzureSearchSoftDeleteColumnDeletionDetectionPolicy
	type Alias SoftDeleteColumnDeletionDetectionPolicy
	return json.Marshal(&struct {
		Alias
	}{
		Alias: (Alias)(sdcddp),
	})
}

// AsSoftDeleteColumnDeletionDetectionPolicy is the DataDeletionDetectionPolicy implementation for SoftDeleteColumnDeletionDetectionPolicy.
func (sdcddp SoftDeleteColumnDeletionDetectionPolicy) AsSoftDeleteColumnDeletionDetectionPolicy() (*SoftDeleteColumnDeletionDetectionPolicy, bool) {
	return &sdcddp, true
}

// SQLIntegratedChangeTrackingPolicy is defines a data change detection policy that captures changes using the
// Integrated Change Tracking feature of Azure SQL Database.
type SQLIntegratedChangeTrackingPolicy struct {
	OdataType OdataType4 `json:"@odata.type,omitempty"`
}

// MarshalJSON is the custom marshaler for SQLIntegratedChangeTrackingPolicy.
func (sictp SQLIntegratedChangeTrackingPolicy) MarshalJSON() ([]byte, error) {
	sictp.OdataType = OdataTypeMicrosoftAzureSearchSQLIntegratedChangeTrackingPolicy
	type Alias SQLIntegratedChangeTrackingPolicy
	return json.Marshal(&struct {
		Alias
	}{
		Alias: (Alias)(sictp),
	})
}

// AsHighWaterMarkChangeDetectionPolicy is the DataChangeDetectionPolicy implementation for SQLIntegratedChangeTrackingPolicy.
func (sictp SQLIntegratedChangeTrackingPolicy) AsHighWaterMarkChangeDetectionPolicy() (*HighWaterMarkChangeDetectionPolicy, bool) {
	return nil, false
}

// AsSQLIntegratedChangeTrackingPolicy is the DataChangeDetectionPolicy implementation for SQLIntegratedChangeTrackingPolicy.
func (sictp SQLIntegratedChangeTrackingPolicy) AsSQLIntegratedChangeTrackingPolicy() (*SQLIntegratedChangeTrackingPolicy, bool) {
	return &sictp, true
}

// StandardAnalyzer is standard Apache Lucene analyzer; Composed of the standard tokenizer, lowercase filter and stop
// filter.
type StandardAnalyzer struct {
	Name           *string   `json:"name,omitempty"`
	OdataType      OdataType `json:"@odata.type,omitempty"`
	MaxTokenLength *int32    `json:"maxTokenLength,omitempty"`
	Stopwords      *[]string `json:"stopwords,omitempty"`
}

// MarshalJSON is the custom marshaler for StandardAnalyzer.
func (sa StandardAnalyzer) MarshalJSON() ([]byte, error) {
	sa.OdataType = OdataTypeMicrosoftAzureSearchStandardAnalyzer
	type Alias StandardAnalyzer
	return json.Marshal(&struct {
		Alias
	}{
		Alias: (Alias)(sa),
	})
}

// AsCustomAnalyzer is the Analyzer implementation for StandardAnalyzer.
func (sa StandardAnalyzer) AsCustomAnalyzer() (*CustomAnalyzer, bool) {
	return nil, false
}

// AsPatternAnalyzer is the Analyzer implementation for StandardAnalyzer.
func (sa StandardAnalyzer) AsPatternAnalyzer() (*PatternAnalyzer, bool) {
	return nil, false
}

// AsStandardAnalyzer is the Analyzer implementation for StandardAnalyzer.
func (sa StandardAnalyzer) AsStandardAnalyzer() (*StandardAnalyzer, bool) {
	return &sa, true
}

// AsStopAnalyzer is the Analyzer implementation for StandardAnalyzer.
func (sa StandardAnalyzer) AsStopAnalyzer() (*StopAnalyzer, bool) {
	return nil, false
}

// StandardTokenizer is breaks text following the Unicode Text Segmentation rules. This tokenizer is implemented using
// Apache Lucene.
type StandardTokenizer struct {
	Name           *string    `json:"name,omitempty"`
	OdataType      OdataType1 `json:"@odata.type,omitempty"`
	MaxTokenLength *int32     `json:"maxTokenLength,omitempty"`
}

// MarshalJSON is the custom marshaler for StandardTokenizer.
func (st StandardTokenizer) MarshalJSON() ([]byte, error) {
	st.OdataType = OdataTypeMicrosoftAzureSearchStandardTokenizer
	type Alias StandardTokenizer
	return json.Marshal(&struct {
		Alias
	}{
		Alias: (Alias)(st),
	})
}

// AsClassicTokenizer is the Tokenizer implementation for StandardTokenizer.
func (st StandardTokenizer) AsClassicTokenizer() (*ClassicTokenizer, bool) {
	return nil, false
}

// AsEdgeNGramTokenizer is the Tokenizer implementation for StandardTokenizer.
func (st StandardTokenizer) AsEdgeNGramTokenizer() (*EdgeNGramTokenizer, bool) {
	return nil, false
}

// AsKeywordTokenizer is the Tokenizer implementation for StandardTokenizer.
func (st StandardTokenizer) AsKeywordTokenizer() (*KeywordTokenizer, bool) {
	return nil, false
}

// AsKeywordTokenizerV2 is the Tokenizer implementation for StandardTokenizer.
func (st StandardTokenizer) AsKeywordTokenizerV2() (*KeywordTokenizerV2, bool) {
	return nil, false
}

// AsMicrosoftLanguageTokenizer is the Tokenizer implementation for StandardTokenizer.
func (st StandardTokenizer) AsMicrosoftLanguageTokenizer() (*MicrosoftLanguageTokenizer, bool) {
	return nil, false
}

// AsMicrosoftLanguageStemmingTokenizer is the Tokenizer implementation for StandardTokenizer.
func (st StandardTokenizer) AsMicrosoftLanguageStemmingTokenizer() (*MicrosoftLanguageStemmingTokenizer, bool) {
	return nil, false
}

// AsNGramTokenizer is the Tokenizer implementation for StandardTokenizer.
func (st StandardTokenizer) AsNGramTokenizer() (*NGramTokenizer, bool) {
	return nil, false
}

// AsPathHierarchyTokenizer is the Tokenizer implementation for StandardTokenizer.
func (st StandardTokenizer) AsPathHierarchyTokenizer() (*PathHierarchyTokenizer, bool) {
	return nil, false
}

// AsPathHierarchyTokenizerV2 is the Tokenizer implementation for StandardTokenizer.
func (st StandardTokenizer) AsPathHierarchyTokenizerV2() (*PathHierarchyTokenizerV2, bool) {
	return nil, false
}

// AsPatternTokenizer is the Tokenizer implementation for StandardTokenizer.
func (st StandardTokenizer) AsPatternTokenizer() (*PatternTokenizer, bool) {
	return nil, false
}

// AsStandardTokenizer is the Tokenizer implementation for StandardTokenizer.
func (st StandardTokenizer) AsStandardTokenizer() (*StandardTokenizer, bool) {
	return &st, true
}

// AsStandardTokenizerV2 is the Tokenizer implementation for StandardTokenizer.
func (st StandardTokenizer) AsStandardTokenizerV2() (*StandardTokenizerV2, bool) {
	return nil, false
}

// AsUaxURLEmailTokenizer is the Tokenizer implementation for StandardTokenizer.
func (st StandardTokenizer) AsUaxURLEmailTokenizer() (*UaxURLEmailTokenizer, bool) {
	return nil, false
}

// StandardTokenizerV2 is breaks text following the Unicode Text Segmentation rules. This tokenizer is implemented
// using Apache Lucene.
type StandardTokenizerV2 struct {
	Name           *string    `json:"name,omitempty"`
	OdataType      OdataType1 `json:"@odata.type,omitempty"`
	MaxTokenLength *int32     `json:"maxTokenLength,omitempty"`
}

// MarshalJSON is the custom marshaler for StandardTokenizerV2.
func (stv StandardTokenizerV2) MarshalJSON() ([]byte, error) {
	stv.OdataType = OdataTypeMicrosoftAzureSearchStandardTokenizerV2
	type Alias StandardTokenizerV2
	return json.Marshal(&struct {
		Alias
	}{
		Alias: (Alias)(stv),
	})
}

// AsClassicTokenizer is the Tokenizer implementation for StandardTokenizerV2.
func (stv StandardTokenizerV2) AsClassicTokenizer() (*ClassicTokenizer, bool) {
	return nil, false
}

// AsEdgeNGramTokenizer is the Tokenizer implementation for StandardTokenizerV2.
func (stv StandardTokenizerV2) AsEdgeNGramTokenizer() (*EdgeNGramTokenizer, bool) {
	return nil, false
}

// AsKeywordTokenizer is the Tokenizer implementation for StandardTokenizerV2.
func (stv StandardTokenizerV2) AsKeywordTokenizer() (*KeywordTokenizer, bool) {
	return nil, false
}

// AsKeywordTokenizerV2 is the Tokenizer implementation for StandardTokenizerV2.
func (stv StandardTokenizerV2) AsKeywordTokenizerV2() (*KeywordTokenizerV2, bool) {
	return nil, false
}

// AsMicrosoftLanguageTokenizer is the Tokenizer implementation for StandardTokenizerV2.
func (stv StandardTokenizerV2) AsMicrosoftLanguageTokenizer() (*MicrosoftLanguageTokenizer, bool) {
	return nil, false
}

// AsMicrosoftLanguageStemmingTokenizer is the Tokenizer implementation for StandardTokenizerV2.
func (stv StandardTokenizerV2) AsMicrosoftLanguageStemmingTokenizer() (*MicrosoftLanguageStemmingTokenizer, bool) {
	return nil, false
}

// AsNGramTokenizer is the Tokenizer implementation for StandardTokenizerV2.
func (stv StandardTokenizerV2) AsNGramTokenizer() (*NGramTokenizer, bool) {
	return nil, false
}

// AsPathHierarchyTokenizer is the Tokenizer implementation for StandardTokenizerV2.
func (stv StandardTokenizerV2) AsPathHierarchyTokenizer() (*PathHierarchyTokenizer, bool) {
	return nil, false
}

// AsPathHierarchyTokenizerV2 is the Tokenizer implementation for StandardTokenizerV2.
func (stv StandardTokenizerV2) AsPathHierarchyTokenizerV2() (*PathHierarchyTokenizerV2, bool) {
	return nil, false
}

// AsPatternTokenizer is the Tokenizer implementation for StandardTokenizerV2.
func (stv StandardTokenizerV2) AsPatternTokenizer() (*PatternTokenizer, bool) {
	return nil, false
}

// AsStandardTokenizer is the Tokenizer implementation for StandardTokenizerV2.
func (stv StandardTokenizerV2) AsStandardTokenizer() (*StandardTokenizer, bool) {
	return nil, false
}

// AsStandardTokenizerV2 is the Tokenizer implementation for StandardTokenizerV2.
func (stv StandardTokenizerV2) AsStandardTokenizerV2() (*StandardTokenizerV2, bool) {
	return &stv, true
}

// AsUaxURLEmailTokenizer is the Tokenizer implementation for StandardTokenizerV2.
func (stv StandardTokenizerV2) AsUaxURLEmailTokenizer() (*UaxURLEmailTokenizer, bool) {
	return nil, false
}

// StemmerOverrideTokenFilter is provides the ability to override other stemming filters with custom dictionary-based
// stemming. Any dictionary-stemmed terms will be marked as keywords so that they will not be stemmed with stemmers
// down the chain. Must be placed before any stemming filters. This token filter is implemented using Apache Lucene.
type StemmerOverrideTokenFilter struct {
	Name      *string    `json:"name,omitempty"`
	OdataType OdataType2 `json:"@odata.type,omitempty"`
	Rules     *[]string  `json:"rules,omitempty"`
}

// MarshalJSON is the custom marshaler for StemmerOverrideTokenFilter.
func (sotf StemmerOverrideTokenFilter) MarshalJSON() ([]byte, error) {
	sotf.OdataType = OdataTypeMicrosoftAzureSearchStemmerOverrideTokenFilter
	type Alias StemmerOverrideTokenFilter
	return json.Marshal(&struct {
		Alias
	}{
		Alias: (Alias)(sotf),
	})
}

// AsASCIIFoldingTokenFilter is the TokenFilter implementation for StemmerOverrideTokenFilter.
func (sotf StemmerOverrideTokenFilter) AsASCIIFoldingTokenFilter() (*ASCIIFoldingTokenFilter, bool) {
	return nil, false
}

// AsCjkBigramTokenFilter is the TokenFilter implementation for StemmerOverrideTokenFilter.
func (sotf StemmerOverrideTokenFilter) AsCjkBigramTokenFilter() (*CjkBigramTokenFilter, bool) {
	return nil, false
}

// AsCommonGramTokenFilter is the TokenFilter implementation for StemmerOverrideTokenFilter.
func (sotf StemmerOverrideTokenFilter) AsCommonGramTokenFilter() (*CommonGramTokenFilter, bool) {
	return nil, false
}

// AsDictionaryDecompounderTokenFilter is the TokenFilter implementation for StemmerOverrideTokenFilter.
func (sotf StemmerOverrideTokenFilter) AsDictionaryDecompounderTokenFilter() (*DictionaryDecompounderTokenFilter, bool) {
	return nil, false
}

// AsEdgeNGramTokenFilter is the TokenFilter implementation for StemmerOverrideTokenFilter.
func (sotf StemmerOverrideTokenFilter) AsEdgeNGramTokenFilter() (*EdgeNGramTokenFilter, bool) {
	return nil, false
}

// AsEdgeNGramTokenFilterV2 is the TokenFilter implementation for StemmerOverrideTokenFilter.
func (sotf StemmerOverrideTokenFilter) AsEdgeNGramTokenFilterV2() (*EdgeNGramTokenFilterV2, bool) {
	return nil, false
}

// AsElisionTokenFilter is the TokenFilter implementation for StemmerOverrideTokenFilter.
func (sotf StemmerOverrideTokenFilter) AsElisionTokenFilter() (*ElisionTokenFilter, bool) {
	return nil, false
}

// AsKeepTokenFilter is the TokenFilter implementation for StemmerOverrideTokenFilter.
func (sotf StemmerOverrideTokenFilter) AsKeepTokenFilter() (*KeepTokenFilter, bool) {
	return nil, false
}

// AsKeywordMarkerTokenFilter is the TokenFilter implementation for StemmerOverrideTokenFilter.
func (sotf StemmerOverrideTokenFilter) AsKeywordMarkerTokenFilter() (*KeywordMarkerTokenFilter, bool) {
	return nil, false
}

// AsLengthTokenFilter is the TokenFilter implementation for StemmerOverrideTokenFilter.
func (sotf StemmerOverrideTokenFilter) AsLengthTokenFilter() (*LengthTokenFilter, bool) {
	return nil, false
}

// AsLimitTokenFilter is the TokenFilter implementation for StemmerOverrideTokenFilter.
func (sotf StemmerOverrideTokenFilter) AsLimitTokenFilter() (*LimitTokenFilter, bool) {
	return nil, false
}

// AsNGramTokenFilter is the TokenFilter implementation for StemmerOverrideTokenFilter.
func (sotf StemmerOverrideTokenFilter) AsNGramTokenFilter() (*NGramTokenFilter, bool) {
	return nil, false
}

// AsNGramTokenFilterV2 is the TokenFilter implementation for StemmerOverrideTokenFilter.
func (sotf StemmerOverrideTokenFilter) AsNGramTokenFilterV2() (*NGramTokenFilterV2, bool) {
	return nil, false
}

// AsPatternCaptureTokenFilter is the TokenFilter implementation for StemmerOverrideTokenFilter.
func (sotf StemmerOverrideTokenFilter) AsPatternCaptureTokenFilter() (*PatternCaptureTokenFilter, bool) {
	return nil, false
}

// AsPatternReplaceTokenFilter is the TokenFilter implementation for StemmerOverrideTokenFilter.
func (sotf StemmerOverrideTokenFilter) AsPatternReplaceTokenFilter() (*PatternReplaceTokenFilter, bool) {
	return nil, false
}

// AsPhoneticTokenFilter is the TokenFilter implementation for StemmerOverrideTokenFilter.
func (sotf StemmerOverrideTokenFilter) AsPhoneticTokenFilter() (*PhoneticTokenFilter, bool) {
	return nil, false
}

// AsShingleTokenFilter is the TokenFilter implementation for StemmerOverrideTokenFilter.
func (sotf StemmerOverrideTokenFilter) AsShingleTokenFilter() (*ShingleTokenFilter, bool) {
	return nil, false
}

// AsSnowballTokenFilter is the TokenFilter implementation for StemmerOverrideTokenFilter.
func (sotf StemmerOverrideTokenFilter) AsSnowballTokenFilter() (*SnowballTokenFilter, bool) {
	return nil, false
}

// AsStemmerTokenFilter is the TokenFilter implementation for StemmerOverrideTokenFilter.
func (sotf StemmerOverrideTokenFilter) AsStemmerTokenFilter() (*StemmerTokenFilter, bool) {
	return nil, false
}

// AsStemmerOverrideTokenFilter is the TokenFilter implementation for StemmerOverrideTokenFilter.
func (sotf StemmerOverrideTokenFilter) AsStemmerOverrideTokenFilter() (*StemmerOverrideTokenFilter, bool) {
	return &sotf, true
}

// AsStopwordsTokenFilter is the TokenFilter implementation for StemmerOverrideTokenFilter.
func (sotf StemmerOverrideTokenFilter) AsStopwordsTokenFilter() (*StopwordsTokenFilter, bool) {
	return nil, false
}

// AsSynonymTokenFilter is the TokenFilter implementation for StemmerOverrideTokenFilter.
func (sotf StemmerOverrideTokenFilter) AsSynonymTokenFilter() (*SynonymTokenFilter, bool) {
	return nil, false
}

// AsTruncateTokenFilter is the TokenFilter implementation for StemmerOverrideTokenFilter.
func (sotf StemmerOverrideTokenFilter) AsTruncateTokenFilter() (*TruncateTokenFilter, bool) {
	return nil, false
}

// AsUniqueTokenFilter is the TokenFilter implementation for StemmerOverrideTokenFilter.
func (sotf StemmerOverrideTokenFilter) AsUniqueTokenFilter() (*UniqueTokenFilter, bool) {
	return nil, false
}

// AsWordDelimiterTokenFilter is the TokenFilter implementation for StemmerOverrideTokenFilter.
func (sotf StemmerOverrideTokenFilter) AsWordDelimiterTokenFilter() (*WordDelimiterTokenFilter, bool) {
	return nil, false
}

// StemmerTokenFilter is language specific stemming filter. This token filter is implemented using Apache Lucene.
type StemmerTokenFilter struct {
	Name      *string                    `json:"name,omitempty"`
	OdataType OdataType2                 `json:"@odata.type,omitempty"`
	Language  StemmerTokenFilterLanguage `json:"language,omitempty"`
}

// MarshalJSON is the custom marshaler for StemmerTokenFilter.
func (stf StemmerTokenFilter) MarshalJSON() ([]byte, error) {
	stf.OdataType = OdataTypeMicrosoftAzureSearchStemmerTokenFilter
	type Alias StemmerTokenFilter
	return json.Marshal(&struct {
		Alias
	}{
		Alias: (Alias)(stf),
	})
}

// AsASCIIFoldingTokenFilter is the TokenFilter implementation for StemmerTokenFilter.
func (stf StemmerTokenFilter) AsASCIIFoldingTokenFilter() (*ASCIIFoldingTokenFilter, bool) {
	return nil, false
}

// AsCjkBigramTokenFilter is the TokenFilter implementation for StemmerTokenFilter.
func (stf StemmerTokenFilter) AsCjkBigramTokenFilter() (*CjkBigramTokenFilter, bool) {
	return nil, false
}

// AsCommonGramTokenFilter is the TokenFilter implementation for StemmerTokenFilter.
func (stf StemmerTokenFilter) AsCommonGramTokenFilter() (*CommonGramTokenFilter, bool) {
	return nil, false
}

// AsDictionaryDecompounderTokenFilter is the TokenFilter implementation for StemmerTokenFilter.
func (stf StemmerTokenFilter) AsDictionaryDecompounderTokenFilter() (*DictionaryDecompounderTokenFilter, bool) {
	return nil, false
}

// AsEdgeNGramTokenFilter is the TokenFilter implementation for StemmerTokenFilter.
func (stf StemmerTokenFilter) AsEdgeNGramTokenFilter() (*EdgeNGramTokenFilter, bool) {
	return nil, false
}

// AsEdgeNGramTokenFilterV2 is the TokenFilter implementation for StemmerTokenFilter.
func (stf StemmerTokenFilter) AsEdgeNGramTokenFilterV2() (*EdgeNGramTokenFilterV2, bool) {
	return nil, false
}

// AsElisionTokenFilter is the TokenFilter implementation for StemmerTokenFilter.
func (stf StemmerTokenFilter) AsElisionTokenFilter() (*ElisionTokenFilter, bool) {
	return nil, false
}

// AsKeepTokenFilter is the TokenFilter implementation for StemmerTokenFilter.
func (stf StemmerTokenFilter) AsKeepTokenFilter() (*KeepTokenFilter, bool) {
	return nil, false
}

// AsKeywordMarkerTokenFilter is the TokenFilter implementation for StemmerTokenFilter.
func (stf StemmerTokenFilter) AsKeywordMarkerTokenFilter() (*KeywordMarkerTokenFilter, bool) {
	return nil, false
}

// AsLengthTokenFilter is the TokenFilter implementation for StemmerTokenFilter.
func (stf StemmerTokenFilter) AsLengthTokenFilter() (*LengthTokenFilter, bool) {
	return nil, false
}

// AsLimitTokenFilter is the TokenFilter implementation for StemmerTokenFilter.
func (stf StemmerTokenFilter) AsLimitTokenFilter() (*LimitTokenFilter, bool) {
	return nil, false
}

// AsNGramTokenFilter is the TokenFilter implementation for StemmerTokenFilter.
func (stf StemmerTokenFilter) AsNGramTokenFilter() (*NGramTokenFilter, bool) {
	return nil, false
}

// AsNGramTokenFilterV2 is the TokenFilter implementation for StemmerTokenFilter.
func (stf StemmerTokenFilter) AsNGramTokenFilterV2() (*NGramTokenFilterV2, bool) {
	return nil, false
}

// AsPatternCaptureTokenFilter is the TokenFilter implementation for StemmerTokenFilter.
func (stf StemmerTokenFilter) AsPatternCaptureTokenFilter() (*PatternCaptureTokenFilter, bool) {
	return nil, false
}

// AsPatternReplaceTokenFilter is the TokenFilter implementation for StemmerTokenFilter.
func (stf StemmerTokenFilter) AsPatternReplaceTokenFilter() (*PatternReplaceTokenFilter, bool) {
	return nil, false
}

// AsPhoneticTokenFilter is the TokenFilter implementation for StemmerTokenFilter.
func (stf StemmerTokenFilter) AsPhoneticTokenFilter() (*PhoneticTokenFilter, bool) {
	return nil, false
}

// AsShingleTokenFilter is the TokenFilter implementation for StemmerTokenFilter.
func (stf StemmerTokenFilter) AsShingleTokenFilter() (*ShingleTokenFilter, bool) {
	return nil, false
}

// AsSnowballTokenFilter is the TokenFilter implementation for StemmerTokenFilter.
func (stf StemmerTokenFilter) AsSnowballTokenFilter() (*SnowballTokenFilter, bool) {
	return nil, false
}

// AsStemmerTokenFilter is the TokenFilter implementation for StemmerTokenFilter.
func (stf StemmerTokenFilter) AsStemmerTokenFilter() (*StemmerTokenFilter, bool) {
	return &stf, true
}

// AsStemmerOverrideTokenFilter is the TokenFilter implementation for StemmerTokenFilter.
func (stf StemmerTokenFilter) AsStemmerOverrideTokenFilter() (*StemmerOverrideTokenFilter, bool) {
	return nil, false
}

// AsStopwordsTokenFilter is the TokenFilter implementation for StemmerTokenFilter.
func (stf StemmerTokenFilter) AsStopwordsTokenFilter() (*StopwordsTokenFilter, bool) {
	return nil, false
}

// AsSynonymTokenFilter is the TokenFilter implementation for StemmerTokenFilter.
func (stf StemmerTokenFilter) AsSynonymTokenFilter() (*SynonymTokenFilter, bool) {
	return nil, false
}

// AsTruncateTokenFilter is the TokenFilter implementation for StemmerTokenFilter.
func (stf StemmerTokenFilter) AsTruncateTokenFilter() (*TruncateTokenFilter, bool) {
	return nil, false
}

// AsUniqueTokenFilter is the TokenFilter implementation for StemmerTokenFilter.
func (stf StemmerTokenFilter) AsUniqueTokenFilter() (*UniqueTokenFilter, bool) {
	return nil, false
}

// AsWordDelimiterTokenFilter is the TokenFilter implementation for StemmerTokenFilter.
func (stf StemmerTokenFilter) AsWordDelimiterTokenFilter() (*WordDelimiterTokenFilter, bool) {
	return nil, false
}

// StopAnalyzer is divides text at non-letters; Applies the lowercase and stopword token filters. This analyzer is
// implemented using Apache Lucene.
type StopAnalyzer struct {
	Name      *string   `json:"name,omitempty"`
	OdataType OdataType `json:"@odata.type,omitempty"`
	Stopwords *[]string `json:"stopwords,omitempty"`
}

// MarshalJSON is the custom marshaler for StopAnalyzer.
func (sa StopAnalyzer) MarshalJSON() ([]byte, error) {
	sa.OdataType = OdataTypeMicrosoftAzureSearchStopAnalyzer
	type Alias StopAnalyzer
	return json.Marshal(&struct {
		Alias
	}{
		Alias: (Alias)(sa),
	})
}

// AsCustomAnalyzer is the Analyzer implementation for StopAnalyzer.
func (sa StopAnalyzer) AsCustomAnalyzer() (*CustomAnalyzer, bool) {
	return nil, false
}

// AsPatternAnalyzer is the Analyzer implementation for StopAnalyzer.
func (sa StopAnalyzer) AsPatternAnalyzer() (*PatternAnalyzer, bool) {
	return nil, false
}

// AsStandardAnalyzer is the Analyzer implementation for StopAnalyzer.
func (sa StopAnalyzer) AsStandardAnalyzer() (*StandardAnalyzer, bool) {
	return nil, false
}

// AsStopAnalyzer is the Analyzer implementation for StopAnalyzer.
func (sa StopAnalyzer) AsStopAnalyzer() (*StopAnalyzer, bool) {
	return &sa, true
}

// StopwordsTokenFilter is removes stop words from a token stream. This token filter is implemented using Apache
// Lucene.
type StopwordsTokenFilter struct {
	Name                    *string       `json:"name,omitempty"`
	OdataType               OdataType2    `json:"@odata.type,omitempty"`
	Stopwords               *[]string     `json:"stopwords,omitempty"`
	StopwordsList           StopwordsList `json:"stopwordsList,omitempty"`
	IgnoreCase              *bool         `json:"ignoreCase,omitempty"`
	RemoveTrailingStopWords *bool         `json:"removeTrailing,omitempty"`
}

// MarshalJSON is the custom marshaler for StopwordsTokenFilter.
func (stf StopwordsTokenFilter) MarshalJSON() ([]byte, error) {
	stf.OdataType = OdataTypeMicrosoftAzureSearchStopwordsTokenFilter
	type Alias StopwordsTokenFilter
	return json.Marshal(&struct {
		Alias
	}{
		Alias: (Alias)(stf),
	})
}

// AsASCIIFoldingTokenFilter is the TokenFilter implementation for StopwordsTokenFilter.
func (stf StopwordsTokenFilter) AsASCIIFoldingTokenFilter() (*ASCIIFoldingTokenFilter, bool) {
	return nil, false
}

// AsCjkBigramTokenFilter is the TokenFilter implementation for StopwordsTokenFilter.
func (stf StopwordsTokenFilter) AsCjkBigramTokenFilter() (*CjkBigramTokenFilter, bool) {
	return nil, false
}

// AsCommonGramTokenFilter is the TokenFilter implementation for StopwordsTokenFilter.
func (stf StopwordsTokenFilter) AsCommonGramTokenFilter() (*CommonGramTokenFilter, bool) {
	return nil, false
}

// AsDictionaryDecompounderTokenFilter is the TokenFilter implementation for StopwordsTokenFilter.
func (stf StopwordsTokenFilter) AsDictionaryDecompounderTokenFilter() (*DictionaryDecompounderTokenFilter, bool) {
	return nil, false
}

// AsEdgeNGramTokenFilter is the TokenFilter implementation for StopwordsTokenFilter.
func (stf StopwordsTokenFilter) AsEdgeNGramTokenFilter() (*EdgeNGramTokenFilter, bool) {
	return nil, false
}

// AsEdgeNGramTokenFilterV2 is the TokenFilter implementation for StopwordsTokenFilter.
func (stf StopwordsTokenFilter) AsEdgeNGramTokenFilterV2() (*EdgeNGramTokenFilterV2, bool) {
	return nil, false
}

// AsElisionTokenFilter is the TokenFilter implementation for StopwordsTokenFilter.
func (stf StopwordsTokenFilter) AsElisionTokenFilter() (*ElisionTokenFilter, bool) {
	return nil, false
}

// AsKeepTokenFilter is the TokenFilter implementation for StopwordsTokenFilter.
func (stf StopwordsTokenFilter) AsKeepTokenFilter() (*KeepTokenFilter, bool) {
	return nil, false
}

// AsKeywordMarkerTokenFilter is the TokenFilter implementation for StopwordsTokenFilter.
func (stf StopwordsTokenFilter) AsKeywordMarkerTokenFilter() (*KeywordMarkerTokenFilter, bool) {
	return nil, false
}

// AsLengthTokenFilter is the TokenFilter implementation for StopwordsTokenFilter.
func (stf StopwordsTokenFilter) AsLengthTokenFilter() (*LengthTokenFilter, bool) {
	return nil, false
}

// AsLimitTokenFilter is the TokenFilter implementation for StopwordsTokenFilter.
func (stf StopwordsTokenFilter) AsLimitTokenFilter() (*LimitTokenFilter, bool) {
	return nil, false
}

// AsNGramTokenFilter is the TokenFilter implementation for StopwordsTokenFilter.
func (stf StopwordsTokenFilter) AsNGramTokenFilter() (*NGramTokenFilter, bool) {
	return nil, false
}

// AsNGramTokenFilterV2 is the TokenFilter implementation for StopwordsTokenFilter.
func (stf StopwordsTokenFilter) AsNGramTokenFilterV2() (*NGramTokenFilterV2, bool) {
	return nil, false
}

// AsPatternCaptureTokenFilter is the TokenFilter implementation for StopwordsTokenFilter.
func (stf StopwordsTokenFilter) AsPatternCaptureTokenFilter() (*PatternCaptureTokenFilter, bool) {
	return nil, false
}

// AsPatternReplaceTokenFilter is the TokenFilter implementation for StopwordsTokenFilter.
func (stf StopwordsTokenFilter) AsPatternReplaceTokenFilter() (*PatternReplaceTokenFilter, bool) {
	return nil, false
}

// AsPhoneticTokenFilter is the TokenFilter implementation for StopwordsTokenFilter.
func (stf StopwordsTokenFilter) AsPhoneticTokenFilter() (*PhoneticTokenFilter, bool) {
	return nil, false
}

// AsShingleTokenFilter is the TokenFilter implementation for StopwordsTokenFilter.
func (stf StopwordsTokenFilter) AsShingleTokenFilter() (*ShingleTokenFilter, bool) {
	return nil, false
}

// AsSnowballTokenFilter is the TokenFilter implementation for StopwordsTokenFilter.
func (stf StopwordsTokenFilter) AsSnowballTokenFilter() (*SnowballTokenFilter, bool) {
	return nil, false
}

// AsStemmerTokenFilter is the TokenFilter implementation for StopwordsTokenFilter.
func (stf StopwordsTokenFilter) AsStemmerTokenFilter() (*StemmerTokenFilter, bool) {
	return nil, false
}

// AsStemmerOverrideTokenFilter is the TokenFilter implementation for StopwordsTokenFilter.
func (stf StopwordsTokenFilter) AsStemmerOverrideTokenFilter() (*StemmerOverrideTokenFilter, bool) {
	return nil, false
}

// AsStopwordsTokenFilter is the TokenFilter implementation for StopwordsTokenFilter.
func (stf StopwordsTokenFilter) AsStopwordsTokenFilter() (*StopwordsTokenFilter, bool) {
	return &stf, true
}

// AsSynonymTokenFilter is the TokenFilter implementation for StopwordsTokenFilter.
func (stf StopwordsTokenFilter) AsSynonymTokenFilter() (*SynonymTokenFilter, bool) {
	return nil, false
}

// AsTruncateTokenFilter is the TokenFilter implementation for StopwordsTokenFilter.
func (stf StopwordsTokenFilter) AsTruncateTokenFilter() (*TruncateTokenFilter, bool) {
	return nil, false
}

// AsUniqueTokenFilter is the TokenFilter implementation for StopwordsTokenFilter.
func (stf StopwordsTokenFilter) AsUniqueTokenFilter() (*UniqueTokenFilter, bool) {
	return nil, false
}

// AsWordDelimiterTokenFilter is the TokenFilter implementation for StopwordsTokenFilter.
func (stf StopwordsTokenFilter) AsWordDelimiterTokenFilter() (*WordDelimiterTokenFilter, bool) {
	return nil, false
}

// Suggester is defines how the Suggest API should apply to a group of fields in the index.
type Suggester struct {
	Name         *string   `json:"name,omitempty"`
	SearchMode   *string   `json:"searchMode,omitempty"`
	SourceFields *[]string `json:"sourceFields,omitempty"`
}

// SuggestParametersPayload is parameters for filtering, sorting, fuzzy matching, and other suggestions query
// behaviors.
type SuggestParametersPayload struct {
	Filter           *string  `json:"filter,omitempty"`
	Fuzzy            *bool    `json:"fuzzy,omitempty"`
	HighlightPostTag *string  `json:"highlightPostTag,omitempty"`
	HighlightPreTag  *string  `json:"highlightPreTag,omitempty"`
	MinimumCoverage  *float64 `json:"minimumCoverage,omitempty"`
	OrderBy          *string  `json:"orderby,omitempty"`
	SearchProperty   *string  `json:"search,omitempty"`
	SearchFields     *string  `json:"searchFields,omitempty"`
	Select           *string  `json:"select,omitempty"`
	SuggesterName    *string  `json:"suggesterName,omitempty"`
	Top              *int32   `json:"top,omitempty"`
}

// SynonymTokenFilter is matches single or multi-word synonyms in a token stream. This token filter is implemented
// using Apache Lucene.
type SynonymTokenFilter struct {
	Name       *string    `json:"name,omitempty"`
	OdataType  OdataType2 `json:"@odata.type,omitempty"`
	Synonyms   *[]string  `json:"synonyms,omitempty"`
	IgnoreCase *bool      `json:"ignoreCase,omitempty"`
	Expand     *bool      `json:"expand,omitempty"`
}

// MarshalJSON is the custom marshaler for SynonymTokenFilter.
func (stf SynonymTokenFilter) MarshalJSON() ([]byte, error) {
	stf.OdataType = OdataTypeMicrosoftAzureSearchSynonymTokenFilter
	type Alias SynonymTokenFilter
	return json.Marshal(&struct {
		Alias
	}{
		Alias: (Alias)(stf),
	})
}

// AsASCIIFoldingTokenFilter is the TokenFilter implementation for SynonymTokenFilter.
func (stf SynonymTokenFilter) AsASCIIFoldingTokenFilter() (*ASCIIFoldingTokenFilter, bool) {
	return nil, false
}

// AsCjkBigramTokenFilter is the TokenFilter implementation for SynonymTokenFilter.
func (stf SynonymTokenFilter) AsCjkBigramTokenFilter() (*CjkBigramTokenFilter, bool) {
	return nil, false
}

// AsCommonGramTokenFilter is the TokenFilter implementation for SynonymTokenFilter.
func (stf SynonymTokenFilter) AsCommonGramTokenFilter() (*CommonGramTokenFilter, bool) {
	return nil, false
}

// AsDictionaryDecompounderTokenFilter is the TokenFilter implementation for SynonymTokenFilter.
func (stf SynonymTokenFilter) AsDictionaryDecompounderTokenFilter() (*DictionaryDecompounderTokenFilter, bool) {
	return nil, false
}

// AsEdgeNGramTokenFilter is the TokenFilter implementation for SynonymTokenFilter.
func (stf SynonymTokenFilter) AsEdgeNGramTokenFilter() (*EdgeNGramTokenFilter, bool) {
	return nil, false
}

// AsEdgeNGramTokenFilterV2 is the TokenFilter implementation for SynonymTokenFilter.
func (stf SynonymTokenFilter) AsEdgeNGramTokenFilterV2() (*EdgeNGramTokenFilterV2, bool) {
	return nil, false
}

// AsElisionTokenFilter is the TokenFilter implementation for SynonymTokenFilter.
func (stf SynonymTokenFilter) AsElisionTokenFilter() (*ElisionTokenFilter, bool) {
	return nil, false
}

// AsKeepTokenFilter is the TokenFilter implementation for SynonymTokenFilter.
func (stf SynonymTokenFilter) AsKeepTokenFilter() (*KeepTokenFilter, bool) {
	return nil, false
}

// AsKeywordMarkerTokenFilter is the TokenFilter implementation for SynonymTokenFilter.
func (stf SynonymTokenFilter) AsKeywordMarkerTokenFilter() (*KeywordMarkerTokenFilter, bool) {
	return nil, false
}

// AsLengthTokenFilter is the TokenFilter implementation for SynonymTokenFilter.
func (stf SynonymTokenFilter) AsLengthTokenFilter() (*LengthTokenFilter, bool) {
	return nil, false
}

// AsLimitTokenFilter is the TokenFilter implementation for SynonymTokenFilter.
func (stf SynonymTokenFilter) AsLimitTokenFilter() (*LimitTokenFilter, bool) {
	return nil, false
}

// AsNGramTokenFilter is the TokenFilter implementation for SynonymTokenFilter.
func (stf SynonymTokenFilter) AsNGramTokenFilter() (*NGramTokenFilter, bool) {
	return nil, false
}

// AsNGramTokenFilterV2 is the TokenFilter implementation for SynonymTokenFilter.
func (stf SynonymTokenFilter) AsNGramTokenFilterV2() (*NGramTokenFilterV2, bool) {
	return nil, false
}

// AsPatternCaptureTokenFilter is the TokenFilter implementation for SynonymTokenFilter.
func (stf SynonymTokenFilter) AsPatternCaptureTokenFilter() (*PatternCaptureTokenFilter, bool) {
	return nil, false
}

// AsPatternReplaceTokenFilter is the TokenFilter implementation for SynonymTokenFilter.
func (stf SynonymTokenFilter) AsPatternReplaceTokenFilter() (*PatternReplaceTokenFilter, bool) {
	return nil, false
}

// AsPhoneticTokenFilter is the TokenFilter implementation for SynonymTokenFilter.
func (stf SynonymTokenFilter) AsPhoneticTokenFilter() (*PhoneticTokenFilter, bool) {
	return nil, false
}

// AsShingleTokenFilter is the TokenFilter implementation for SynonymTokenFilter.
func (stf SynonymTokenFilter) AsShingleTokenFilter() (*ShingleTokenFilter, bool) {
	return nil, false
}

// AsSnowballTokenFilter is the TokenFilter implementation for SynonymTokenFilter.
func (stf SynonymTokenFilter) AsSnowballTokenFilter() (*SnowballTokenFilter, bool) {
	return nil, false
}

// AsStemmerTokenFilter is the TokenFilter implementation for SynonymTokenFilter.
func (stf SynonymTokenFilter) AsStemmerTokenFilter() (*StemmerTokenFilter, bool) {
	return nil, false
}

// AsStemmerOverrideTokenFilter is the TokenFilter implementation for SynonymTokenFilter.
func (stf SynonymTokenFilter) AsStemmerOverrideTokenFilter() (*StemmerOverrideTokenFilter, bool) {
	return nil, false
}

// AsStopwordsTokenFilter is the TokenFilter implementation for SynonymTokenFilter.
func (stf SynonymTokenFilter) AsStopwordsTokenFilter() (*StopwordsTokenFilter, bool) {
	return nil, false
}

// AsSynonymTokenFilter is the TokenFilter implementation for SynonymTokenFilter.
func (stf SynonymTokenFilter) AsSynonymTokenFilter() (*SynonymTokenFilter, bool) {
	return &stf, true
}

// AsTruncateTokenFilter is the TokenFilter implementation for SynonymTokenFilter.
func (stf SynonymTokenFilter) AsTruncateTokenFilter() (*TruncateTokenFilter, bool) {
	return nil, false
}

// AsUniqueTokenFilter is the TokenFilter implementation for SynonymTokenFilter.
func (stf SynonymTokenFilter) AsUniqueTokenFilter() (*UniqueTokenFilter, bool) {
	return nil, false
}

// AsWordDelimiterTokenFilter is the TokenFilter implementation for SynonymTokenFilter.
func (stf SynonymTokenFilter) AsWordDelimiterTokenFilter() (*WordDelimiterTokenFilter, bool) {
	return nil, false
}

// TagScoringFunction is defines a function that boosts scores of documents with string values matching a given list of
// tags.
type TagScoringFunction struct {
	FieldName     *string                      `json:"fieldName,omitempty"`
	Boost         *float64                     `json:"boost,omitempty"`
	Interpolation ScoringFunctionInterpolation `json:"interpolation,omitempty"`
	Type          Type                         `json:"type,omitempty"`
	Parameters    *TagScoringParameters        `json:"tag,omitempty"`
}

// MarshalJSON is the custom marshaler for TagScoringFunction.
func (tsf TagScoringFunction) MarshalJSON() ([]byte, error) {
	tsf.Type = TypeTag
	type Alias TagScoringFunction
	return json.Marshal(&struct {
		Alias
	}{
		Alias: (Alias)(tsf),
	})
}

// AsDistanceScoringFunction is the ScoringFunction implementation for TagScoringFunction.
func (tsf TagScoringFunction) AsDistanceScoringFunction() (*DistanceScoringFunction, bool) {
	return nil, false
}

// AsFreshnessScoringFunction is the ScoringFunction implementation for TagScoringFunction.
func (tsf TagScoringFunction) AsFreshnessScoringFunction() (*FreshnessScoringFunction, bool) {
	return nil, false
}

// AsMagnitudeScoringFunction is the ScoringFunction implementation for TagScoringFunction.
func (tsf TagScoringFunction) AsMagnitudeScoringFunction() (*MagnitudeScoringFunction, bool) {
	return nil, false
}

// AsTagScoringFunction is the ScoringFunction implementation for TagScoringFunction.
func (tsf TagScoringFunction) AsTagScoringFunction() (*TagScoringFunction, bool) {
	return &tsf, true
}

// TagScoringParameters is provides parameter values to a tag scoring function.
type TagScoringParameters struct {
	TagsParameter *string `json:"tagsParameter,omitempty"`
}

// TextWeights is defines weights on index fields for which matches should boost scoring in search queries.
type TextWeights struct {
	Weights *map[string]*float64 `json:"weights,omitempty"`
}

// TokenFilter is abstract base class for token filters.
type TokenFilter interface {
	AsASCIIFoldingTokenFilter() (*ASCIIFoldingTokenFilter, bool)
	AsCjkBigramTokenFilter() (*CjkBigramTokenFilter, bool)
	AsCommonGramTokenFilter() (*CommonGramTokenFilter, bool)
	AsDictionaryDecompounderTokenFilter() (*DictionaryDecompounderTokenFilter, bool)
	AsEdgeNGramTokenFilter() (*EdgeNGramTokenFilter, bool)
	AsEdgeNGramTokenFilterV2() (*EdgeNGramTokenFilterV2, bool)
	AsElisionTokenFilter() (*ElisionTokenFilter, bool)
	AsKeepTokenFilter() (*KeepTokenFilter, bool)
	AsKeywordMarkerTokenFilter() (*KeywordMarkerTokenFilter, bool)
	AsLengthTokenFilter() (*LengthTokenFilter, bool)
	AsLimitTokenFilter() (*LimitTokenFilter, bool)
	AsNGramTokenFilter() (*NGramTokenFilter, bool)
	AsNGramTokenFilterV2() (*NGramTokenFilterV2, bool)
	AsPatternCaptureTokenFilter() (*PatternCaptureTokenFilter, bool)
	AsPatternReplaceTokenFilter() (*PatternReplaceTokenFilter, bool)
	AsPhoneticTokenFilter() (*PhoneticTokenFilter, bool)
	AsShingleTokenFilter() (*ShingleTokenFilter, bool)
	AsSnowballTokenFilter() (*SnowballTokenFilter, bool)
	AsStemmerTokenFilter() (*StemmerTokenFilter, bool)
	AsStemmerOverrideTokenFilter() (*StemmerOverrideTokenFilter, bool)
	AsStopwordsTokenFilter() (*StopwordsTokenFilter, bool)
	AsSynonymTokenFilter() (*SynonymTokenFilter, bool)
	AsTruncateTokenFilter() (*TruncateTokenFilter, bool)
	AsUniqueTokenFilter() (*UniqueTokenFilter, bool)
	AsWordDelimiterTokenFilter() (*WordDelimiterTokenFilter, bool)
}

func unmarshalTokenFilter(body []byte) (TokenFilter, error) {
	var m map[string]interface{}
	err := json.Unmarshal(body, &m)
	if err != nil {
		return nil, err
	}

	switch m["@odata.type"] {
	case string(OdataTypeMicrosoftAzureSearchASCIIFoldingTokenFilter):
		var aftf ASCIIFoldingTokenFilter
		err := json.Unmarshal(body, &aftf)
		return aftf, err
	case string(OdataTypeMicrosoftAzureSearchCjkBigramTokenFilter):
		var cbtf CjkBigramTokenFilter
		err := json.Unmarshal(body, &cbtf)
		return cbtf, err
	case string(OdataTypeMicrosoftAzureSearchCommonGramTokenFilter):
		var cgtf CommonGramTokenFilter
		err := json.Unmarshal(body, &cgtf)
		return cgtf, err
	case string(OdataTypeMicrosoftAzureSearchDictionaryDecompounderTokenFilter):
		var ddtf DictionaryDecompounderTokenFilter
		err := json.Unmarshal(body, &ddtf)
		return ddtf, err
	case string(OdataTypeMicrosoftAzureSearchEdgeNGramTokenFilter):
		var engtf EdgeNGramTokenFilter
		err := json.Unmarshal(body, &engtf)
		return engtf, err
	case string(OdataTypeMicrosoftAzureSearchEdgeNGramTokenFilterV2):
		var engtfv EdgeNGramTokenFilterV2
		err := json.Unmarshal(body, &engtfv)
		return engtfv, err
	case string(OdataTypeMicrosoftAzureSearchElisionTokenFilter):
		var etf ElisionTokenFilter
		err := json.Unmarshal(body, &etf)
		return etf, err
	case string(OdataTypeMicrosoftAzureSearchKeepTokenFilter):
		var ktf KeepTokenFilter
		err := json.Unmarshal(body, &ktf)
		return ktf, err
	case string(OdataTypeMicrosoftAzureSearchKeywordMarkerTokenFilter):
		var kmtf KeywordMarkerTokenFilter
		err := json.Unmarshal(body, &kmtf)
		return kmtf, err
	case string(OdataTypeMicrosoftAzureSearchLengthTokenFilter):
		var ltf LengthTokenFilter
		err := json.Unmarshal(body, &ltf)
		return ltf, err
	case string(OdataTypeMicrosoftAzureSearchLimitTokenFilter):
		var ltf LimitTokenFilter
		err := json.Unmarshal(body, &ltf)
		return ltf, err
	case string(OdataTypeMicrosoftAzureSearchNGramTokenFilter):
		var ngtf NGramTokenFilter
		err := json.Unmarshal(body, &ngtf)
		return ngtf, err
	case string(OdataTypeMicrosoftAzureSearchNGramTokenFilterV2):
		var ngtfv NGramTokenFilterV2
		err := json.Unmarshal(body, &ngtfv)
		return ngtfv, err
	case string(OdataTypeMicrosoftAzureSearchPatternCaptureTokenFilter):
		var pctf PatternCaptureTokenFilter
		err := json.Unmarshal(body, &pctf)
		return pctf, err
	case string(OdataTypeMicrosoftAzureSearchPatternReplaceTokenFilter):
		var prtf PatternReplaceTokenFilter
		err := json.Unmarshal(body, &prtf)
		return prtf, err
	case string(OdataTypeMicrosoftAzureSearchPhoneticTokenFilter):
		var ptf PhoneticTokenFilter
		err := json.Unmarshal(body, &ptf)
		return ptf, err
	case string(OdataTypeMicrosoftAzureSearchShingleTokenFilter):
		var stf ShingleTokenFilter
		err := json.Unmarshal(body, &stf)
		return stf, err
	case string(OdataTypeMicrosoftAzureSearchSnowballTokenFilter):
		var stf SnowballTokenFilter
		err := json.Unmarshal(body, &stf)
		return stf, err
	case string(OdataTypeMicrosoftAzureSearchStemmerTokenFilter):
		var stf StemmerTokenFilter
		err := json.Unmarshal(body, &stf)
		return stf, err
	case string(OdataTypeMicrosoftAzureSearchStemmerOverrideTokenFilter):
		var sotf StemmerOverrideTokenFilter
		err := json.Unmarshal(body, &sotf)
		return sotf, err
	case string(OdataTypeMicrosoftAzureSearchStopwordsTokenFilter):
		var stf StopwordsTokenFilter
		err := json.Unmarshal(body, &stf)
		return stf, err
	case string(OdataTypeMicrosoftAzureSearchSynonymTokenFilter):
		var stf SynonymTokenFilter
		err := json.Unmarshal(body, &stf)
		return stf, err
	case string(OdataTypeMicrosoftAzureSearchTruncateTokenFilter):
		var ttf TruncateTokenFilter
		err := json.Unmarshal(body, &ttf)
		return ttf, err
	case string(OdataTypeMicrosoftAzureSearchUniqueTokenFilter):
		var utf UniqueTokenFilter
		err := json.Unmarshal(body, &utf)
		return utf, err
	case string(OdataTypeMicrosoftAzureSearchWordDelimiterTokenFilter):
		var wdtf WordDelimiterTokenFilter
		err := json.Unmarshal(body, &wdtf)
		return wdtf, err
	default:
		return nil, errors.New("Unsupported type")
	}
}
func unmarshalTokenFilterArray(body []byte) ([]TokenFilter, error) {
	var rawMessages []*json.RawMessage
	err := json.Unmarshal(body, &rawMessages)
	if err != nil {
		return nil, err
	}

	tfArray := make([]TokenFilter, len(rawMessages))

	for index, rawMessage := range rawMessages {
		tf, err := unmarshalTokenFilter(*rawMessage)
		if err != nil {
			return nil, err
		}
		tfArray[index] = tf
	}
	return tfArray, nil
}

// TokenFilterName is defines the names of all token filters supported by Azure Search.
type TokenFilterName struct {
	Name *string `json:"name,omitempty"`
}

// TokenInfo is information about a token returned by an analyzer.
type TokenInfo struct {
	Token       *string `json:"token,omitempty"`
	StartOffset *int32  `json:"startOffset,omitempty"`
	EndOffset   *int32  `json:"endOffset,omitempty"`
	Position    *int32  `json:"position,omitempty"`
}

// Tokenizer is abstract base class for tokenizers.
type Tokenizer interface {
	AsClassicTokenizer() (*ClassicTokenizer, bool)
	AsEdgeNGramTokenizer() (*EdgeNGramTokenizer, bool)
	AsKeywordTokenizer() (*KeywordTokenizer, bool)
	AsKeywordTokenizerV2() (*KeywordTokenizerV2, bool)
	AsMicrosoftLanguageTokenizer() (*MicrosoftLanguageTokenizer, bool)
	AsMicrosoftLanguageStemmingTokenizer() (*MicrosoftLanguageStemmingTokenizer, bool)
	AsNGramTokenizer() (*NGramTokenizer, bool)
	AsPathHierarchyTokenizer() (*PathHierarchyTokenizer, bool)
	AsPathHierarchyTokenizerV2() (*PathHierarchyTokenizerV2, bool)
	AsPatternTokenizer() (*PatternTokenizer, bool)
	AsStandardTokenizer() (*StandardTokenizer, bool)
	AsStandardTokenizerV2() (*StandardTokenizerV2, bool)
	AsUaxURLEmailTokenizer() (*UaxURLEmailTokenizer, bool)
}

func unmarshalTokenizer(body []byte) (Tokenizer, error) {
	var m map[string]interface{}
	err := json.Unmarshal(body, &m)
	if err != nil {
		return nil, err
	}

	switch m["@odata.type"] {
	case string(OdataTypeMicrosoftAzureSearchClassicTokenizer):
		var ct ClassicTokenizer
		err := json.Unmarshal(body, &ct)
		return ct, err
	case string(OdataTypeMicrosoftAzureSearchEdgeNGramTokenizer):
		var engt EdgeNGramTokenizer
		err := json.Unmarshal(body, &engt)
		return engt, err
	case string(OdataTypeMicrosoftAzureSearchKeywordTokenizer):
		var kt KeywordTokenizer
		err := json.Unmarshal(body, &kt)
		return kt, err
	case string(OdataTypeMicrosoftAzureSearchKeywordTokenizerV2):
		var ktv KeywordTokenizerV2
		err := json.Unmarshal(body, &ktv)
		return ktv, err
	case string(OdataTypeMicrosoftAzureSearchMicrosoftLanguageTokenizer):
		var mlt MicrosoftLanguageTokenizer
		err := json.Unmarshal(body, &mlt)
		return mlt, err
	case string(OdataTypeMicrosoftAzureSearchMicrosoftLanguageStemmingTokenizer):
		var mlst MicrosoftLanguageStemmingTokenizer
		err := json.Unmarshal(body, &mlst)
		return mlst, err
	case string(OdataTypeMicrosoftAzureSearchNGramTokenizer):
		var ngt NGramTokenizer
		err := json.Unmarshal(body, &ngt)
		return ngt, err
	case string(OdataTypeMicrosoftAzureSearchPathHierarchyTokenizer):
		var pht PathHierarchyTokenizer
		err := json.Unmarshal(body, &pht)
		return pht, err
	case string(OdataTypeMicrosoftAzureSearchPathHierarchyTokenizerV2):
		var phtv PathHierarchyTokenizerV2
		err := json.Unmarshal(body, &phtv)
		return phtv, err
	case string(OdataTypeMicrosoftAzureSearchPatternTokenizer):
		var pt PatternTokenizer
		err := json.Unmarshal(body, &pt)
		return pt, err
	case string(OdataTypeMicrosoftAzureSearchStandardTokenizer):
		var st StandardTokenizer
		err := json.Unmarshal(body, &st)
		return st, err
	case string(OdataTypeMicrosoftAzureSearchStandardTokenizerV2):
		var stv StandardTokenizerV2
		err := json.Unmarshal(body, &stv)
		return stv, err
	case string(OdataTypeMicrosoftAzureSearchUaxURLEmailTokenizer):
		var uuet UaxURLEmailTokenizer
		err := json.Unmarshal(body, &uuet)
		return uuet, err
	default:
		return nil, errors.New("Unsupported type")
	}
}
func unmarshalTokenizerArray(body []byte) ([]Tokenizer, error) {
	var rawMessages []*json.RawMessage
	err := json.Unmarshal(body, &rawMessages)
	if err != nil {
		return nil, err
	}

	tArray := make([]Tokenizer, len(rawMessages))

	for index, rawMessage := range rawMessages {
		t, err := unmarshalTokenizer(*rawMessage)
		if err != nil {
			return nil, err
		}
		tArray[index] = t
	}
	return tArray, nil
}

// TokenizerName is defines the names of all tokenizers supported by Azure Search.
type TokenizerName struct {
	Name *string `json:"name,omitempty"`
}

// TruncateTokenFilter is truncates the terms to a specific length. This token filter is implemented using Apache
// Lucene.
type TruncateTokenFilter struct {
	Name      *string    `json:"name,omitempty"`
	OdataType OdataType2 `json:"@odata.type,omitempty"`
	Length    *int32     `json:"length,omitempty"`
}

// MarshalJSON is the custom marshaler for TruncateTokenFilter.
func (ttf TruncateTokenFilter) MarshalJSON() ([]byte, error) {
	ttf.OdataType = OdataTypeMicrosoftAzureSearchTruncateTokenFilter
	type Alias TruncateTokenFilter
	return json.Marshal(&struct {
		Alias
	}{
		Alias: (Alias)(ttf),
	})
}

// AsASCIIFoldingTokenFilter is the TokenFilter implementation for TruncateTokenFilter.
func (ttf TruncateTokenFilter) AsASCIIFoldingTokenFilter() (*ASCIIFoldingTokenFilter, bool) {
	return nil, false
}

// AsCjkBigramTokenFilter is the TokenFilter implementation for TruncateTokenFilter.
func (ttf TruncateTokenFilter) AsCjkBigramTokenFilter() (*CjkBigramTokenFilter, bool) {
	return nil, false
}

// AsCommonGramTokenFilter is the TokenFilter implementation for TruncateTokenFilter.
func (ttf TruncateTokenFilter) AsCommonGramTokenFilter() (*CommonGramTokenFilter, bool) {
	return nil, false
}

// AsDictionaryDecompounderTokenFilter is the TokenFilter implementation for TruncateTokenFilter.
func (ttf TruncateTokenFilter) AsDictionaryDecompounderTokenFilter() (*DictionaryDecompounderTokenFilter, bool) {
	return nil, false
}

// AsEdgeNGramTokenFilter is the TokenFilter implementation for TruncateTokenFilter.
func (ttf TruncateTokenFilter) AsEdgeNGramTokenFilter() (*EdgeNGramTokenFilter, bool) {
	return nil, false
}

// AsEdgeNGramTokenFilterV2 is the TokenFilter implementation for TruncateTokenFilter.
func (ttf TruncateTokenFilter) AsEdgeNGramTokenFilterV2() (*EdgeNGramTokenFilterV2, bool) {
	return nil, false
}

// AsElisionTokenFilter is the TokenFilter implementation for TruncateTokenFilter.
func (ttf TruncateTokenFilter) AsElisionTokenFilter() (*ElisionTokenFilter, bool) {
	return nil, false
}

// AsKeepTokenFilter is the TokenFilter implementation for TruncateTokenFilter.
func (ttf TruncateTokenFilter) AsKeepTokenFilter() (*KeepTokenFilter, bool) {
	return nil, false
}

// AsKeywordMarkerTokenFilter is the TokenFilter implementation for TruncateTokenFilter.
func (ttf TruncateTokenFilter) AsKeywordMarkerTokenFilter() (*KeywordMarkerTokenFilter, bool) {
	return nil, false
}

// AsLengthTokenFilter is the TokenFilter implementation for TruncateTokenFilter.
func (ttf TruncateTokenFilter) AsLengthTokenFilter() (*LengthTokenFilter, bool) {
	return nil, false
}

// AsLimitTokenFilter is the TokenFilter implementation for TruncateTokenFilter.
func (ttf TruncateTokenFilter) AsLimitTokenFilter() (*LimitTokenFilter, bool) {
	return nil, false
}

// AsNGramTokenFilter is the TokenFilter implementation for TruncateTokenFilter.
func (ttf TruncateTokenFilter) AsNGramTokenFilter() (*NGramTokenFilter, bool) {
	return nil, false
}

// AsNGramTokenFilterV2 is the TokenFilter implementation for TruncateTokenFilter.
func (ttf TruncateTokenFilter) AsNGramTokenFilterV2() (*NGramTokenFilterV2, bool) {
	return nil, false
}

// AsPatternCaptureTokenFilter is the TokenFilter implementation for TruncateTokenFilter.
func (ttf TruncateTokenFilter) AsPatternCaptureTokenFilter() (*PatternCaptureTokenFilter, bool) {
	return nil, false
}

// AsPatternReplaceTokenFilter is the TokenFilter implementation for TruncateTokenFilter.
func (ttf TruncateTokenFilter) AsPatternReplaceTokenFilter() (*PatternReplaceTokenFilter, bool) {
	return nil, false
}

// AsPhoneticTokenFilter is the TokenFilter implementation for TruncateTokenFilter.
func (ttf TruncateTokenFilter) AsPhoneticTokenFilter() (*PhoneticTokenFilter, bool) {
	return nil, false
}

// AsShingleTokenFilter is the TokenFilter implementation for TruncateTokenFilter.
func (ttf TruncateTokenFilter) AsShingleTokenFilter() (*ShingleTokenFilter, bool) {
	return nil, false
}

// AsSnowballTokenFilter is the TokenFilter implementation for TruncateTokenFilter.
func (ttf TruncateTokenFilter) AsSnowballTokenFilter() (*SnowballTokenFilter, bool) {
	return nil, false
}

// AsStemmerTokenFilter is the TokenFilter implementation for TruncateTokenFilter.
func (ttf TruncateTokenFilter) AsStemmerTokenFilter() (*StemmerTokenFilter, bool) {
	return nil, false
}

// AsStemmerOverrideTokenFilter is the TokenFilter implementation for TruncateTokenFilter.
func (ttf TruncateTokenFilter) AsStemmerOverrideTokenFilter() (*StemmerOverrideTokenFilter, bool) {
	return nil, false
}

// AsStopwordsTokenFilter is the TokenFilter implementation for TruncateTokenFilter.
func (ttf TruncateTokenFilter) AsStopwordsTokenFilter() (*StopwordsTokenFilter, bool) {
	return nil, false
}

// AsSynonymTokenFilter is the TokenFilter implementation for TruncateTokenFilter.
func (ttf TruncateTokenFilter) AsSynonymTokenFilter() (*SynonymTokenFilter, bool) {
	return nil, false
}

// AsTruncateTokenFilter is the TokenFilter implementation for TruncateTokenFilter.
func (ttf TruncateTokenFilter) AsTruncateTokenFilter() (*TruncateTokenFilter, bool) {
	return &ttf, true
}

// AsUniqueTokenFilter is the TokenFilter implementation for TruncateTokenFilter.
func (ttf TruncateTokenFilter) AsUniqueTokenFilter() (*UniqueTokenFilter, bool) {
	return nil, false
}

// AsWordDelimiterTokenFilter is the TokenFilter implementation for TruncateTokenFilter.
func (ttf TruncateTokenFilter) AsWordDelimiterTokenFilter() (*WordDelimiterTokenFilter, bool) {
	return nil, false
}

// UaxURLEmailTokenizer is tokenizes urls and emails as one token. This tokenizer is implemented using Apache Lucene.
type UaxURLEmailTokenizer struct {
	Name           *string    `json:"name,omitempty"`
	OdataType      OdataType1 `json:"@odata.type,omitempty"`
	MaxTokenLength *int32     `json:"maxTokenLength,omitempty"`
}

// MarshalJSON is the custom marshaler for UaxURLEmailTokenizer.
func (uuet UaxURLEmailTokenizer) MarshalJSON() ([]byte, error) {
	uuet.OdataType = OdataTypeMicrosoftAzureSearchUaxURLEmailTokenizer
	type Alias UaxURLEmailTokenizer
	return json.Marshal(&struct {
		Alias
	}{
		Alias: (Alias)(uuet),
	})
}

// AsClassicTokenizer is the Tokenizer implementation for UaxURLEmailTokenizer.
func (uuet UaxURLEmailTokenizer) AsClassicTokenizer() (*ClassicTokenizer, bool) {
	return nil, false
}

// AsEdgeNGramTokenizer is the Tokenizer implementation for UaxURLEmailTokenizer.
func (uuet UaxURLEmailTokenizer) AsEdgeNGramTokenizer() (*EdgeNGramTokenizer, bool) {
	return nil, false
}

// AsKeywordTokenizer is the Tokenizer implementation for UaxURLEmailTokenizer.
func (uuet UaxURLEmailTokenizer) AsKeywordTokenizer() (*KeywordTokenizer, bool) {
	return nil, false
}

// AsKeywordTokenizerV2 is the Tokenizer implementation for UaxURLEmailTokenizer.
func (uuet UaxURLEmailTokenizer) AsKeywordTokenizerV2() (*KeywordTokenizerV2, bool) {
	return nil, false
}

// AsMicrosoftLanguageTokenizer is the Tokenizer implementation for UaxURLEmailTokenizer.
func (uuet UaxURLEmailTokenizer) AsMicrosoftLanguageTokenizer() (*MicrosoftLanguageTokenizer, bool) {
	return nil, false
}

// AsMicrosoftLanguageStemmingTokenizer is the Tokenizer implementation for UaxURLEmailTokenizer.
func (uuet UaxURLEmailTokenizer) AsMicrosoftLanguageStemmingTokenizer() (*MicrosoftLanguageStemmingTokenizer, bool) {
	return nil, false
}

// AsNGramTokenizer is the Tokenizer implementation for UaxURLEmailTokenizer.
func (uuet UaxURLEmailTokenizer) AsNGramTokenizer() (*NGramTokenizer, bool) {
	return nil, false
}

// AsPathHierarchyTokenizer is the Tokenizer implementation for UaxURLEmailTokenizer.
func (uuet UaxURLEmailTokenizer) AsPathHierarchyTokenizer() (*PathHierarchyTokenizer, bool) {
	return nil, false
}

// AsPathHierarchyTokenizerV2 is the Tokenizer implementation for UaxURLEmailTokenizer.
func (uuet UaxURLEmailTokenizer) AsPathHierarchyTokenizerV2() (*PathHierarchyTokenizerV2, bool) {
	return nil, false
}

// AsPatternTokenizer is the Tokenizer implementation for UaxURLEmailTokenizer.
func (uuet UaxURLEmailTokenizer) AsPatternTokenizer() (*PatternTokenizer, bool) {
	return nil, false
}

// AsStandardTokenizer is the Tokenizer implementation for UaxURLEmailTokenizer.
func (uuet UaxURLEmailTokenizer) AsStandardTokenizer() (*StandardTokenizer, bool) {
	return nil, false
}

// AsStandardTokenizerV2 is the Tokenizer implementation for UaxURLEmailTokenizer.
func (uuet UaxURLEmailTokenizer) AsStandardTokenizerV2() (*StandardTokenizerV2, bool) {
	return nil, false
}

// AsUaxURLEmailTokenizer is the Tokenizer implementation for UaxURLEmailTokenizer.
func (uuet UaxURLEmailTokenizer) AsUaxURLEmailTokenizer() (*UaxURLEmailTokenizer, bool) {
	return &uuet, true
}

// UniqueTokenFilter is filters out tokens with same text as the previous token. This token filter is implemented using
// Apache Lucene.
type UniqueTokenFilter struct {
	Name               *string    `json:"name,omitempty"`
	OdataType          OdataType2 `json:"@odata.type,omitempty"`
	OnlyOnSamePosition *bool      `json:"onlyOnSamePosition,omitempty"`
}

// MarshalJSON is the custom marshaler for UniqueTokenFilter.
func (utf UniqueTokenFilter) MarshalJSON() ([]byte, error) {
	utf.OdataType = OdataTypeMicrosoftAzureSearchUniqueTokenFilter
	type Alias UniqueTokenFilter
	return json.Marshal(&struct {
		Alias
	}{
		Alias: (Alias)(utf),
	})
}

// AsASCIIFoldingTokenFilter is the TokenFilter implementation for UniqueTokenFilter.
func (utf UniqueTokenFilter) AsASCIIFoldingTokenFilter() (*ASCIIFoldingTokenFilter, bool) {
	return nil, false
}

// AsCjkBigramTokenFilter is the TokenFilter implementation for UniqueTokenFilter.
func (utf UniqueTokenFilter) AsCjkBigramTokenFilter() (*CjkBigramTokenFilter, bool) {
	return nil, false
}

// AsCommonGramTokenFilter is the TokenFilter implementation for UniqueTokenFilter.
func (utf UniqueTokenFilter) AsCommonGramTokenFilter() (*CommonGramTokenFilter, bool) {
	return nil, false
}

// AsDictionaryDecompounderTokenFilter is the TokenFilter implementation for UniqueTokenFilter.
func (utf UniqueTokenFilter) AsDictionaryDecompounderTokenFilter() (*DictionaryDecompounderTokenFilter, bool) {
	return nil, false
}

// AsEdgeNGramTokenFilter is the TokenFilter implementation for UniqueTokenFilter.
func (utf UniqueTokenFilter) AsEdgeNGramTokenFilter() (*EdgeNGramTokenFilter, bool) {
	return nil, false
}

// AsEdgeNGramTokenFilterV2 is the TokenFilter implementation for UniqueTokenFilter.
func (utf UniqueTokenFilter) AsEdgeNGramTokenFilterV2() (*EdgeNGramTokenFilterV2, bool) {
	return nil, false
}

// AsElisionTokenFilter is the TokenFilter implementation for UniqueTokenFilter.
func (utf UniqueTokenFilter) AsElisionTokenFilter() (*ElisionTokenFilter, bool) {
	return nil, false
}

// AsKeepTokenFilter is the TokenFilter implementation for UniqueTokenFilter.
func (utf UniqueTokenFilter) AsKeepTokenFilter() (*KeepTokenFilter, bool) {
	return nil, false
}

// AsKeywordMarkerTokenFilter is the TokenFilter implementation for UniqueTokenFilter.
func (utf UniqueTokenFilter) AsKeywordMarkerTokenFilter() (*KeywordMarkerTokenFilter, bool) {
	return nil, false
}

// AsLengthTokenFilter is the TokenFilter implementation for UniqueTokenFilter.
func (utf UniqueTokenFilter) AsLengthTokenFilter() (*LengthTokenFilter, bool) {
	return nil, false
}

// AsLimitTokenFilter is the TokenFilter implementation for UniqueTokenFilter.
func (utf UniqueTokenFilter) AsLimitTokenFilter() (*LimitTokenFilter, bool) {
	return nil, false
}

// AsNGramTokenFilter is the TokenFilter implementation for UniqueTokenFilter.
func (utf UniqueTokenFilter) AsNGramTokenFilter() (*NGramTokenFilter, bool) {
	return nil, false
}

// AsNGramTokenFilterV2 is the TokenFilter implementation for UniqueTokenFilter.
func (utf UniqueTokenFilter) AsNGramTokenFilterV2() (*NGramTokenFilterV2, bool) {
	return nil, false
}

// AsPatternCaptureTokenFilter is the TokenFilter implementation for UniqueTokenFilter.
func (utf UniqueTokenFilter) AsPatternCaptureTokenFilter() (*PatternCaptureTokenFilter, bool) {
	return nil, false
}

// AsPatternReplaceTokenFilter is the TokenFilter implementation for UniqueTokenFilter.
func (utf UniqueTokenFilter) AsPatternReplaceTokenFilter() (*PatternReplaceTokenFilter, bool) {
	return nil, false
}

// AsPhoneticTokenFilter is the TokenFilter implementation for UniqueTokenFilter.
func (utf UniqueTokenFilter) AsPhoneticTokenFilter() (*PhoneticTokenFilter, bool) {
	return nil, false
}

// AsShingleTokenFilter is the TokenFilter implementation for UniqueTokenFilter.
func (utf UniqueTokenFilter) AsShingleTokenFilter() (*ShingleTokenFilter, bool) {
	return nil, false
}

// AsSnowballTokenFilter is the TokenFilter implementation for UniqueTokenFilter.
func (utf UniqueTokenFilter) AsSnowballTokenFilter() (*SnowballTokenFilter, bool) {
	return nil, false
}

// AsStemmerTokenFilter is the TokenFilter implementation for UniqueTokenFilter.
func (utf UniqueTokenFilter) AsStemmerTokenFilter() (*StemmerTokenFilter, bool) {
	return nil, false
}

// AsStemmerOverrideTokenFilter is the TokenFilter implementation for UniqueTokenFilter.
func (utf UniqueTokenFilter) AsStemmerOverrideTokenFilter() (*StemmerOverrideTokenFilter, bool) {
	return nil, false
}

// AsStopwordsTokenFilter is the TokenFilter implementation for UniqueTokenFilter.
func (utf UniqueTokenFilter) AsStopwordsTokenFilter() (*StopwordsTokenFilter, bool) {
	return nil, false
}

// AsSynonymTokenFilter is the TokenFilter implementation for UniqueTokenFilter.
func (utf UniqueTokenFilter) AsSynonymTokenFilter() (*SynonymTokenFilter, bool) {
	return nil, false
}

// AsTruncateTokenFilter is the TokenFilter implementation for UniqueTokenFilter.
func (utf UniqueTokenFilter) AsTruncateTokenFilter() (*TruncateTokenFilter, bool) {
	return nil, false
}

// AsUniqueTokenFilter is the TokenFilter implementation for UniqueTokenFilter.
func (utf UniqueTokenFilter) AsUniqueTokenFilter() (*UniqueTokenFilter, bool) {
	return &utf, true
}

// AsWordDelimiterTokenFilter is the TokenFilter implementation for UniqueTokenFilter.
func (utf UniqueTokenFilter) AsWordDelimiterTokenFilter() (*WordDelimiterTokenFilter, bool) {
	return nil, false
}

// WordDelimiterTokenFilter is splits words into subwords and performs optional transformations on subword groups. This
// token filter is implemented using Apache Lucene.
type WordDelimiterTokenFilter struct {
	Name                  *string    `json:"name,omitempty"`
	OdataType             OdataType2 `json:"@odata.type,omitempty"`
	GenerateWordParts     *bool      `json:"generateWordParts,omitempty"`
	GenerateNumberParts   *bool      `json:"generateNumberParts,omitempty"`
	CatenateWords         *bool      `json:"catenateWords,omitempty"`
	CatenateNumbers       *bool      `json:"catenateNumbers,omitempty"`
	CatenateAll           *bool      `json:"catenateAll,omitempty"`
	SplitOnCaseChange     *bool      `json:"splitOnCaseChange,omitempty"`
	PreserveOriginal      *bool      `json:"preserveOriginal,omitempty"`
	SplitOnNumerics       *bool      `json:"splitOnNumerics,omitempty"`
	StemEnglishPossessive *bool      `json:"stemEnglishPossessive,omitempty"`
	ProtectedWords        *[]string  `json:"protectedWords,omitempty"`
}

// MarshalJSON is the custom marshaler for WordDelimiterTokenFilter.
func (wdtf WordDelimiterTokenFilter) MarshalJSON() ([]byte, error) {
	wdtf.OdataType = OdataTypeMicrosoftAzureSearchWordDelimiterTokenFilter
	type Alias WordDelimiterTokenFilter
	return json.Marshal(&struct {
		Alias
	}{
		Alias: (Alias)(wdtf),
	})
}

// AsASCIIFoldingTokenFilter is the TokenFilter implementation for WordDelimiterTokenFilter.
func (wdtf WordDelimiterTokenFilter) AsASCIIFoldingTokenFilter() (*ASCIIFoldingTokenFilter, bool) {
	return nil, false
}

// AsCjkBigramTokenFilter is the TokenFilter implementation for WordDelimiterTokenFilter.
func (wdtf WordDelimiterTokenFilter) AsCjkBigramTokenFilter() (*CjkBigramTokenFilter, bool) {
	return nil, false
}

// AsCommonGramTokenFilter is the TokenFilter implementation for WordDelimiterTokenFilter.
func (wdtf WordDelimiterTokenFilter) AsCommonGramTokenFilter() (*CommonGramTokenFilter, bool) {
	return nil, false
}

// AsDictionaryDecompounderTokenFilter is the TokenFilter implementation for WordDelimiterTokenFilter.
func (wdtf WordDelimiterTokenFilter) AsDictionaryDecompounderTokenFilter() (*DictionaryDecompounderTokenFilter, bool) {
	return nil, false
}

// AsEdgeNGramTokenFilter is the TokenFilter implementation for WordDelimiterTokenFilter.
func (wdtf WordDelimiterTokenFilter) AsEdgeNGramTokenFilter() (*EdgeNGramTokenFilter, bool) {
	return nil, false
}

// AsEdgeNGramTokenFilterV2 is the TokenFilter implementation for WordDelimiterTokenFilter.
func (wdtf WordDelimiterTokenFilter) AsEdgeNGramTokenFilterV2() (*EdgeNGramTokenFilterV2, bool) {
	return nil, false
}

// AsElisionTokenFilter is the TokenFilter implementation for WordDelimiterTokenFilter.
func (wdtf WordDelimiterTokenFilter) AsElisionTokenFilter() (*ElisionTokenFilter, bool) {
	return nil, false
}

// AsKeepTokenFilter is the TokenFilter implementation for WordDelimiterTokenFilter.
func (wdtf WordDelimiterTokenFilter) AsKeepTokenFilter() (*KeepTokenFilter, bool) {
	return nil, false
}

// AsKeywordMarkerTokenFilter is the TokenFilter implementation for WordDelimiterTokenFilter.
func (wdtf WordDelimiterTokenFilter) AsKeywordMarkerTokenFilter() (*KeywordMarkerTokenFilter, bool) {
	return nil, false
}

// AsLengthTokenFilter is the TokenFilter implementation for WordDelimiterTokenFilter.
func (wdtf WordDelimiterTokenFilter) AsLengthTokenFilter() (*LengthTokenFilter, bool) {
	return nil, false
}

// AsLimitTokenFilter is the TokenFilter implementation for WordDelimiterTokenFilter.
func (wdtf WordDelimiterTokenFilter) AsLimitTokenFilter() (*LimitTokenFilter, bool) {
	return nil, false
}

// AsNGramTokenFilter is the TokenFilter implementation for WordDelimiterTokenFilter.
func (wdtf WordDelimiterTokenFilter) AsNGramTokenFilter() (*NGramTokenFilter, bool) {
	return nil, false
}

// AsNGramTokenFilterV2 is the TokenFilter implementation for WordDelimiterTokenFilter.
func (wdtf WordDelimiterTokenFilter) AsNGramTokenFilterV2() (*NGramTokenFilterV2, bool) {
	return nil, false
}

// AsPatternCaptureTokenFilter is the TokenFilter implementation for WordDelimiterTokenFilter.
func (wdtf WordDelimiterTokenFilter) AsPatternCaptureTokenFilter() (*PatternCaptureTokenFilter, bool) {
	return nil, false
}

// AsPatternReplaceTokenFilter is the TokenFilter implementation for WordDelimiterTokenFilter.
func (wdtf WordDelimiterTokenFilter) AsPatternReplaceTokenFilter() (*PatternReplaceTokenFilter, bool) {
	return nil, false
}

// AsPhoneticTokenFilter is the TokenFilter implementation for WordDelimiterTokenFilter.
func (wdtf WordDelimiterTokenFilter) AsPhoneticTokenFilter() (*PhoneticTokenFilter, bool) {
	return nil, false
}

// AsShingleTokenFilter is the TokenFilter implementation for WordDelimiterTokenFilter.
func (wdtf WordDelimiterTokenFilter) AsShingleTokenFilter() (*ShingleTokenFilter, bool) {
	return nil, false
}

// AsSnowballTokenFilter is the TokenFilter implementation for WordDelimiterTokenFilter.
func (wdtf WordDelimiterTokenFilter) AsSnowballTokenFilter() (*SnowballTokenFilter, bool) {
	return nil, false
}

// AsStemmerTokenFilter is the TokenFilter implementation for WordDelimiterTokenFilter.
func (wdtf WordDelimiterTokenFilter) AsStemmerTokenFilter() (*StemmerTokenFilter, bool) {
	return nil, false
}

// AsStemmerOverrideTokenFilter is the TokenFilter implementation for WordDelimiterTokenFilter.
func (wdtf WordDelimiterTokenFilter) AsStemmerOverrideTokenFilter() (*StemmerOverrideTokenFilter, bool) {
	return nil, false
}

// AsStopwordsTokenFilter is the TokenFilter implementation for WordDelimiterTokenFilter.
func (wdtf WordDelimiterTokenFilter) AsStopwordsTokenFilter() (*StopwordsTokenFilter, bool) {
	return nil, false
}

// AsSynonymTokenFilter is the TokenFilter implementation for WordDelimiterTokenFilter.
func (wdtf WordDelimiterTokenFilter) AsSynonymTokenFilter() (*SynonymTokenFilter, bool) {
	return nil, false
}

// AsTruncateTokenFilter is the TokenFilter implementation for WordDelimiterTokenFilter.
func (wdtf WordDelimiterTokenFilter) AsTruncateTokenFilter() (*TruncateTokenFilter, bool) {
	return nil, false
}

// AsUniqueTokenFilter is the TokenFilter implementation for WordDelimiterTokenFilter.
func (wdtf WordDelimiterTokenFilter) AsUniqueTokenFilter() (*UniqueTokenFilter, bool) {
	return nil, false
}

// AsWordDelimiterTokenFilter is the TokenFilter implementation for WordDelimiterTokenFilter.
func (wdtf WordDelimiterTokenFilter) AsWordDelimiterTokenFilter() (*WordDelimiterTokenFilter, bool) {
	return &wdtf, true
}
